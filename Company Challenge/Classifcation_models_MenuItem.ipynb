{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps Performed while working on given Problem Statement - \n",
    "\n",
    "### First we will be going with regular approach of preparing our data for our models by performing various steps like dummy encdoing, Train - Test data splitting and Initializing various models and then performing  fit() & predict() methods on our models and check their accuracies.\n",
    "\n",
    "### From here, we will be predicting MenuItems for our already generated test data for dates 1st July,2019 to 7th July,2019 and then exporting that predicted data to an excel file which will be used again as test data for Predicting Item Quantity for each order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_excel(\"prepared_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General EDA - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22038, 7)\n",
      "            ItemQty\n",
      "count  22038.000000\n",
      "mean       1.695707\n",
      "std        0.896095\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        2.000000\n",
      "max        4.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22038 entries, 0 to 22037\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          22038 non-null  datetime64[ns]\n",
      " 1   Day           22038 non-null  object        \n",
      " 2   Day Type      22038 non-null  object        \n",
      " 3   Shift         22038 non-null  object        \n",
      " 4   MenuCategory  22038 non-null  object        \n",
      " 5   MenuItem      22038 non-null  object        \n",
      " 6   ItemQty       22038 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.describe())\n",
    "print(data.info())\n",
    "print(data.MenuItem.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day Type</th>\n",
       "      <th>Shift</th>\n",
       "      <th>MenuCategory</th>\n",
       "      <th>MenuItem</th>\n",
       "      <th>ItemQty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Starter</td>\n",
       "      <td>GOBI MANCHURIAN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Starter</td>\n",
       "      <td>TASTY FLATBREAD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "      <td>SARSON DA SAAG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "      <td>PANEER VINDALOO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>GARLIC NAAN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Day Day Type  Shift        MenuCategory         MenuItem  \\\n",
       "0 2019-01-01  Tuesday  Weekday  Lunch             Starter  GOBI MANCHURIAN   \n",
       "1 2019-01-01  Tuesday  Weekday  Lunch             Starter  TASTY FLATBREAD   \n",
       "2 2019-01-01  Tuesday  Weekday  Lunch  VEGETABLE SPECIALS   SARSON DA SAAG   \n",
       "3 2019-01-01  Tuesday  Weekday  Lunch  VEGETABLE SPECIALS  PANEER VINDALOO   \n",
       "4 2019-01-01  Tuesday  Weekday  Lunch              BREADS      GARLIC NAAN   \n",
       "\n",
       "   ItemQty  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data.groupby(['Date','Shift','MenuItem']).agg({'ItemQty':sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ItemQty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Shift</th>\n",
       "      <th>MenuItem</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019-01-01</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Dinner</th>\n",
       "      <th>BAINGAN BARTHA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUTTER CHICKEN</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARROT HALWA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHICKEN TIKKA MASALA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FISH CURRY</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ItemQty\n",
       "Date       Shift  MenuItem                     \n",
       "2019-01-01 Dinner BAINGAN BARTHA              1\n",
       "                  BUTTER CHICKEN              5\n",
       "                  CARROT HALWA                1\n",
       "                  CHICKEN TIKKA MASALA        1\n",
       "                  FISH CURRY                  5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram plots from checking distribution of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "data.groupby('MenuCategory').MenuItem.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAANOCAYAAACBfep6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdfbzlc73//8fTuJxcRhdCtiYRYoxdCikRyqSUYkxH009n6hydokMU5zSnEjWkC6WkYrqJKSLRkVPMF5mj9jDXLjLNkNGFoTNipikzz98fn/fKx7L23p89hj175nm/3dbNWu/L12et7Xb7vNb7/V4j20RERERERDSxzmAHEBERERERQ0cSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERja072AFErC222mord3V1DXYYEREREf2aNm3aItsv6FSXBCLiOdLV1UVPT89ghxERERHRL0n39VaXLUwREREREdFYEoiIiIiIiGgsCURERERERDSWMxARz5FZCxfTdeq1gx1GRAySBWcdNtghRESsElmBiIiIiIiIxpJArKVUuUXSW2pl75F0naTlkqbXHqeW+imSutvGeaOkazqMv76kL0maJ+k3kn4sadtSd66kE2ptfybpwtrrcyR9rMOYrbjmSJoh6WOS1mlr82VJC+vlksZJOq+f92OKpLtr13xk25yzJf1E0uaSNpR0l6RX1fp/XNI3+pojIiIiYk2QBGItZdvAh4Avlhvi5wFnAMcDS22PrD3OWokpPgdsArzC9o7AVcCPJAm4FdgHoNzobwXsWuu7D/DLDmO24toVeDPwVuBTrcoy1hHA74D9VyLmsbVrvrxtzt2AR4Djbf8VOAH4eknEtgE+CHxiJeaMiIiIGFKSQKzFbM8GfgKcQnUjPsn2vGc6rqThwPuBE20vL3N9F1gGvIkqOdinNN8VmA38RdIWkjYAXgnc0U/sfwLGAx8uSQnAAWWs84Exz/Q6OpgKbFPmvw74PXAscC4wwfafn4U5IyIiIlYrOUQd/wXcDvwNaG1P2kjS9FqbM21PHsCYLwfut/1oW3kPsKvtX0h6QtJLqRKJ1o3564DFwEzbf+tvEtu/LasOLwT+SJU0XAr8GPicpPVs/30AcV8iaWl5fqDth1sVkoYBBwLfrrU/AfgV8Bvb3+s0oKTxVIkOwzbt+I85RkRERAwpSSDWcrYflzQZeMz2slK81PbIZzCsAPdT3lqF2Af4IlUCsQ9VAnHrAOdC0vpUW5pOtP0XSbcBBwMD+dmjsbbb/6noVjLVBUwD/qdVYftBSTcATzsDUmtzAXABwAZb79jpPYmIiIgYUrKFKQBWlMeqci+wvaRN2spHAXPL89Y5iFdRbTv6X6oViN7OPzyNpJcBy4E/AYcCmwGzJC0A9mPVbGNqJVPbA+tTnRGpW9XvXURERMRqLQlErHK2HwcupjqgPQxA0rHAcOCG0uyXwGjgEdvLbT8CbE6VREztbw5JLwC+AZxXDoSPAT5gu8t2F7ADcHA5j7Eqrmkx8BHgJEnrrYoxIyIiIoaiJBDRyUZtP+Na/xWmayU9UB4/LGUH1soekPQ6ql8k+itwj6TfAO8Gjig3+wCzqH596X9rY88CFtte1E9cc4CfA9cD/1WShEOobVcqScwtwNtK0bi2GLcd6Jti+w5gBnD0QPtGRERErCn05P1cRDyburu73dPTfsQiIiIiYvUjaZrt7k51WYGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY2tO9gBRKwtZi1cTNep1/bfMCL6tOCswwY7hIiItVpWICIiIiIiorEkEEOMpCmSDmkrO0HS1yV1SVoqaXrtcWxps7Gk8yXNk3SHpGmS/rnUdewn6bby/H5JD9Xqukq/PSW5QzzLS7sZkm6XtE9tntkdrukiSfNr49/aoc1wSZdImiVptqRbJG1cqz+ixLJzrayrlH2mVraVpL9LOq9WNl7SXeXxK0n71epGl/drhqS5kj7YFtcMSZf297lFRERErCmyhWnouRQ4GvhZrexo4OTyfJ7tkR36XQj8FtjR9gpJLwD+v1p9p36TACSNA7ptf7itfgxwS/lvPZ6lrbFKcnEm8IZ+rutk25f3Uf9R4I+2X1XG3Qn4e4dYjgYm1Mp/C4wG/qO8fjcwp1UpaTTwQWA/24skjQKukvQa4GHgAuA1th+QtAHQVev7SqokfH9Jz7P9eD/XGBERETHkZQVi6LkcGF1uZimrAS+hunnuSNII4DXA6bZXANh+yPbnVzYISQKOBMYBB0vasJemmwJ/Xtl5arYGFrZe2L7b9rISy8bAvsBxVAlE3VLgTknd5fVRwA9q9adQJS+Lyri3AxcDxwObUCXZD5e6ZbbvrvU9BvgecD1w+Cq4xoiIiIjVXhKIIcb2w8CvgENL0dHAZNsur0e0bUV6PbArMKOVPPSiU7++7AvMtz0PmAK8tVa3URnjLqqVj8906N9uYm3uSzrUfwc4RdJUSZ+VtGOt7h3AdbbvAR4pqwh1lwFHS9oWWA48WKvbFZjW1r4H2NX2I8DVwH2SLpU0VlL9/5mjgMlUq0JjOl1U2R7VI6ln+ZLFfb4BEREREUNBEoihqbWNifLf+h78ebZH1h43t3eWdFq5UX9wIP3ajKG6Maf8t34DvbSMsTNVojOprFj05eTa3GPbK21PB14GTASeD/y6bCHqLxaA64A3l/LJ/cQBIMBl3g8AB1IlbSdRJTJIejXwkO37gF8AoyRt0SHuC2x32+4eNnyzBlNHRERErN5yBmJougr4YvmmfaOy7aYvc4E9JK1je4XtM4AzJD22MpNLGga8Czhc0mlUN9xbStrE9l/qbW1PlbQV8IKVmattrMeAHwE/krQCeKukPwFvAnaTZGAYYEkfr/X7m6RpwL9TrTi8rTbsXGAv4IZa2ahS3uo/C5gl6XvAfKptW2OAnSUtKM02pXpPLnym1xkRERGxOssKxBBUbqSnUH0b3u8vANm+l2pbzmfLzT/lzEJ/qwK9OYhqS9R2trtsbw9cQbWV6CnKryINo5wjWFmS9m19wy9pfWAX4D6qcxiTbG9fYtmO6iZ/v7YhzgFOKVvA6r4AfF7SlmXskVQJwtdV/XLVG2ttR1JtZ1qH6jD27mXOLuDt9LKNKSIiImJNkhWIoetSqm/j2w8Nj5A0vfb6O7a/AnyAavvPvZIeoTpcfEqDfp2MAa5sK7sC+BeqQ8Ub1cYS8D7by8supp0kPVDrd2L570RJp9fKX2P7b/X4gPPLVqh1gGvLnDcCZ3WI5RjgH4fEbc+h9utLtfKrJW0D3FpWMP4CvNf27yVtAnxc0jep3q/HqZKL/YGFthfWhroJ2EXS1rZ/3z5PRERExJpCT569jYhnU3d3t3t6egY7jIiIiIh+SZpmu7tTXbYwRUREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNJYGIiIiIiIjG8i9RRzxHZi1cTNep1w52GBFPs+CswwY7hIiIGEKyAhEREREREY0lgRiiJE2RdEhb2QmSvi6pS9JSSdNrj2NLm40lnS9pnqQ7JE2T9M+lrmM/SbeV5/dLeqhW11X67SnJHeJZXtrNkHS7pH1q88zucE0XSZpfG//WDm3eKGlxif1OSZ9qq/+ypIWS1qmVjZN0Xnm+jqSLJX1Hlc0kTSrvx7zyfLMO78fcUrdef/NFRERErMly0zN0XQoc3VZ2dCkHmGd7ZO0xqZRfCPwZ2NH2nsChwPNrYzytn+29bY8E/hOYXKtbUPqMAW4p/61bWtrtAXwCOLPBdZ1cG3+fXtrcXGLvBt4raS+okgPgCOB3wP7tnSQJ+AawHvAB2wa+DfzW9gjbI4D55T16yvsBvArYFnhPbbw+54uIiIhYEyWBGLouB0ZL2gCqb8uBl1DdyHckaQTwGuB02ysAbD9k+/MrG0S5KT8SGAccLGnDXppuSpW4rDK2HwemASNK0QHAbOB8np7MAHwZ2BI41vYKSS8H9gI+U2vzaaC7vFf1uZYDvwK2qRX3N19ERETEGicJxBBl+2GqG9pDS9HRVKsDLq9HtG1Fej2wKzCjlTz0olO/vuwLzLc9D5gCvLVWt1EZ4y6qb/U/06F/u4m1uS/pq6GkLYHXAnNK0RiqFZgrqZKr+najY6iShaNtP1HKdgGml+QA+EeiMJ3qvarPtSGwN3Bdrbiv+Vr9xkvqkdSzfMnifi49IiIiYvWXBGJoq29jqm9fgqdvRbq5vbOk08qN+oMD6ddmDHBZeX4ZT/0mvrWFaWeqRGdSWbHoS30L09he2rxe0h3A9cBZtudIWp8qebnK9qPAbcDBtT63A9tTrcC0CDBPVy8fIWk68DBwv+2ZAA3mA8D2Bba7bXcPG75ZP5ceERERsfrLz7gObVcBX5Q0CtjI9u39tJ8L7CFpHdsrbJ8BnCHpsZWZXNIw4F3A4ZJOo7rx3lLSJrb/Um9re6qkrYAXrMxcbW62Pbqt7FBgM2BWyVGGA0uA1u+m3kV1huMHkg6xPYdq5WLP1vtRrmkdYA/gztJvnu2RkrYGpkg63PbVDeaLiIiIWCNlBWIIs/0Y1bah7/DU1Yfe2t8L9ACfLTf/ra05/a0K9OYgqi1R29nusr09cAXwjvaGknYGhlF9k/9sGEN1MLrLdhewA9WZjOGtBrZvBT4EXCvppeX9uAM4vTbO6cDtpY5a398Dp1IdBm80X0RERMSaKAnE0Hcp1Tfml7WVt59l+Egp/wDVQeJ7JU0Dfg6c0qBfJ2Oo9v/XXUF13gCePAMxHZgMvK923mAnSQ/UHu8u5RPb5l+/vzeg3LQfQu3b/3LA+hbgbfW2tq8B/gu4rpyhOA54haR7Jc0DXlHKOrkKGC7pDU3ni4iIiFjT6MkztxHxbOru7nZPT89ghxERERHRL0nTbHd3qssKRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhobN3BDiBibTFr4WK6Tr22/4YRERExZCw467DBDuE5lxWIiIiIiIho7FlJICRtKWl6efxB0sLa6yWlTZek2bU+/yzpdklbSLpI0pGl/PmS7pD0/lrbEyX9VdJmvczfJWlpmW+upEmS1it1b5R0Ta3tWyT1SLpT0l2Szi7lE9rini5p8z7mmSHpVkk71er3k/SrMu5dksaX8s0lPSxJ5fXrJFnStuX1ZpIekbRO/b1Yic/hIknzS3y3S3pdrW5dSYskndnWZ4qkntrrbklTau/d4rb35KBSt7yt/NTaeHeX9+fXkkb2EusESeN6qXuNpJvKOHdJulDScEnjJJ3XIf7u8nyBpK3K8xdLukzSvPI38VNJr2jwd9h6/6ZLurW0GSdphaTda/1mS+rq/1OJiIiIGNqelQTC9sO2R9oeCXwDOLf2ekV7e0n/BPwbcLDtP9fKNwN+Blxg+7u1LmOAXwNH9BHGvDLfq4Btgfd0mHc34DzgvbZfCewG/LbW5B9xl8f/9TaP7T2Ai4FPlrFfDHwf+JDtnYH9gA9KOqyM8wfglWWMfYA7yn8BXgvcZvtp79VKOLm8D6cC36yVHwzcDbynlcjUvFDSW3oZ7+a29+TnpXxpW/lZtT5jy/vzdWDiQIKX9CLgh8Aptneies+uAzYZwBgCrgSm2B5hexeqz+lFbe06/R2eXLumfWrNHwBOG8i1RERERKwJBn0Lk6T3UN3cHmx7Ua1qY+C/ge/bPr/WfkSpO50qkeiT7eXAr4BtOlR/HDjD9l2l7RO2v76y1wJsCrRuPI8HLrJ9exl7UZnv1FL/S55MGPYBzm17fesziKOTm4CX116PAb4M3E+VsNRNpHp/V7WpdP4c+nI8cLHtqQCuXG77jwMY4wDg77a/0SqwPd32za3Xffwd9uYaYNf6ilNERETE2mCwE4jtqVYADrb9h7a6LwK32D63rXwMcClwM7CTpBf2NYGkDYG9qb61brcbMK2P7ifWtq/c2EubEaV+HvCxEjfArh3G7inlUCUIrYThZVTfsneX1/tQJRiNlO04L+mn2duAWaX9RsCBVDfBl/L0RGwqsEzSAR3GeX3bVqURpXyjtvKjOvQ9FLiq6XUV/X1GR9Xn5cn3cCBj9PV3OLE2/iW18hXAFygrTr2RNF7VFrme5UsW99U0IiIiYkgY7ATiIapvwJ+2vQi4AXh7hwThaOCysr3nR8C7exl7RLmhfBi43/bMlYivvoWp0800PLmFaQRwAnBBKRfgDu1bZb8E9pG0A7DA9l+pdttsDOxFtWrSiO232n6wl+qJ5X0YDxxXykYDN9peAlwBHCFpWFu/z9J5FaJ9C9O8Ut6+hWlyrc8lkh4ATgG+2vS6Gppcn5cqSRuovv4O61uYxrbVfR94bfkMO7J9ge1u293Dhnc8shMRERExpAx2ArEEeAvwIUntN2eXAecDP5W0CUA5tLoj8D+SFlAlE71tY2qdgXg51U3e4R3azKG6WV9Vrgb2r43d/m34XsBcANu/AbagWhmYWuqnAe8H5tt+bBXF1LoBfrPt1mHhMcBB5T2cBmxJtc3nH2zfAGzI07c3rYyxwA5UN9xfG2DfVfEZ9TdGX3+HvbL9BHAOVWIUERERsVYY7AQC2w9RbW35nKRD2uq+BPwCuFLS+lQ3vhNsd5XHS4BtJG3fx/i/p9rb/okO1ROBT0p6BYCqXz362DO4nP2A1jfyXwPGtX51SNKWwOeptr20TAU+ypMJxFSqVYxVff7hHyRtWuJ8aet9pDpn0CkRO4Pq3MYzZvvvVCsar5X0yv7a15wHvE/S3q0CSe8th9SbugHYQNI/18Z4taQ31OLr9e+wHxcBBwEvGECfiIiIiCFr0BMIANvzgcOB79RvFEvdKcDvgO9RrThc2db9ylLel6uA4ZJe3zb2TKob9ksl3QnMBrauNamfgZjey890ts5AzAA+B3ygjP174L3AtyTdRZUUfMf2T2p9fwlsx5PbbqZSnYdoTyC+KemB8pjaVtf0DETLO4EbbC+rlf0YOFzSBvWGtn9Ktb2nrv0MROsnZtvPQJzV1g/bS6m+sT+pYayUw9JHA2er+hnXO4HXA48OYAxT/WLXm8vPuM4BJgAPtrXr9Hc4se261m/r8zfgK0CfZ3EiIiIi1hSq7q0iBpekCVRnQS4a5FCeNd3d3e7pWZkjGhERERHPLUnTbHf6cZrVYwUiIiIiIiKGhnUHO4CIYgrQ6R/qi4iIiIjVSBKIWC3YnjLYMURERERE/7KFKSIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisfwKU8RzZNbCxXSdeu1ghxExpCw467DBDiEiItpkBSIiIiIiIhpbrRMISVtKml4ef5C0sPZ6fUlHSLKknWt91pH0FUmzJc2S9GtJO0i6rfS7X9JDtXG+L+lfav33ljRT0rptsYyWdIekGZLmSvpgKZ8g6aQOsT9W/tslaWnpe6ekX0l6X63duLZ4pkvapdZveplvkqT1Sp/hki4p1zdb0i2SNh7ge3ts6TunjH9SKb9I0pF9XMvsWvlrJN0k6W5Jd0m6sMQ2TtJ5tc/jYknfUWVBibt1rV+pzbtQ0gbl9VaSFvQS+/LSd7akH0oaXqvr9DfRVcr+rVZ2nqRxtbnn12K6dWU/m4iIiIg13Wq9hcn2w8BIqG7Ugcdsn92qlzQGuAU4GphQio8CXgLsbnuFpG2Bx23vXfqMA7ptf7i8fhEwVdLlwMPAecC/2n6iNs96wAXAa2w/UG5yuwZwKfNs71nGehnwI0nr2P5uqZ/ciqc2Z1fpN1LSMOB/gPcAlwAfBf5o+1Wl7U7A35sGI+ktwAnAwbYflLQh8E8DuJ7W+/ZD4GjbUyUJeBewSa2NgG8A6wHvt+2qiANsL+ow7HLg/wPO72f6pbZbfxeXAB8CvljqOv1NAPwJ+Kikb9r+W4cxT7Z9eYfygX42EREREWu01XoFoi/lG/d9geOobhZbtgZ+b3sFgO0HbP+5t3Fs/xE4G/gC1Y3oTNu3tDXbhCrZerj0WWb77pWJ2/ZvgY8BHxlAn+XAr4BtStHWwMJa/d22lw0gjE8AJ9l+sPT/q+1vDaA/wPHAxbanljFs+/LyfrZ8GdgSOLb1efTjS8CJ7as//bgZeDn0+TcB8BDwC+B9rEIdPpuIiIiINdqQTSCAdwDX2b4HeETSqFL+A+BtZXvJOZL2bDDWN4BdgJOBj7dX2n4EuBq4T9KlksZKeibv3e3AzrXXR7Vtk9mo3risEOwNXFeKvgOcImmqpM9K2rHTJGVLUXeHqt2AaX3EN7EeTy9t+hvjGGAvqhWKJ9rqbqyNf2Kt/H6q1YNGqyEl0XgLMKsU9fY30XIW8O9l1aBd/ZrrKwkD/WzaYxwvqUdSz/Ili5tcVkRERMRqbSgnEGOAy8rzy8prbD8A7ET1LfsK4BeSDuxroPLt+DeB/y7bpjq1+QBwINW3zSdR3cSvLLW9nmx7ZO2xtJSPKDfwDwP3255ZYpkOvAyYCDwf+LWkV3aK2XbPSsR3cj2elegPVZK0PfCaDnUH1MY/t63uc1SJXF9/mxuV96WHKun4dinv+DfRYns+1ed3TIcx69c8tlY+oM+mne0LbHfb7h42fLM+LikiIiJiaFitz0D0RtKWwJuA3SQZGAZY0sfLVpplwH8D/y3pj1TfTP+in2FXlEevbM8CZkn6HjAfGLeSl7AncGeDdq199lsDUyQdbvvqEstjwI+ozlOsAN7acEyAOVSrAzcMPPSnjfHjXurvAv4T+IGkQ2zPaTKo7XvLjfl7+mi2tD2x6etvoq3v54DLgZuaxNOHXj+biIiIiDXZUF2BOBKYZHt72122t6O6od9P0ihJL4HqF4CA3YH7nslkkjaW9MZa0ciVHbMcwD0b+GrTPrZ/D5xKtaqCpH0lbVGer0+1/Wog8ZwJfEHSi8sYG0hqfCajOA94n6S9WwWS3tsas8R9K9W5kmslvXQAY59BtcozEL3+TdQb2b4LmAuMHuD4HbV/NhERERFruiG5AkG1NeWstrIrqLam/Bj4VvmlJKi2rJz3DOcT8HFJ3wSWAo/z1NWH0yWd0Hphe9u2/iMk3QFsCPwF+GrtF5ig2mdfv9H9V+DBtjGuAiZIej2wA3B++ZWjdYBrqa7/qUFLFwLfaN/GZPun5VeUfl7GMAPckmX7j5KOBs6W9EKq1ZubqFZF6u2ukfQC4LoSO1RnIJaX5zNtH9vWZ46k24H2Mwx96etv4vNt5WcAd7SVTZR0eu11a+vVgD4b2zf3FuCrttmMnvyjWBERETHEyfZgxxCxVuju7nZPz8ocSYmIiIh4bkmaZrvTj/EM2S1MERERERExCJJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNDdV/iTpiyJm1cDFdp1472GFEPGsW5F9aj4hYK2QFYg0maUtJ08vjD5IW1l6vL+kISZa0c63POpK+Imm2pFmSfi1pB0m3lX73S3qoNs73Jf1Lrf/ekmZKWrctlimS7q71O7KUP9ZH/DMkXVp7/bXSd66kpfWxJF0kaX55fZekT3WYe0a5npG1ugXlOltjfaVWt66kRZLO7OVaZpa5zpO0+cA/oYiIiIihJysQazDbDwMjASRNAB6zfXarXtIY4BbgaGBCKT4KeAmwu+0VkrYFHre9d+kzDui2/eHy+kXAVEmXAw8D5wH/avuJDiGNtd3TJHZJr6RKcPeX9Dzbj9s+vtR1AdfYricCo4GTbV8uaUNgrqRJtufX55b0fmAi8ObadAfYXtQhjIOBu4H3SPqkbbdfi6T1gTOBHwNvaHJtEREREUNZViDWUpI2BvYFjqNKIFq2Bn5vewWA7Qds/7m3cWz/ETgb+ALwIWCm7VtWQYjHAN8DrgcOH2DfDct/H+9QNxXYpuE4Y4AvA/cDr+3UwPbfgI8DL5W0xwDjjIiIiBhykkCsvd4BXGf7HuARSaNK+Q+At5XtPOdI2rPBWN8AdgFOprqZ7s0lta1CW/Yz5lHAZOBSqhv5JiZKmg48AFxm+08d2hwKXNVWdmMtrhMBJG0EHAhc018MtpcDM4Cde2sTERERsabIFqa11xjgS+X5ZeX17bYfkLQT8Kby+IWkd9v+RW8Dla1O36Ta2vRwH3M22sIk6dXAQ7bvk/QA8B1JW/S1ElK0tjBtXOLex/atpe4SSc8DhgGj2vp12sI0GrjR9hJJVwD/IenEkix0DLuXaxkPjAcYtukL+gk/IiIiYvWXFYi1UPn2/03AhZIWUK0cHCVJALaX2f5v2ycDn6NarejPivJYFcYAO5fY5gGbAu9q2tn2Y8AUYL9a8VhgB+D7wNcaxnBQiWEasCVwQKeGkoYBrwLu7BDLBba7bXcPG75Z00uIiIiIWG0lgVg7HQlMsr297S7b2wHzgf0kjZL0Eqh+kQnYHbjvuQqszPluqkPcXba7gLfTfBsT5Reg9qZKPv7B9t+B04HXlkPavfXflCr5eGkthuM7xSBpPapD1L+zPbNpjBERERFDVRKItdMY4Mq2siuoDi6/EPiJpNnATOAJql9WerYMl/RA6wGcACy0vbDW5iZgF0lb9zNW6wzETGAW8KP2BraXAucAJ9WK62cgJgHvBG6wvazW5sfA4ZI2KK8vkTQTmA08jyrJiYiIiFjj6am/TBkRz5bu7m739DT6FduIiIiIQSVpmu3uTnVZgYiIiIiIiMaSQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxtYd7AAi1hazFi6m69RrBzuMiIiIGMIWnHXYYIeQFYh4KklbSppeHn+QtLD2en1JR0iypJ1rfbpK2b/Vys6TNK48v0jSfEkzJN0jaZKkbWptNytl88pjkqTNavW7Srqh9P2NpP+QpFI3TqrGFrYAACAASURBVNJDJb67JJ1Y6zdB0kkdrnFC7brmShpTq5Ok08s890i6UdKupe620uf+2pzTy/UvkLTVKvsgIiIiIlZTSSDiKWw/bHuk7ZHAN4BzW69t/w0YA9wCHN3W9U/ARyWt38vQJ9veA9gJuAO4sdb228BvbY+wPQKYD1wIIGkj4GrgLNuvAPYA9gH+tTb25BLvvsBpkrZrcKnnlj5vB74pab1SfnwZf48y35nA1ZI2tL136fOfrTnLY0GD+SIiIiLWCEkgojFJG1PdpB/H0xOIh4BfAO/rawxXzgX+ALxF0suBvYDP1Jp9GuiWNAI4Bvil7etL/yXAh4FTO4z9MHAvsHXTa7L9G2AJsEUpOgX4tzIPZd5bgbFNx4yIiIhYkyWBiIF4B3Cd7XuARySNaqs/C/h3ScMajHU7sDOwCzDd9vJWRXk+Hdi1PKbVO9qeB2wsadN6uaSXAhsCM5teULmG39j+UxnveWX8up4SR0RERMRaLwlEDMQY4LLy/LLy+h9szwd+RbVq0B/V/ute6t1HPbXyoyTNAX4LfNn2XxvMf6Kku4HbgAkNYu0thr47SuMl9UjqWb5k8coMEREREbFaSQIRjUjaEngTcKGkBcDJVDfuamv6OaptQP39be0J3AnMAfaU9I/25fketfrutlheBjxm+y+laLLtXYHXA+dIenGDSzrX9k7AUcCkcsbhUeDxMn7dKGBugzGfxvYFtrttdw8bvln/HSIiIiJWc0kgoqkjgUm2t7fdZXs7qsPO+9Ub2b6L6mZ7dKdByq8cfYTqnMJ1tu+lOlR9eq3Z6cDtpe4SYD9JB5X+GwFfAb7QPrbtqcD3gI82vSjbP6LaotQ6uzER+EqZhzLvfsD3m44ZERERsSZLAhFNjQGubCu7gs7blc4Atm0rmyhpBnAP8GrggPKrTlAdyn6FpHslzQNeUcqwvZTql5JOL1uOZgG/Bs7rJc7PA++XtMkAru3TwMfKysdXy/izynz/Aby9xBERERGx1pO9Ulu7I2KAuru73dPTM9hhRERERPRL0jTb3Z3qsgIRERERERGNJYGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY2tO9gBRKwtZi1cTNep1w52GBEREbGaWXDWYYMdwoBkBSIakXSapDmSZkqaLmnvUj5F0t2SZkj6paSdauXd5fkCSVfUxjpS0kVt4/9Y0tQO8x4raXaZe66kk0r5RZKObGv7WC+xW9I5tdcnSZrQ1maGpEs79F1X0iJJZ7aVT5HUU3vdLWlKp/kjIiIi1iRJIKJfkl4HjAZG2d4dOAj4Xa3JWNt7ABcDE3sZplvSrr2MvzkwCthc0g618rcAJwAH2961tFm8EpewDHinpK16mf+VVP8v7C/peW3VBwN3A++RpLa6F5YYIyIiItYaSSCiia2BRbaXAdheZPvBDu1uAl7eyxhnA5/spe5dwE+Ay4Cja+WfAE5qzWX7r7a/tRLxPwFcAJzYS/0xwPeA64HD2+rGAF8G7gde21Y3ETh9JeKJiIiIGLKSQEQT1wPbSbpH0tclvaGXdm8DZvVS9wNglKROCcYY4NLyGFMr3w2Y1kdcE8t2qumSpvd9CXwNGCtpsw51RwGT2+eXtBFwIHBNh9gApgLLJB3Qz9wRERERa4wkENEv248BewHjgYeAyZLG1ZpcUm7g9wVO6mWY5VTf2H+iXijpRVSrFrfYvgd4QtJuDUM72fbI1qOfa3gUmAR8pG3+VwMP2b4P+AVVkrNFqR4N3Gh7CXAFcISkYW1Df5Y+ViEkjZfUI6ln+ZKV2X0VERERsXpJAhGN2F5ue4rtTwEfptp21DK23MS/w/bvehkCqm1C+wMvrZUdBWwBzJe0AOjiyW1Mc6gSl1XlS8BxQP2cwxhg5zL3PGBTnry2McBBpW4asCXwlNUG2zcAG/L07U2t+gtsd9vuHja80+JHRERExNCSBCL6JWknSTvWikYC9w10HNt/B86lOhjdMgY41HaX7S6qhKGVQJwJfEHSi0scG0h6ygrCAOd/hGor1XFlvHWAdwO71+Z/OzBG0qbAfsBLa3XH8/RtTABnAB9f2bgiIiIihpIkENHExsDF5WdUZwK7ABNWcqxvU/79EUldVKsR/9uqtD0feFTS3rZ/SnV24eeS5lCtAjzTf7vkHKD1a0z7AwttL6zV30R1fccDN7QOjhc/Bg6XtEF9wBLnQ88wroiIiIghQbYHO4aItUJ3d7d7enr6bxgRERExyCRNs93dqS4rEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHR2LqDHUDE2mLWwsV0nXrtYIcRscosOOuwwQ4hIiIGQVYghghJp0maI2mmpOmS9i7lUyTdLWmGpF9K2qlW3l2ebyzpm5LmlTFukrS3pFskvaU2x3skXddh7o79S91jbW3HSTqvPJ8g6aRa3UmS7pI0u8R7bIdYuyT9RtIhkt4oaXG53tbjoNLOks5pG3tCh9jHSXqo9J0j6XJJw+vxSfpaqZ8raWltriMlXSRpfq3s1tL3RZKuKdcxV9JPV+qDjYiIiBhisgIxBEh6HTAaGGV7maStgPVrTcba7pE0HpgIHN42xIXAfGBH2yskvQx4JfAh4IeSbgSGAWcAh3YIobf+A7mGDwFvBl5j+1FJmwHvaGuzLfAz4N9t/0zSG4GbbY/uMOQy4J2SzrS9qJ/pJ9v+cJnj+8BRwHdblbaPL3VdwDW2R9ZiGg2cbPvytjE/DfyP7S+Xdrv3E0NERETEGiEJxNCwNbDI9jKAPm6YbwJOqBdIGgHsTZVkrCj9fwv8ttT/BDgFeB4wyfa8gfQfgE8CB9h+tIyxGLi4Vv9iYBJwuu2rG4z3BHABcCJwWpMAJK1LdZ1/HkDcvdkauL71wvbMVTBmRERExGovW5iGhuuB7STdI+nrkt7QS7u3AbPaynYFptte3kuf/wKOAd4CfKFDfX/9N6pvMaL6Zv4pJG0CbNKenLSZBJxn+4dt5a9v28I0olb3NWBsWc3oy1EltoXA84Gf9NO+3cTa/JfU5v62pBvL9rKXDHDMiIiIiCEpCcQQYPsxYC9gPPAQMFnSuFqTS8oN8r7ASU8foc+xHwcmA99rrXAM0FLbI1sP4D87tBHgfsb5OfBPrfMJNTfXx68nIWU1YxLwkX7GnlxiezFVgnVyP+3bnVybf2yZ+2fAy4BvATsDd0h6QXtHSeMl9UjqWb5k8QCnjYiIiFj9JIEYImwvtz3F9qeADwPvqlWPLTe377D9u7auc4A9JPX1Wa8oj06a9O8v9keBx8vZid58AbiN6kzGQLbWfQk4jmprUn9xmGr1Yf8BjN/XeI/Y/r7tfwJ+3Wlc2xfY7rbdPWx4fwslEREREau/JBBDgKSdJO1YKxoJ3Nekb/nGvgf4L0kq4+0o6e3PRf+aM4GvSdq0jLFpOfRddyLwKNXWIDWM7xHgB1RJRBP7AX1tpWpE0ptqv+a0CTACuP+ZjhsRERGxuksCMTRsDFxcfi50JrALMGEA/T9AtX3nXkmzqLbdPPgc9gc4H7gR+LWk2cD/A5bUG5QVgvdRHVBuncdoPwNxZIexzwG26mPuo0rfmcCewGcGGPvEthjWp9pS1lPGnApcaPvXAxw3IiIiYshRdc8WEc+27u5u9/T0DHYYEREREf2SNM12d6e6rEBERERERERjSSAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGPrDnYAEWuLWQsX03XqtYMdRsSQs+CswwY7hIiIqMkKRDQi6TRJcyTNlDRd0t6lfIqk7lq7Lkmzy/M3Slos6Q5Jd0k6u9ZunKTzyvMJkizp5bX6E0tZd3m9QNIsSTMkXS/pxR1iHF3mmiFprqQPlrinl8fy2vOPlHkXltdzJY2pjXWRpCNr13h3GfeXknbqbb5V/b5HRERErG6SQES/JL0OGA2Msr07cBDwu4bdb7a9J7AnMFrSvr20mwUcXXt9JDC3rc0BtvcAeoBPtsW4HnAB8LbSZk9giu0zbI+0PRJY2npu+yul67ml7u3AN8s4nYwt414MTOxtvn7ei4iIiIghLwlENLE1sMj2MgDbi2w/OJABbC8FpgPb9NLkKqqbeCS9DFgMPNRL25uAl7eVbUK1Je/hMt8y23cPIL7fAEuALfpp2pr7Gc0XERERMVQlgYgmrge2k3SPpK9LekNb/SWtrUHATzsNIGkLYEeqG/BOHgV+J2k3YAwwuY94RlOtWPyD7UeAq4H7JF0qaaykxn/fkkYBv7H9p36avg2Y9Uzni4iIiBiqcsMT/bL9GLAXMJ5qVWCypHG1JmNr24Te2tb99ZJmAn8ArrH9hz6muoxqG9M7gCs71N9YkpRNgTM7xPkB4EDgV8BJwHcaXN6Jku4GbgMm9NHukjL3vmXsRvNJGi+pR1LP8iWLG4QTERERsXrLrzBFI7aXU+3xnyJpFvA+4KIGXW+2PVrSK4BbJF1pe3ovbX8CTAR6bD8qqb3+ANuL+olzFjBL0veA+cC4fuI71/bZkt4JTJI0wvZfO7Qba7tnoPPZvoDqrAQbbL2j+4klIiIiYrWXFYjol6SdJO1YKxoJ3DeQMWzfQ7VqcEofbZaW+jNWIsaNJb1xZWO0/SOqw9nvey7mi4iIiBiqsgIRTWwMfFXS5sATwL1U25kG6hvASZJ26K2B7ctWLkQEfFzSN4GlwOP0v/rQ7tPA9yV96zmaLyIiImLIkZ1dFRHPhe7ubvf0PG0XVERERMRqR9I0292d6rKFKSIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaW3ewA4hYW8xauJiuU68d7DAiYhVacNZhgx1CRMRzLisQ0Zik0yTNkTRT0nRJe5fyKZK6a+26JM1u6/tlSQslrVMrGyfpvLZ2/xhL0gJJW3WIY4GkWZJmSLpe0otrdXtKsqRD2vpY0jm11ydJmlCeTyixTa89Npf0RkmL28oPKn2Wl9ezJf1E0uYr9aZGREREDDFJIKIRSa8DRgOjbO8OHAT8rmHfdYAjSvv9V1FIB9jeA+gBPlkrHwPcUv5btwx4Z6eEpDjX9sja4/9K+c1t5T8v5UvL692AR4DjV81lRURERKzekkBEU1sDi2wvA7C9yPaDDfseAMwGzufpN/bP1E3AywEkCTgSGAccLGnDWrsngAuAE1fx/ABTgW2ehXEjIiIiVjtJIKKp64HtJN0j6euS3tBWf0lrmw/w07a6McClwJXAaEnr1eqOqm8RAroZmNHArPJ8X2C+7XnAFOCtbW2/BoyVtFmHcU6sxXFjrfz1bVuYRtQ7SRoGHAhcPcC4IyIiIoakJBDRiO3HgL2A8cBDwGRJ42pNxra2+VC7cZe0fnl9le1HgduAg2v9Jte3CFFtSWrixpJwbAqcWcrGAJeV55fRttpR5p8EfKTDePUtTAfUytu3MM0r5RuV+R8Gng/8T6cgJY2X1COpZ/mSxQ0vLSIiImL1lV9hisZsL6f6Zn+KpFnA+4CL+ul2KLAZMKvaYcRwYAnwTH+O6ADbi1ovykrAu4DDJZ0GCNhS0ia2/1Lr9yXgduC7z3D+pbZHltWMa6jOQHylvZHtC6i2TrHB1jv6Gc4ZERERMeiyAhGNSNpJ0o61opHAfQ26jgE+YLvLdhewA9X5hOGrOMSDgBm2tytzbQ9cAbyj3sj2I8APgONWxaS2F1OtaJzUtjUrIiIiYo2UBCKa2hi4WNJcSTOBXYAJfXUoScIh1FYbbD9O9StJb1vF8Y2hOmNRdwVwTIe25wDtv8Z0YttZh65S3n4G4sj2wWzfAcwAjn5GVxARERExBMjOroqI50J3d7d7epoe8YiIiIgYPJKm2e744zZZgYiIiIiIiMaSQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxtYd7AAi1hazFi6m69RrBzuMiCgWnHXYYIcQETEkZQViLSLpNElzJM2UNF3S3rW6F0j6u6QPtvVZIGlW6fP/JG3f33iS1pf0JUnzJP1G0o8lbVvrZ0nn1F6fJGlCh3jHSXpI0h1lnJ9J2qetzbqSFkk6s4/rfq2k20qMd7bPVeKb2kvfGZIu7VD+MUl3lfdmhqQvSlqvtxgiIiIi1hRJINYSkl4HjAZG2d4dOAj4Xa3Ju4H/BcZ06H5A6TMFOL3BeJ8DNgFeYXtH4CrgR5JU6pcB75S0VYPQJ9ves4xzVhnnlbX6g4G7gffUxm93MTDe9khgN+AHrQpJmwOjgM0l7VDvVOZZB9hf0vNq5R8q877W9quAVwN/AjZqcD0RERERQ1oSiLXH1sAi28sAbC+y/WCtfgzw78C2krbpZYypQKuu43iShgPvB060vbzUfZcqaXhT6fsEcAFw4kAuwPaNpd/4tri/DNwPvLaXri8Efl/GWG57bq3uXcBPgMuAo9v6HQN8D7geOLxWfhrwL7b/r4z5N9tn2X50INcTERERMRQlgVh7XA9sJ+keSV+X9IZWhaTtgBfb/hXVt/NH9TLGoVSrCX2N93Lg/g430z3ArrXXXwPGStpsgNdxO7BziXsj4EDgGuBSOq+eAJwL3C3pSkkflLRhrW5M6dup/1HA5HqdpE2AjW3PbxKspPGSeiT1LF+yuEmXiIiIiNVaEoi1hO3HgL2ovr1/CJgsaVypPpont/VcxtNvpG+U9CeqbUrf72c8Ae4QwlPKS4IxCfjIAC+lvk1pNHCj7SXAFcARkoa1d7D9aaCbKuk5BrgOQNKLqBKeW2zfAzwhabdS92rgIdv3Ab8ARknaov06JB1SzlYsaD+fUea+wHa37e5hwweaK0VERESsfpJArEXK9p0ptj8FfJhq+w5UCcM4SQuAq4E9JO1Y63oAsD0wB/h0P+PdC2xfvqmvGwXMbSv7EnAc8Dya2xO4sxb3QSXuacCWJdansT3P9vlUKxZ7SNqSaoVhC2B+GaOLJ7cxjQF2LuXzgE2Bd5XE5/HWeQnbPytnK2YD6w/gOiIiIiKGpCQQawlJO7UlBSOB+yTtBDzP9ja2u2x3AWfSdh7A9lLgBOBYSc/vbTzbj1MdWv5iazVA0rHAcOCGtjEfoVr5OK7hNbyBasXjW5I2BfYDXlqL+3g6bGOSdFjtgPWOwHLg/0rbQ2v99wKOlrQO1aHy3Wt1b6+NfSZwfjmATRm7vi0qIiIiYo2Vfwdi7bEx8NVy0/sE1UrBeKqVgyvb2l5BtZXpM/VC278vP2l6PPDTXsYD+ARwNnCPpBXAXcARtjttbTqnxNCboyTtR5WAzKdaBbizbJe6oXWIu/gx8AVJG7SV/xNwrqQlJdaxwHbAS6l+eap1ffMlPQqcDCy0vbA2xk3ALpK2Bs4v8dwmaRnwGPBL4I4+riMiIiJijaDO93QRsap1d3e7p6dnsMOIiIiI6Jekaba7O9VlC1NERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorEkEBEREfH/s3fnUZaV9b3/3x8bGZpZnJCpFBEUxBZLTRwIiAOKA1xBuiRRbsgl3ut14ApKDL9c4kgEQ4hyTYgD4NVuB0AQFDUKChGVam3oxgGEbgmdQRB/TaBRofneP84usjmcqtpNd1FDv19rnVVnP9P+7kOz1v6e53n2kaTOTCAkSZIkdWYCIUmSJKmzTaY7AGljsWzVaoZOvGS6w5AkadZYecoh0x2CBnAGQhulJGuTLE2yPMmXk2zXlA8lWd5q95wk30nysyQ/TfLxJPOTHJ3k1maMsdfTpu+KJEmSHh4mENpY3V1VC6pqH+B24M39DZI8DvgC8K6q2hN4KnApsHXT5HPNGGOvHz9cwUuSJE0XlzBJcBWw74DyNwPnVNVVAFVVwBcBkjx80UmSJM0gzkBoo5ZkHnAQcNGA6n2AJRN0P7JvCdMWA8Y/NsloktG1a1ZvoKglSZKmjwmENlZbJFkK/Ap4FPCNhzBG/xKmu/sbVNVZVTVcVcPz5m+7vjFLkiRNOxMIbazurqoFwG7ApgzYAwFcBzzrYY1KkiRphjOB0EatqlYDbwWOT/LIvuqPAm9M8tyxgiR/mOTxD2eMkiRJM4kJhDZ6VfUj4BpgYV/5vzdlpzWPcf0J8ELgjqZJ/x6I5z2sgUuSJE2D9B4sI2mqDQ8P1+jo6HSHIUmSNKkkS6pqeFCdMxCSJEmSOjOBkCRJktSZCYQkSZKkzkwgJEmSJHVmAiFJkiSpMxMISZIkSZ2ZQEiSJEnqzARCkiRJUmcmEJIkSZI622S6A5A2FstWrWboxEumOwxJ0kZo5SmHTHcImkOcgdCMkWRtkqVJlif5cpLt+uqPS/KbJNu2yuYn+UySZU2/K5Ns1dRVkk+32m6S5NYkF/eNe2GSq/rKTk5y/DhxHtaMvVerbCjJ8vX7BCRJkmY+EwjNJHdX1YKq2ge4HXhzX/0IcDVwWKvsbcC/V9XTm37HAPc0dXcB+yTZojl+CbCqPWCTpOwHbJfkiR3jHAGuBBZ2bC9JkjRnmEBoproK2GnsIMnuwFbASfRu4MfsSCspqKqfVdVvW/VfBcbmbUeARX3neS3wZWAxHRKCZnbj+fQSFRMISZK00TGB0IyTZB5wEHBRq3js5v8KYM8kj23KPwm8K8lVSd6XZI++4RYDC5NsDuwLfL+vfmzcRTwwMRnPocClVXU9cHuS/Sa5lmOTjCYZXbtmdYfhJUmSZjYTCM0kWyRZCvwKeBTwjVbdQmBxVd0HnA8cAVBVS4EnAac2fa5O8tSxTlV1LTBELzn4SvtkSR4HPBm4skkI7k2yzyQxjtBLSmj+Tph0VNVZVTVcVcPz5m87UVNJkqRZwacwaSa5u6oWNJukL6a3B+Jvk+wL7AF8IwnApsBNwJkAVXUnvaTi/CT3Aa8AftIa9yLgNOAAYIdW+ZHA9sCKZtxt6CUqJw0KLskOwIvo7asoYB5QSd653lcuSZI0SzgDoRmnqlYDbwWOT/JIet/yn1xVQ83rCcBOSXZL8vwk2wMk2RR4GvCLviE/Cbynqpb1lY8AB4+NCzyLifc1HA6cW1W7NX12AVYAL1i/K5YkSZo9TCA0I1XVj4Br6N3QLwQu6GtyQVO+O/DtJMuAHwGjwHl9Y91SVWe0y5IMAbsC32u1WwHckeS5TdFJSW4Ze9FLOPrjOA94/UO8TEmSpFknVTXdMUgbheHh4RodHZ3uMCRJkiaVZElVDQ+qcwZCkiRJUmcmEJIkSZI6M4GQJEmS1JkJhCRJkqTOTCAkSZIkdWYCIUmSJKkzEwhJkiRJnZlASJIkSerMBEKSJElSZ5tMdwDSxmLZqtUMnXjJdIchqYOVpxwy3SFI0ozlDMQclWRtkqVJlif5QpL5rbrDklSSvVplQ03ZW1plH01ydPP+7CQrmjGXJvluU350kltb5UuTPK0Z7+7m+MdJzk3yyAFxrkiyZ1/Z3yR5Z5IDklzcOs99SfZttVueZKh5vzLJsub14yTvS7JZ37jHJflNkm1bZfefo6/tpk0cNya5IcmFSXZu1e/clN3QtDkjyaYd/tNIkiTNaiYQc9fdVbWgqvYBfge8qVU3AlwJLOzr80vgbRPcCJ/QjLmgqp7XKv9cq3xBVf24Kb+xqhYATwd2Bl43YMzF7TiSPAI4HPjcgLa3AH8+TmwAB1bV04HnAE8CzuqrHwGuBg6bYIwxHwC2Bp5SVXsAXwLOTwM4H/hSU/cUYCvg/R3GlSRJmtVMIDYOVwBPBkiyFfB84BgenEDcCnwTeOOGPHlVrQV+AOw0oHpRXxz7Ayur6hcD2l4M7N0/YzHgfHfSS5gOTfIogCS707vJP4leIjGuZrbmvwLHNbFTVZ8Cfgu8qHn9pikbu77jgD9uz/RIkiTNRSYQc1ySTYCXA8uaokOBS6vqeuD2JPv1dTkFeEeSeQOGO7W1TOkzrfIj+5YwbdEXw+bAc4FL+wesqmuB+5I8oylaSC+pGOQ+4EPAu8e94P8c9w5gBbBHUzTSjHsFsGeSx07Q/cnAzc0YbaPA3s1ryYDz3dz0vV+SY5OMJhldu2b1ZGFLkiTNeCYQc9cWSZbSu+m9GfhEUz5Cb9kQzd8HfBtfVSvozRa8fsCY7SVMR7XK+5cw3d2U797E8Ct6N+TXjhPrImBhk+y8BvjCBNf1WeD3kjxxgjZj0nq/EFhcVffRW350xCT9aoLyyervV1VnVdVwVQ3Pm7/tgC6SJEmzi09hmrvubvYf3C/JDvSW3+yTpIB5QCV5Z1/fDwBfBL6znjHcWFULkuwIXJ7k1VV10YB2i4CvA98Grq2qX443YFXdm+TDwLsmOnGSrYEh4Ppm4/UewDd62xfYFLgJOHOc7j8HdkuydVX9R6t8P+DL9BKF1/adbxtgF+DGieKSJEma7ZyB2LgcDpxbVbtV1VBV7UJvmc8L2o2q6qfAj4FXboiTVtW/AicCfzZO/Y30ZilOYfzlS21nAy8GHjOostnn8X/obXL+Nb1ZlpObax6qqicAOyXZbZx47gLOAf56bClXkjcA84Fv0dsnMr8po2nzYeDsqlrTIX5JkqRZywRi4zICXNBXdh6Dlyu9n96Tk9pO7dvrMPa0pv49EM/jwb5E76b7hePEtgjYa0B8D1JVvwP+Fujfx3BZkuX0lmDdDPxpU75wwLgX8J+btw9Kckvr9fv0kp3f0JvBFa710QAAIABJREFUuIHekqfDqkHvSU5HNHXXN20n3ZshSZI026V3LyRpqg0PD9fo6Oh0hyFJkjSpJEuqanhQnTMQkiRJkjozgZAkSZLUmQmEJEmSpM5MICRJkiR1ZgIhSZIkqTMTCEmSJEmdmUBIkiRJ6swEQpIkSVJnJhCSJEmSOttkugOQNhbLVq1m6MRLpjsMSZK0Aaw85ZDpDmHaOAOhCSXZOcmFSW5IcmOSM5Js2tQdkKSSvKrV/uIkBzTvL08y3LzfNsm5zRg3Nu+3beqGmnHe0hrno0mOHhDPyUmOb95vnuQbSf53M8byCdqeneTwAeM9JclXkvw8yU+SfD7J45pru7iv7QPGSPKYJPck+dN1/2QlSZJmJxMIjStJgPOBL1XVHsBTgK2A97ea3QL8eYfhPgHcVFW7V9XuwArg4636XwJvG0tOOsS2KXAesKSq/rJLnwFjbA5cAnysqp5cVU8FPgY8puMQRwDfA0YeyvklSZJmIxMITeRFwG+q6lMAVbUWOA744yTzmzbXAKuTvGS8QZI8GXgW8N5W8XuA4SS7N8e3At8E3tghrk2AxcANVXXiOlxPv9cDV1XVl8cKquqyqlo+QZ+2EeAdwM5JdlqPOCRJkmYNEwhNZG9gSbugqu4Abgae3Cp+H3DSBOM8DVjaJCBj46wFljbnGHMK8I4k8yaJ653AvVX19kmvYGL70Hd9fV6YZOnYC3j1WEWSXYDHV9UPgM8DRw4aIMmxSUaTjK5ds3o9w5UkSZp+JhCaSICarLyqrgBI8sL1HGcF8AN6MwMTuRL4/SRPaZUNGn+i8i6uqKoFYy/golbdQnqJA/RmQwYuY6qqs6pquKqG583fdj1CkSRJmhlMIDSR64DhdkGSbYBdgBv72r6f8fdCXAc8M8n9/96a988AftLX9gPAu5j43+Z3gLcDX03yhKbsV8D2fe0eBdw2wTjX0Vta9VCMAEcnWUkvsXhGkj0e4liSJEmzhgmEJvJNYH6SNwA0S4s+DJxdVWvaDavq6/Ru4J/RP0hV/Rz4EQ9c5nQS8MOmrt32p8CPgVdOFFhVnQecClyaZLuquhP41yQHNbE+CjiY3mzFeD4LPC/J/c9hS3JwkqdPdO4kewJbVtVOVTVUVUPAB+nNSkiSJM1pJhAaV1UVcBhwRJIbgOuB3wDvHqfL+4Gdx6k7BnhK87jUG+k90emYhzBOO76/o/eUqIuaJyq9ATip2a/wLeAvq6o9U/L3SW5pXldV1d30EpW3NI+p/TFwNL0nQk1kBLigr+w8fBqTJEnaCKR3jyhpqg0PD9fo6Oh0hyFJkjSpJEuqanhQnTMQkiRJkjozgZAkSZLUmQmEJEmSpM5MICRJkiR1ZgIhSZIkqTMTCEmSJEmdmUBIkiRJ6swEQpIkSVJnJhCSJEmSOttkugOQNhbLVq1m6MRLpjsMSZI0A6085ZDpDqEzZyA05yWpJB9uHR+f5OS+NtckWTSg7yZJbkvywb7yy5OMto6Hk1y+4aOXJEmaWUwgtDH4LfBfkjx6UGWSp9L7f2H/JFv2Vb8U+BnwuiTpq3tskpdv8GglSZJmMBMIbQzuBc4Cjhun/vXAp4GvA6/uqxsBzgBuBn6vr+5U4KQNF6YkSdLMZwKhjcWZwFFJth1QdyTwOWARvYQBgCRbAAcBF/fXNa4CfpvkwPFOmuTYJKNJRteuWb2elyBJkjT9TCC0UaiqO4Bzgbe2y5M8G7i1qn4BfBPYL8n2TfUrgcuqag1wHnBYknl9Q7+PCWYhquqsqhququF58wflLpIkSbOLCYQ2Jn8DHAO09zmMAHslWQncCGwDvLZV9+KmbgmwA/CA2Yaq+hawOQ9e3iRJkjQnmUBoo1FVtwOfp5dEkOQRwBHAvlU1VFVDwGuAkSTbAC8Adm3VvZkHL2MCeD/wzqm/AkmSpOlnAqGNzYeBsacx7Q+sqqpVrfrvAE+jlyx8q6p+26q7EHh1ks3aA1bVV4Bbpy5kSZKkmSNVNd0xSBuF4eHhGh0dnbyhJEnSNEuypKqGB9U5AyFJkiSpMxMISZIkSZ2ZQEiSJEnqzARCkiRJUmcmEJIkSZI6M4GQJEmS1JkJhCRJkqTOTCAkSZIkdWYCIUmSJKmzTaY7AGljsWzVaoZOvGS6w5BmrJWnHDLdIUiSOnAGYgolqSSfbh1vkuTWJBf3tbswyVV9ZXsmuTzJ0iQ/SXJWX/0ZSVYleUSr7OgkHx0nlmc28bxsgni3SvL3SW5Mcl2S7yR5blN3Z1/b+8+V5OQkx7fqjk/y0yTLk1yT5A1N+eVJhpv3Q0luSPKyJAckWd1c69jrxa3P8MN9Y5/cF0uS3JZk++Z4x6bfC1ptbk2yQzvWJGc3n+FmzfGjk6xs9dkjycXN57EkyWVJ9m/qHtfUXZPkx0m+Mt7nKkmSNJeYQEytu4B9kmzRHL8EWNVukGQ7YD9guyRPbFX9LXB6VS2oqqcCH2n1eQRwGPDPwP4dYxkBrmz+jufjwO3AHlW1N3A08OiO44/F9iZ61/mcqtqniS99bXYGvga8o6q+1hRf0Vzr2Osfm/LfAv8lybhxVFUB3wd+vyl6HvCj5i9J9gRuq6pfDei+FvjjAdexOXAJcFZV7V5VzwLeAjypafIe4BtV9Yyqehpw4vifiiRJ0txhAjH1vgqMzcuPAIv66l8LfBlYDCxsle8I3DJ2UFXLWnUHAsuBjzFxQgD0vqEHDqeXELy0uTnub7M78FzgpKq6rznnTVW1rmtu3g38j6q6oxljdVWd06p/PPD15jwXdRjvXuAs4LhJ2v0TTcLQ/P1rHphQfHecfn8DHJekfznfUcBV7RiranlVnd0c9v/3uXaS+CRJkuYEE4iptxhY2Ny070vvm/K2saRiEQ9MBk4HvpXkq0mOa2Yq+vtcALwyySMnieH5wIqquhG4HHjFgDZ7A0urau04Y2zRXmJE7xv4B0iyNbB1c57xnAt8tKq+0Ff+wr4lTLu36s4Ejkqy7QTjfpf/TCCeA3wJ2KU5fh69BGOQm+nNzPxRX/newA8nON+ZwCeaZU1/nuQJgxolOTbJaJLRtWtWTzCcJEnS7GACMcWab6aH6N30P2CdfJLHAU8Grqyq64F7k+zT9PsU8FTgC8ABwPeSbJZkU3oJwJeab/m/D7x0kjBG6CUyNH8nnbUY4O72EiPgLwa0CVCTjPOPwB8lmd9X3r+E6f4kpLnOc4G3TjDuD4BnJtkSeGRV3QnclOTJTDwDAfAB4AQm+P8hyQXNno7zm5i+Rm850z8AewE/SvKY/n5VdVZVDVfV8Lz5E+U/kiRJs4MJxMPjIuA0Hrx86Uhge2BFs3l3iNYypqr6l6r6ZFW9ht5Snn2Ag4FtgWVNnxcwQUKQZB69ZVJ/0bT/CPDyZrag7TrgGe1N2euqudG/K8mTJmj2IXpJzxcGLBuayN8AxwBbjnPuNcDP6e1nGJs5+B69ZOuxwM8miPvnwFLgda3i6+jtTRlrcxi9JWCPapXdXlWfrao/Aq6m+34USZKkWcsE4uHxSeA9ffsYoHfjf3BVDVXVEPAsmgQiycFjS5OSPB7Ygd4G7BHgT1p9nkhvX0P/N/pjXgxcU1W7NH12A84DDm03ar7xHwX+stkzMfYUotes47V+EDgzyTbNGNskObavzXHAHfSWAKV/gEGq6nbg8/SSiPH8E/B2YOyJVlcBbwO+12y0nsj7geNbx58Fnp/k1a2y+z/jJC8a+8ybZGx3esuhJEmS5jQTiIdBVd1SVWe0y5IMAbvS+5Z8rN0K4I7m0akvBZYnuYbeE4tOoHfT/TJ6Twca63MXvTX8r2qKjk5yy9ir6XdBX0jnAa8fEOqf0Nvk/PMky+gtz/mXdbzcjwGXAVcnWQ58G1jTbtDczL+R3kbkDzXF/XsgDh8w9oeZ+KlQ/0RvWdFYAvFDYGcmXr40FtN1tPY8VNXdwCuBNyW5Kb3H7J4EvK9p8ixgNMm1zfk+XlVXT3YeSZKk2S6TfzEraUMYHh6u0dHR6Q5DkiRpUkmWVNXwoDpnICRJkiR1ZgIhSZIkqTMTCEmSJEmdmUBIkiRJ6swEQpIkSVJnJhCSJEmSOjOBkCRJktSZCYQkSZKkzjaZ7gCkjcWyVasZOvGSyRtKkjQFVp5yyHSHoDnCGQhJkiRJnZlAaMZJUkk+3TreJMmtSS7ua3dhkqv6yk5OcvyAMdcmWZpkeZIvJJmfZCjJ8vH6Jzk7yYqm3zVJDupr+5gk9yT50w1x3ZIkSbOBCYRmoruAfZJs0Ry/BFjVbpBkO2A/YLskT+ww5t1VtaCq9gF+B7ypYywnVNUC4O3A3/XVHQF8DxjpOJYkSdKsZwKhmeqrwNhizRFgUV/9a4EvA4uBhes49hXAk9exz1XATn1lI8A7gJ2T9NdJkiTNSSYQmqkWAwuTbA7sC3y/r34sqVjEOswAJNkEeDmwbB3jORj4UmucXYDHV9UPgM8DR45zvmOTjCYZXbtm9TqeUpIkaeYxgdCMVFXXAkP0koOvtOuSPI7eDMKVVXU9cG+SfSYZcoskS4FR4GbgE0CNd/rW+1OT3AT8X+ADrfKF9BIH6CU7A5OYqjqrqoaranje/G0nCVGSJGnm8zGumskuAk4DDgB2aJUfCWwPrEgCsA29G/qTJhjr7mYvw/2S/KoZp+1RwIrW8QnA+cBbgXOAZzXlI8DjkhzVHD8hyR5VdUOnK5MkSZqlnIHQTPZJ4D1V1b/caAQ4uKqGqmqI3k39uu6DoKruBP517OlKSR5Fb6nSlX3t7gPOAB6R5GVJ9gS2rKqdWjF88KHEIEmSNNuYQGjGqqpbquqMdlmSIWBXek8/Gmu3ArgjyXObopOS3DL2muQ0b2jaLwW+BfxlVd04IJYC3ge8k14Cc0Ffk/PwaUySJGkjkN59kaSpNjw8XKOjo9MdhiRJ0qSSLKmq4UF1zkBIkiRJ6swEQpIkSVJnJhCSJEmSOjOBkCRJktSZCYQkSZKkzkwgJEmSJHVmAiFJkiSpMxMISZIkSZ1tMt0BSBuLZatWM3TiJdMdhqSH2cpTDpnuECRpg3IGQpIkSVJnJhDaYJJUkk+3jjdJcmuSi/vaXZjkqr6yk5McP864hzVj79UqG0qyfEDbB5Qn+W9Jfphk+/SclOSGJNcnuSzJ3q22K5MsS7K0ef1B6/3tSVY07/+x1ee4JL9Jsu26fl6SJEmzkUuYtCHdBeyTZIuquht4CbCq3SDJdsB+wJ1JnlhVKzqMOwJcCSwETu4aTJI/At4CvKiqfp3kfwLPA55RVWuSvBS4KMneVfWbptuBVXVba5gFzVhnAxdX1RcHxHY1cBhwdtfYJEmSZitnILShfRUYW/A7Aizqq38t8GVgMb2EYEJJtgKeDxzTpX2r3+uAE4GXthKCdwFvqao1AFX1deC7wFFdx+07x+7AVsBJ9K5VkiRpzjOB0Ia2GFiYZHNgX+D7ffVjScUiut10HwpcWlXXA7cn2a9Dn92Aj9JLHv4NIMk2wJZVdWNf21Fg79bxZc0ypf64Bxm7liuAPZM8tr9BkmOTjCYZXbtmdYchJUmSZjYTCG1QVXUtMETv5vor7bokjwOeDFzZJAT3JtlnkiFH6CUlNH+7JB23AjcDr+vQNkC1jg+sqgVV9dwOfRcCi6vqPuB84Ij+BlV1VlUNV9XwvPluk5AkSbOfeyA0FS4CTgMOAHZolR8JbA+sSAKwDb2b8JMGDZJkB+BF9PZVFDAPqCTvnOT8a4CXA1cm+WVVfaaq7khyV5InVdVNrbb7Ad9e1wtMsi+wB/CN5lo2BW4CzlzXsSRJkmYTZyA0FT4JvKeqlvWVjwAHV9VQVQ0Bz2LifQ2HA+dW1W5Nn12AFcALJgugqm4FDgY+kORlTfGpwN8m2QIgyYubsT7b/dIecC0nj11LVT0B2CnJbg9hLEmSpFnDBEIbXFXdUlVntMuSDAG7At9rtVsB3JFkbLnQSUluGXvRu0m/oG/484DXd4xjBfBq4JPNOT5C74lJy5L8DPj/gNc0T4xaVwsHxHYB67DRW5IkaTZKVU3eStJ6Gx4ertHR0ekOQ5IkaVJJllTV8KA6ZyAkSZIkdWYCIUmSJKkzEwhJkiRJnZlASJIkSerMBEKSJElSZyYQkiRJkjozgZAkSZLUmQmEJEmSpM42me4ApI3FslWrGTrxkukOQ5IkzVIrTzlkukMAnIGQJEmStA46JxBJtk+yb5L9xl5TGZgeXknunKDumiSLBpQfn+SnSZY3bd7QlF+eZLjVbijJ8r6+ZyRZlWTgv8EkByRZneRHSX6S5H9P1j/J0UluTbK0ieu4ya4lyZlN+x8nubt5vzTJ4UnOTnL4RJ9TkuOS/CbJtuN9fpIkSXNJpyVMSd4LHA3cCFRTXMCLpiYszRRJnkov0dw/yZZVdVdT/ibgJcBzquqO5gb60I5jPgI4DPhnYH/g8nGaXlFVr0yyJbA0ycVVtWSS/p+rqv+ZZAfgZ0m+WFX/PN61VNWbm7oh4OKqWtCK85UdLmcEuLqJ5+wu1y9JkjSbdZ2BeB2we1UdUFUHNi+Th43D64FPA18HXt0qfzfwP6rqDoCqWl1V53Qc80BgOfAxejfgE2qSliXA7l37V9WvgJ8DO3a4lockye7AVsBJ48UhSZI013RNIJYD201lIJqxjgQ+ByyiuUlOsjWwdVXdOEG/z4wtBwK+0lc30ox3AfDKJI+cKIBmNuH3gOu69k+yK7A5cO1E19LBqa1lTUvHuY4rgD2TPHZAHMcmGU0yunbN6o6nlCRJmrm6JhAfBH6U5GtJLhp7TWVgmn5Jng3cWlW/AL4J7JdkeyD851K28RxVVQuaJUGvaI25aXP8pWb24vvAS8cZ44VJfkRvxuCUqrquQ/8jk1wH3AScUVW/meRaJnPC2HW0lzc1FgKLq+o+4HzgiP7OVXVWVQ1X1fC8+W6TkCRJs1/Xx7ieA/wVsAy4b+rC0QwzAuyVZGVzvA3w2qr6eJK7kjypqm5axzEPBrYFliUBmA+sAQY93/SKqurfhzBZ/7E9EL8PXJLkq1X1b+NdC/DxdYwfgCT7AnsA32ji2JRe0nLmQxlPkiRptug6A3FbVf1tVV1WVd8ee01pZJpWzUblI4B9q2qoqoaA1/CfS38+CJyZZJum/TZJju0w9AjwJ60xnwi8NMn8jqF16l9VV9Hb7/C2DtfyUIwAJ4+NV1VPAHZKstt6jClJkjTjdU0gliT5YJLf9zGuc9b8JLeMvYC3A6uqalWrzXeApyXZkd4G5suAq5tHtH6b3kzAuJqb/JfRmm1oNkhfCbxqsgAfQv+/Av4rcMgk1/JQLKS3B6PtgqZckiRpzkrVZEvZIcllA4rLJzFJ3Q0PD9fo6Oh0hyFJkjSpJEuqanhQXac9EFV14IYNSZIkSdJs1GkJU5LHJflEkq82x09LcszUhiZJkiRppum6B+Js4GvAE5rj6+mtkZckSZK0EemaQDy6qj5P8wjXqroXWDtlUUmSJEmakbomEHc1vwZcAEl+D/BndSVJkqSNTNcfkvtfwEXA7kn+CXgMA351V5IkSdLc1jWBuA74A2BPIMDP6D57IUmSJGmO6JoEXFVV91bVdVW1vKruAa6aysAkSZIkzTwTzkAkeTywE7BFkmfSm30A2AaYP8WxSXPKslWrGTrxkskbSpI0iZWnHDLdIWgjNtkSppcBRwM7A3/dKv8P4N1TFJMkSZKkGWrCBKKqzgHOSfLaqjrvYYpJesiS3FlVWzXvXwGcARwE/DFwZ1Wd1mq7EhiuqtuSrAWWtYZaXFWnJLkc2BG4uyn/eVUdnuRk4L8BtwKbAu+tqkVTenGSJEkzwGRLmP7XoPdjquqv+8ukmSDJQcBHgJdW1c1JJutyd1UtGKfuqKoaHVB+elWdlmQPYEmSLzb7gyRJkuasyZYwbf2wRCFtQEleCPwD8IqqunGqz1dVNyRZA2wP/HKqzydJkjSdJlvC9JcPVyDSBrIZcCFwQFX9tK/uuCR/2Dp+Quv9FkmWto4/WFWfa95/JsnYEqZvVNUJ7UGT7AfcUFUPSh6SHAscCzBvm8es+9VIkiTNMJ1+ByLJp2h+hbqtqv54g0ckrZ97gO8CxwBv66s7fcAeiDEPZQnTcUn+G/Ak4OBBHavqLOAsgM123ONB/w9JkiTNNl1/B+Ji4JLm9U16j3G9c6qCktbDfcDrgGcnmeonhZ1eVXsCRwLnJtl8is8nSZI07TrNQPQ/gSnJIuAfpyQiaT1V1ZokrwSuSPLvVfWJKT7f+UneCLwR+PupPJckSdJ065RADLAHsOuGDETakKrq9iQHA99JcluHLv17IC6tqhOb9+09ELdV1YsH9H8P8Nkk/1BV961H6JIkSTNaqiZflp3kP+jtgUjz99+AP/O3IaTuhoeHa3R00FYKSZKkmSXJkqoaHlTXdQmTj3OVJEmS1H0JU5KdgN3afarqO1MRlCRJkqSZqetjXP+K3pNmfgysbYoLMIGQJEmSNiJdZyAOBfasqt9OZTCSJEmSZrauvwNxE/DIqQxEkiRJ0szXdQZiDbA0yTeB+2chquqtUxKVJEmSpBmpawJxUfOSJEmStBHr+hjXc5JsAexaVT+b4pgkSZIkzVBdn8L0KuA0YFPgiUkWAO+pqldPZXDSXLJs1WqGTrxkusOQtAGtPOWQ6Q5Bkh52XTdRnww8B/j/AapqKfDEKYpJkiRJ0gzVNYG4t6pW95XVhg5G0y/Jna33r0hyQ5JdW2XXJFnU1+fsJCuauuuTnNv88GC7zTOTVJKXjXe+5vjoJB9t3p+c5PgBMZ6cZFWSpUmWJ3l1X/14Ma5Ksllz/OgkK5v3Q0nubsYbe72hqVuZZFmr/G/7rnlpc76DJv1wJUmS5oCum6iXJ3k9MC/JHsBbge9OXViabs0N8UeAl1bVzU3ZU+klnfsn2bKq7mp1OaGqvpgkwNuBy5LsU1W/a+pHgCubv1/bACGeXlWnNTFdkeSxVXXfJDGuBf4Y+NiA8W6sqgXjnOvAqrptQPnYNR8InAXssR7XI0mSNCt0nYF4C7A3vUe4LgLuoHeTqDkoyQuBfwAOqaobW1WvBz4NfB0YuP+lek4H/g14eTNegMOBo4GXJtl8Q8VaVT8B7gUe3SHGvwGOS9I1ce7qKmCnSVtJkiTNAZ0SiKpaU1V/XlXPrqrh5v1vpjo4TYvNgAuBQ6vqp311RwKfo5dEjkwyzg+BvZr3zwdWNMnI5cArWu22aC8dAt6zLsEmeS5wH3BrhxhvpjcL8kcDhtq9bwnTC1t1l7XKjxvQ92DgS+PEd2yS0SSja9f0rwKUJEmafSb8JjbJhL/94FOY5qR76C1POwZ421hhkmcDt1bVL5LcAnwyyfZV9etxxknr/QiwuHm/mN4N/PnN8d3tpUNJjgaGO8R5XJI/BP4DOLKqqmOMH6D3myb9j0N6KEuYTk3yIeCxwO8N6lhVZ9Fb3sRmO+7hviFJkjTrTbaU4/eBf6b3be73eeBNoeam+4DXAf+Y5N1V9YGmfATYa2zjMbAN8Frg4+OM80zgm0nmNe1eneTP6f0b2iHJ1lX1H+sR5+lVdVpf2aQxVtXPm5mO163HucecQC8ReitwDvCsDTCmJEnSjDbZEqbHA+8G9gHOAF4C3FZV366qb091cJoeVbUGeCVwVJJjkjwCOALYt6qGqmoIeA0DljGl563AjsClwIuBa6pql6bvbsB5wKEbMuZ1iRF4P/Cgpzs9FFV1H73/Nx7R/4QpSZKkuWjCBKKq1lbVpVX1RnpLNH4OXJ7kLQ9LdJo2VXU7vbX9JwGvAlZV1apWk+8AT0uyY3N8apJrgOuBZ9Nb9vM7ejfwF/QNfx69zc4b0v4dYgSgqq6jt0ejrX8PxFtbde09EOf2n7iqCngf8M4NcymSJEkzV3r3PhM06D03/xB6N4JD9NaPf7LvRk3SJIaHh2t0dHS6w5AkSZpUkiVVNXBf6mSbqM+ht3zpq8BfVtXyKYhPkiRJ0iwx2SbqPwLuAp4CvLX3OH+gtxG2qmqbKYxNkiRJ0gwzYQJRVV1/aE6SJEnSRsAEQZIkSVJnJhCSJEmSOjOBkCRJktSZCYQkSZKkzkwgJEmSJHU22WNcJW0gy1atZujES6Y7DEmz2MpTDpnuECTJGQhJkiRJ3ZlAaL0kubP1/hVJbkiya6vsmiSL+vqcnWRFU3d9knOT7NTX5plJKsnLxjtfc3x0ko82709OcvyAGAeWN3WHNefZq1U21JS9t1X26CT39J1rVZKlSX6a5GNJ/P9JkiTNed7waINIchDwEeDgqrq5KXsqvX9j+yfZsq/LCVX1DGBP4EfAZUk2bdWPAFc2f6fS2HkW9pXfBLyydXwEcF1fm9OragHwNODpwB9MVZCSJEkzhQmE1luSFwL/ABxSVTe2ql4PfBr4OvDqQX2r53Tg34CXN+MFOBw4Gnhpks2nKO6tgOcDx/DgBOJu4CdJhpvjI4HPjzPUpsDmwK+nIk5JkqSZxARC62sz4ELg0Kr6aV/dkcDngEVMPpPwQ2BsGdHzgRVNMnI58IpWuy2aZUNLkywF3rMesR8KXFpV1wO3J9mvr34xsDDJzsBa4F/66o9rYvhX4PqqWtp/giTHJhlNMrp2zer1CFWSJGlmMIHQ+roH+C69b/Hvl+TZwK1V9Qvgm8B+SbafYJy03o/Qu3mn+dtOPu6uqgVjL+Av1iP2ic4DcCnwkqb8cwP6jy1heiywZZL+WQyq6qyqGq6q4Xnzt12PUCVJkmYGEwitr/uA1wHPTvLuVvkIsFeSlcCNwDbAaycY55n0lgzNa9r9RdP3I8DLk2y9IYNOsgPwIuDjzXlOAI5slk8BUFW/A5YA7wDOG2+sqrqHXrKx/4aMUZIkaSYygdB6q6o19DYcH5XkmOZpREcA+1bVUFUNAa9hwDKm9LwV2JHeTfiLgWuqapem7270bt4P3cBhHw6cW1W7NefZBVgEztA7AAAgAElEQVQBvKCv3YeBd1XVr8YbqEk6nkcvUZIkSZrTTCC0QVTV7cDBwEnAq4BVVbWq1eQ7wNOS7Ngcn5rkGuB64NnAgc03/iPABX3Dn0dvQ/b6OCnJLWOvruepquuq6pxxxhzbA7Gc3o8y/p/1jFGSJGnGS1VNdwzSRmF4eLhGR0enOwxJkqRJJVlSVcOD6pyBkCRJktSZCYQkSZKkzkwgJEmSJHVmAiFJkiSpMxMISZIkSZ2ZQEiSJEnqzARCkiRJUmcmEJIkSZI622S6A5A2FstWrWboxEumOwxp1lh5yiHTHYIkaQBnICRJkiR1ZgIxCyW5s+/46CQf7Su7JsmivrKzk6xIsrSpP6iv/jFJ7knypxOc+/IkP2vG+EmSY1t1K5M8unV8QJKL+/pfmOSqvrKTk6xqxvxxkpG++k2S3JbkgxPEdXaSw5v3j0ryoyT/tVV/XJLfJNm2L77VzXmvTfKPSR7bqj+0Kf9pkmVJDh3ns/xpkv89XmySJElziQnEHJTkqfT+2+6fZMu+6hOqagHwduDv+uqOAL4HjDCxo5oxng/8VZJNO8a1HbAfsF2SJ/ZVn96M+Rrg75M8slX3UuBnwOuSZJJzbAt8DTirqj7VqhoBrgYO6+tyRVUtqKp9m/o3N+M8AzgNeE1V7QW8Gjgtyb6tvmOf5QLgjQOuSZIkac4xgZibXg98Gvg6vRvfQa4CduorGwHeAeycpL9ukK2Au4C1HeN6LfBlYDGwcFCDqroBWANs3xfXGcDNwO9NEs9Xgc9W1cfGCpPs3tSdxDjJUZOYbA38uik6HvhAVa1o4loBfBA4YUD3zZu/d00QmyRJ0pxgAjE7bdEsnVmaZCnwnr76I4HPAYsYfzbhYOBLYwdJdgEeX1U/AD7fjDGezyS5lt6swHurqp1AXNaK6+N9/UaamMaNK8l+wA1V9cvmeAvgIODiSa4H4K+BK6vq9HHOewWwZ3uZEvDCJtabgRcDn2zK9waW9I0z2pSPObXpewuweCzmvus5NsloktG1a1ZPELokSdLsYAIxO93dLLtZ0Cyh+YuxiiTPBm6tql8A3wT2S9L+Nv/UJDcB/xf4QKt8Ib3EAXozBBPdqB/VLPnZFTg+yW6tugNbcf1JK67HAU+md4N/PXBvkn1a/Y5L8jPg+8DJrfJXApdV1RrgPOCwJPPGietbwGv6EoSxa1tcVfcB59NbqjVmbAnTLsCngA+NhQxU3zj9ZWNLmB4PHJTkef0BVdVZVTVcVcPz5m/bXy1JkjTrmEDMPSPAXklWAjcC29BbOjTmBHo38icB5/T1O7rpdxHwjCR7THSiqroV+CHw3A5xHUlvWdKK5hxDPHAZ0+lVtWfT7twkY8uCRoAXN32WADsAB45zjsXAx4CvJNkaoNmzsAfwjWaMhYyfHF0E7N+8vw4Y7qvfD/hxf6equhO4HHjBOONKkiTNGSYQc0iSR9D7dn3fqhqqqiF6m5IfcMPcfBN/BvCIJC9LsiewZVXt1Or3QcbZp9A633zgmfQSlcmMAAe3xn/WoPGr6nx6S4XemGQbejflu7b6vbn/evr6/w29mZcLms3dI8DJY/2r6gnATn2zJmNe0LqW04A/SzLUXOsQ8G7gw/2dkmxCL4nq8jlIkiTNav6Q3NyyP7Cqqla1yr4DPC3Jju2GVVVJ3ge8k97egAv6xjqP3jf67x1wns8kuRvYDDi7qvr3CjxAc/O9K70nPI2df0WSO5IMmr14D/BZ4B7gW1X121bdhcCHkmzWV96+tncl+RS9jeTPAV7e1+QCesnL9/nPPRABVtMsu6qqpUneBXy5eSLUPcA7q2ppa5xTk5wEbEovaTl/os9BkiRpLkhV/zJvSVNheHi4RkdHpzsMSZKkSSVZUlX9y7kBlzBJkiRJWgcmEJIkSZI6M4GQJEmS1JkJhCRJkqTOTCAkSZIkdWYCIUmSJKkzEwhJkiRJnZlASJIkSerMX6KWHibLVq1m6MRLpjsMSZKmxMpTDpnuEPQwcQZCkiRJUmcmENogkjwuyWeT3JRkSZKrkhyW5OgkH+1re3mS4eb9yiSPHmfMC5Nc1Vd2cpJVSZYm+WmSjyV5RFN3dpLDW20fk+SeJH/aN8bKJFf0lS1Nsrx53yXm81p1hyc5u/OHJUmSNIuZQGi9JQnwJeA7VfWkqnoWsBDYeT3G3A7YD9guyRP7qk+vqgXA04CnA38wzjBHAN8DRgbUbZ1kl+ZcT30IIQ4n2fsh9JMkSZrVTCC0IbwI+F1V/d1YQVX9oqo+sh5jvhb4MrCYXjIyyKbA5sCvx6kfAd4B7Jxkp766zwNHttotWsf4TgPevY59JEmSZj0TCG0IewM/3MBjjt3UL+LBMwjHJVkK/CtwfVUt7e/czC48vqp+wAOThTFfBP5L8/5V9JKVdfF5YL8kT56oUZJjk4wmGV27ZvU6nkKSJGnmMYHQBpfkzCTXJLkaqHGajVdOkscBTwaurKrrgXuT7NNqMraE6bHAlkkGzVAspHeTD71ZjP4k5Hbg103fnwBrOsTWLl8LnAr82XjXAVBVZ1XVcFUNz5u/7URNJUmSZgUTCG0I19HbrwBAVb0ZOAh4DPArYPu+9o8CbptgvCObPiuSrASGGLCMqaruAS4F9h8wxghwdNP/IuAZSfboa/M54EwevHypa8yfbs696wTXIkmSNKeYQGhD+BaweZL/3iqb3/y9Gnh+kscDNE8y2gz45wnGGwEOrqqhqhoCxjZlP0Czeft5wI195XsCW1bVTq0xPjhgjAuADwFf6yvvFHOTwJwOvH2Ca5EkSZpT/CE5rbeqqiSHAqcneSdwK3AX8K6q+vckbwO+0jxu9U5gpKruaw1xbZKx4x/Q+0b/e63xVyS5I8lzm6Ljkvwh8EjgWuD/NOWbAL+ll4Bc0BfmefSWMr23Ne5/AH8F0MtF7i/vEvOYTwAnTfohSZIkzRGpGncpujRrNDf6VwNvqKrrpjueQYaHh2t0dHS6w5AkSZpUkiVVNTyoziVMmvWSPAFYDnxvpiYPkiRJc4VLmDTrVdW/0PtROUmSJE0xZyAkSZIkdWYCIUmSJKkzEwhJkiRJnZlASJIkSerMBEKSJElSZyYQkiRJkjrzMa7Sw2TZqtUMnXjJdIchzSorTzlkukOQJPVxBkKSJElSZyYQc0ySxyX5bJKbkixJclWSw1r1L0jygyQ/bV7HtupOTrIqydKm7mNJHtHUnZ3k8AHnOzvJmiRbt8rOSFJJHt0qO6wp26tVNtSUvaVV9tEkR7eOj29iWZ7kmiRvaMovTzLcN9by5v3RST7aF+f97ZOsTLIsybVJvp1kt1a7O/v6HZfkN0m2bZUd0MT9qlbZxUkOGPTfRJIkaS4xgZhDkgT4EvCdqnpSVT0LWAjs3NQ/Hvgs8Kaq2gt4AfCnSdprBE6vqgX0ftn56cAfdDj1z4HXNOd4BHAgsKqvzQhwZRNP2y+BtyXZdMD1vAl4CfCcqtoH2B9Ih3i6OLCq9gUuB06aoN0IcDVwWF/5LcCfb6BYJEmSZg0TiLnlRcDvqurvxgqq6hdV9ZHm8M3A2VX1w6buNuCdwIkDxtoU2Bz4dYfzLgKObN4fAPwTcO9YZZKtgOcDx/DgBOJW4JvAGweM+27gf1TVHU28q6vqnA7xrIurgJ0GVSTZHdiKXoIx0ld9DbA6yUs2cDySJEkzmgnE3LI38MNJ6pf0lY025WOOS7IU+Ffg+qpa2uG8NwCPSbI9vRvtxX31hwKXVtX1wO1J9uurPwV4R5J5YwXNkqitq+rGCc77mWa51VLgKx3iHORgerM2g4zQS46uAPZM8ti++vcx8ewFSY5NMppkdO2a1Q8xREmSpJnDBGIOS3Jms2/g6rEioAY0bZeNLWF6LLBlkv4Zg/GcT2924bn0brjb2knFYvq+za+qFcAPgNe3wx8n1rajqmpBE+8r2kOO075dflmSXwIvpresa5CFwOKquo/e9R3RF/cVAEleOF6AVXVWVQ1X1fC8+duO10ySJGnWMIGYW64D7v92v6reDBwEPKZVP9zX51nAj/sHqqp7gEvp7TvoYjHwXuAbzQ03AEl2oLe06uNJVgInAEc2+zXaPgC8i+bfZLNs6a4kT+p4/rZfAdv3lT0KuK11fCCwG73P5D39AyTZF9gD+EYT90IevIwJ4P24F0KSJG1ETCDmlm8Bmyf5762y+a33ZwJHJ1kA99/c/xX8P/buPMquqk7///shSCAyOCGEsZRJIEKAcgJEcEAQFNOioRQ1dgsOgEKLEpBvd9puJCo0gijpOIEuIdBGBhkcIQ1oNFQkIYNhiIlIEI3aHdQEfhCe3x9nXzxeblWdSgKV4XmtdVfdu8fPuYG1zqf23qf4bPtA5Qb/QKC/LURPsn0/1Y30l9qqjgW+YXtn2122dwQWUR3grvdfQJXIHF0rPhf4oqQtS0xb1p8a1Y87gIPKoXHK05eGA79pm3MFcCrwHknPaxujB5hQYu6yvR2wff2JTWWMH1AlK/s2iCsiIiJinZcEYj1i21TnDV4jaZGkGcBlVL/Zx/ZvgeOBL0taAPwU+Jrt79aGaZ2BmEv1hwbbE4L+5v+vDmcWeoCr28qm8vfblVrOoTwxqrgEuAW4ozyi9X+A5Q3i+B3wUeDGci2fB3rqKyO1tr+lOudwUlvVcR3ivpqnHgLvFHdERETEekvVPWdEPN26u7vd29s71GFEREREDEjSTNvtW9+BrEBERERERMQgJIGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhrbeKgDiNhQzFmyjK7xNwx1GBEREdFm8cSjhjqEdUpWICIiIiIiorEkELHaJG0j6XJJv5I0U9J0SWPa2lwoaYmkjWpl4yQtlTRL0gJJp9XqJkg6vcNcf6m9313SjZLuk/RLSVdJ2qatfZckSzqlVnaxpHG1zxtL+oOkczvMt7WkxyR9oK18saSptc/HSrp04G8rIiIiYt2WBCJWiyQB1wC32n6x7QOA44Adam02AsYAvwEOaRviStujgYOAT0raseG8mwI3AJfY3tX2nsAlwNYdmv8e+KikTfoY7nDgbuAd5Xrq3g78DOjp0K9b0t5N4o2IiIhYXySBiNX1WuD/sz2pVWD717a/UGtzGDCX6ga/0404tv8I3AeMbDjvO4Hptr9bG+MW23M7tF0K/Bh4bx9j9QAXAvcDr+xQ9zFgB0nbt9WdB5zVMN6IiIiI9UISiFhdewO/GKBND3AFcDVwtKRntTeQtBOwKXBXw3lHATMHEedE4GOShrXNuxnwOuD6EmNPrW5HYFvbM4CrgLFtY14F7C9p174mlXSipF5JvSuXLxtEuBERERFrpyQQsUZJ+qKk2ZLuKJ83Ad4EXGP7YeDnVFuGWsZKmgf8CrjQ9iNPR1y2FwEzqFYu6o4GbrG9HJgKjKklGcdRJQkAU3jq6slK4HPAmf3MO9l2t+3uYSO2Ws2riIiIiBh6SSBidc0D9m99sH0S1W/0W2cRjgC2AuZIWgwczN/fiF9pe2/g1cD5krYdxLwHDDLWTwNn8Pf/3fcAry+xzQSeT7XlqlU3rtRdB+wrabe2Mb9Jda5jp0HGEhEREbFOSgIRq+tmYFNJH6qVjai97wHeb7vLdhfwIuBwSfU22J5OdTP+0YbzXg4cKOnJBzdLOkLSS/vqYHsBMJ9q1QFJW1IlNDvV4jsJ6JG0B/Bs29vX6s6lWpWoj/kYcAFwasO4IyIiItZpSSBitdg28FbgNZIWSZoBXAacUZKEN1I9LanV/q/A7cCbOwz3GeB9krYon8+W9EDr1TbvCqpE4BRJ90qaD4yjeuJSf87hb0+I+gfgZtuP1uqvBd5Sxrq6re9UOh8C/yr5o4wRERGxgVB1/xcRT7fu7m739vYOdRgRERERA5I003Z3p7qsQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxvLXcyOeIXOWLKNr/A0DN4xYTyyeeNRQhxAREU+DrEBERERERERjSSBijZG0UtKs2qtL0qGSri/120i6XtJsSfMl3VjKuyTNbRtrgqTTO8wxQdKSMv5cSW9pq58t6Yq2skslHVveP0/SnZLeVz7vLelmSfdIulfS/5OkUjdO0tIy1wJJp3WI5ynzRURERKzPkkDEmrTC9ujaa3Fb/aeAH9re1/ZewPhVnOcC26OBtwNfk7QRgKQ9qf6bPkTSs9s7SdoK+D4w2fbXJW0GXAdMtL07sC9wIPDhWrcry1wHAZ+UtGNtvH7ni4iIiFgfJYGIZ9JI4IHWB9t3rc5gtn8JPA68oBS9E/gm8APgLW3NNwduAi63fUmt/U9s/6CMtxw4mQ6Jje0/AveVa6DWv6/5IiIiItZLSSBiTdqstn3p6g71XwS+KukWSZ+UtF2tbpf69ifggwNNJukVwBPA0lI0FrgSuALoaWv+n8Dtti+ole0NzKw3sr0Q2FzSlm1z7QRsCtSTnv7ma/U7UVKvpN6Vy5cNdEkRERERa708hSnWpBVlu09Htr8v6cXAEcCRwJ2SRpXqhfW+kib0M89pko4H/gyMtW1JLwOW2v61pAeotjY91/b/lj43A8dIOs/271vTAO4r3PJzrKTDgD2AE2w/UuIbaL7WNU8GJgMMH7lbX3NFRERErDOyAhHPKNt/sn257XcDdwCHrMIwF5QzFq+2fVsp6wFeImkxsBDYEnhbrc8U4BLgRklblLJ5QHd94JLg/MX2n0vRlbb3Bl4NnC9p24bzRURERKyXkkDEM0bSayWNKO+3AHYB7l8D425EdaB6H9tdtruAY2jbVmT788CPgaslbQJ8CzhY0uvLOJsBFwGfbZ/D9nSq8w4fbTpfRERExPooCUQ8kw4AeiXdBUwHvmL7jjUw7iHAEttLamW3AntJqh96xvYZwG+okoFHqW78z5Z0NzCHalXk4j7m+QzwPuCopvNFRERErG9kZ1t2xDOhu7vbvb29Qx1GRERExIAkzbTd3akuKxAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorGNhzqAiA3FnCXL6Bp/w1CHERFPg8UTjxrqECIinjFZgYiIiIiIiMaSQMTTRtJKSbNqry5Jh0q6vtRvI+l6SbMlzZd0YynvkjS3bawJkk7vMMeT5ZI2lfRDSf9aPu8g6VpJ90paKOlCSZuUukMlLZN0p6QFks6rjTlOkiW9rlY2ppQdWyvbWtJjkj6wZr+5iIiIiLVXEoh4Oq2wPbr2WtxW/yngh7b3tb0XMH5VJyqJwVRgpu1/kyTgO8A1tncDdgc2B86pdbvN9n7AfsDRkg6q1c0BemqfjwNmt037duBnbe0iIiIi1mtJIGIojQQeaH2wfdcqjrMxMAW413YrCXkt8Ijtr5exVwKnAf8oaUS9s+0VwCxg+1rxbcDLJT1L0ubArqVNXQ/wMWAHSdsTERERsQFIAhFPp81q25eu7lD/ReCrkm6R9ElJ29XqdqlvfwI+2M88nwAet31qrWxvYGa9ke2HgfupkoEnSXousBtwa7058CPgjcAxwHVtfXYEtrU9A7gKGNspMEknSuqV1Lty+bJ+LiEiIiJi3ZAEIp5O9S1MY9orbX8feDHwZeAlwJ2Sti7VC+vbn4BJ/cxzO/AqSbvXykSVBLSrl79a0l3AQ8D1th9qazuFauvSccAVbXXHUSUOrXYdtzHZnmy723b3sBFb9XMJEREREeuGJBAxpGz/yfbltt8N3AEcsgrD3AqcCtxUW8WYB3TXG0naEtgRWFiKbrO9D/BS4EOSRrfFNgMYBbzA9j1tc/YA4yQtplqd2FfSbqsQe0RERMQ6JQlEDBlJr22dR5C0BbAL1RajQbM9Ffgc8D1JzwF+DIyQ9J4y/jDgfOBS28vb+t4DnAuc0WHoM4Gz2uLeA3i27e1td9nuKv2PW5XYIyIiItYlSSBiKB0A9JZtRNOBr9i+Y1UHsz2J6slL1wHDgTHA2yXdC9wDPEJbMlAzCThE0ovaxrzJ9i1tbXuA9jMdU8nTmCIiImIDILvTNvGIWNO6u7vd29s71GFEREREDEjSTNvdneqyAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGtt4qAOI2FDMWbKMrvE3DHUYEREsnnjUUIcQEeuwrEBERERERERjSSDiGSFppaRZtVeXpEMlXV/qt5F0vaTZkuZLurGUd0ma2zbWBEmn9zHPeyTNlTSvjHN6KZ8mqbvW7slxSxzLJN0paYGk82rtxklaWmJeIOm0Un64pOmSVD4PK20OXLPfXERERMTaJQlEPFNW2B5dey1uq/8U8EPb+9reCxg/2AkkHQmcChxue29gf2BZw+632d4P2A84WtJBtborbY8GDgI+KWlH2z8Afg38U2lzCnCH7Z8ONu6IiIiIdUnOQMTaYiTwg9YH23etwhhnAqfbfrCM8Qjw5cEMYHuFpFnA9h3q/ijpvhLrb4DTgNslTQdOBl6+CjFHRERErFOSQMQzZbNyYw6wyPaYtvovAldKOhn4EfD1ViIA7FLrC7AtcB5PNQqYuTpBSnousBtwa4e6nYBNgbsAbP9W0ueB6cBHbP+pQ58TgRMBhm259eqEFhEREbFWyBameKbUtzC1Jw/Y/j7wYqoVg5cAd0pq3XEvrG9/AiatwvweoOzVku4CHgKut/1QrW6spHnAr4ALy8pGyxeBYbYv7TipPdl2t+3uYSO2WoWwIyIiItYuSSBirWH7T7Yvt/1u4A7gkEEOMQ84oI+6PwLPrX1+HvCH2ufbbO8DvBT4kKTRtbory5mKVwPnS9q2FvMTdE5OIiIiItZLSSBirSDptZJGlPdbALsA9w9ymHOBz7Zu8CUNl/SRUjcNOL711CTgvcAt7QPYvqeMc0aHuunAN4GPDjKuiIiIiPVGEohYWxwA9JZtRNOBr9i+YzAD2L6RakvRj8qWo5n87ZzPZODPwGxJs4HN6XyOAqotUodIelGHus8A7ytJTkRERMQGR3Z2X0Q8E7q7u93b2zvUYUREREQMSNJM292d6rICERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIa23jgJhGxJsxZsoyu8TcMdRgREbGBWzzxqKEOIdZxWYGIiIiIiIjGkkCsBknbSpoiaaGk+ZJulLR7qdtb0s2S7pF0r6T/J0m1vkdK6pX0S0kLJJ1XqzuxlC2QNEPSwbW6aZJ6a5+7JU0r78dJurgtxmmlzc8lzZJ0v6Sl5f0sSV1t7Z8laWKJeW6Z/8hSt1jSC2ptD5V0fae5Jb2n9J9XvpvTS/mlko4t758n6U5J75PUJWlFLa5Zkt5Tm3dqbexjJV3ax7/JyyXdKunu8v19RdIISRNaMdTaPnk9klaWOedK+q6k55TyelzzJX2jfEcvlLRI0ra18b4kaXynuCIiIiLWF0kgVlFJBq4GptnexfZewFnANpI2A64DJtreHdgXOBD4cOk7CrgYON72nsAo4Fel7mjgA8DBtl8CfBC4vH6jCrywdVPflO1X2B4N/Atwpe3R5bW4rem/AyOBUbZHAW8GthjMXCW2U4HDbe8N7A8sa2uzFfB9YLLtr5fihbW4Rtv+Rq1Lt6S9B5h3G+C/gTNs7wHsCXyvYfwrypyjgD8BJ9XqFpbv7qXADsA7bP8e+AxwXpl7f+Bg4PwGc0VERESss5JArLrDgMdsT2oV2J5l+zbgncBPbP+glC8HTgZav53+BHCO7QWl/nHbXyp1ZwAft/2HUvcL4DL+/ob2c8DZa/qCJI0ATgBOsf1omf93tq8a5FBnAqfbfrCM8YjtL9fqNwduAi63fUnDMc+jStD6cxJwme3pZV7b/rbt3w0ufKYD27cX2l4JzKjVTQZ2kXQYVUJ4su3HBjlXRERExDolCcSqGwXM7KNu7/Y62wuBzSVtOdi+QG8pb5kOPFpuXNekXYH7bT/cT5tbWluMgK/00aa/6wP4T+B22xe0le/StoXp1bW6q4D9Je3az7gDzTsgScOA11GtILXXbQq8gmpVA9tPAB8CpgL32L61Q58Ty1a13pXLl7VXR0RERKxzkkA8PQS4j7q+ygc73n/w1FWINTlnXw5rbTEC3r+KY9wMHCPphW3l7VuYbqvVraRaeTlzFecc6LvZrCRFfwSeB/yw1maXWt39tu96srM9C5gLfIkObE+23W27e9iIrVYx9IiIiIi1RxKIVTcPOKCfuu56gaQXA3+x/ecB+s7vULd/KX+S7ZuBTYFX1or/CDy3re/zgD/0MVe7+4CdJA3qzEMH/V0fwBTgEuDGQc71TeAQYKdVmLfTd7MF8H/l/YqSFO0MbELnMxC7Aq+U9Ja2cZ4or4iIiIj1XhKIVXczMFzSCa0CSS+T9BrgW8DBkl5fyjcDLgI+W5p+DjhLf3ti00aS/rnUfRb4jKTnl7rRwDg6/4b7HKrzFC13AAe1DlxL6gaGA79pckHlrMZXgYskbVLGGCnp+Cb9a84FPluLY7ikj7TN9Xngx8DVrbkaxPcYcAHVAe1OLgbeK+kVrQJJx5c4bgXe0kpYJP0DMLuca6jPsQz4CHC6pGe11f2W6hzLqq6CRERERKzz8ofkVpFtSxoDfL48uvMRYDFwqu0Vko4BviDpi8Awqt+eX1z63iXpVOCKcnDZwA2l7jpJ2wM/lWTgz1RPa/pthxhulLS09vl3kj5K9Zv9jYC/AD1lr35TZ1Ntj5ov6RHgr1RPbgJ3Kd8AACAASURBVGqsxLUN8KPytCoDX+vQ7gxJX6f6bs7kb1uFWr5m+6K2bl+ljwPk5fqPA84r26OeoEocvmP7ofKY2dvL9/p7+tiCZftOSbOB44Db2qqvASZIenXbFqsBvXT7rejNH++JiIiIdZzsNbk9PiL60t3d7d7e3oEbRkRERAwxSTNtd3eqyxamiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNJYGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxJBAREREREdFY/hJ1xDNkzpJldI2/YajDiNjgLc5fhI+IWC1ZgQAkbStpiqSFkuZLulHS7qVub0k3S7pH0r2S/p8k1foeKalX0i8lLZB0XimfIOn08n5TST+U9K+SZpXXQ5KW1D5vUtqOkWRJL6nN0SVpbnl/qKTrG1zT6SWeuZJmS3pPKZ8mqbvWrs+xB3tt5fPK2jXNkjS+Nm9vbexuSdM6xL2RpItK3HMk3SHpRbX6/cr388a2fpb0zdrnjSUtbbuet0q6q1zLHElvrdW9UtLPS8y/lDShbfxrJU1vK9ujXFerz+T+/1UiIiIi1n0b/ApESQauBi6zfVwpGw1sI+k3wHXAh2z/QNIIYCrwYeCLkkYBFwNH2V4gaWPgxLbxNyl9Ztr+N+DfSvkE4C+2z2sLqQe4HTgOmLCK1/RB4A3Ay20/LGkr4K0DdGsfY1WuDWCF7dF9DPtCSUfavqmfqccC2wH72H5C0g7AX2v1re+nB/h+rfyvwChJm9leQXX9S2qx7gucB7zB9qKSlPxQ0q9s3wVcBrzD9mxJw4A9an2fA+wP/EXSi2wvKlUXARfYvra0e2k/1xURERGxXsgKBBwGPGZ7UqvA9izbtwHvBH5i+welfDlwMjC+NP0EcI7tBaX+cdtfqo29MTAFuNf2eAYgaXPgIOCfqBKIVXUW8GHbD5e4ltm+bJBjrNFrKz4HnD1Am5HAb20/UeZ9wPb/wpPJ3rHAOOBwSZu29b0JaO1N6AGuqNWdDny6dfNffp4LfLzUvxD4balbaXt+re/bgO9SXW/932Uk8EDrg+05A1xbRERExDovCQSMAmb2Ubd3e53thcDmkrYcoC9UN+GP2z61YSxvBb5n+x7gT5L2b9jvSZK2ALYocfblW60tRsCNfbRZ1WvbrG0L09ha3XTgUUmH9TPuVcCbS9/zJe1XqzsIWFSubRrwpra+U4DjSmKxD/DzWt1T/i2B3lIOcAFwt6SrJX2gLTlpJSNXlPfU+tws6SZJp5WVioiIiIj1WhKI/glwH3V9ldfdDrxK5TxFAz1UN8GUnz39tO1LfzG3vMv26LLVqP0mvKm+rm1Fa+zyurKt/j/oZxXC9gNU24fOBJ4AfizpdaW63++nbEXqKuXtiVGn7+XJMtufArqBH1CtPH0PQNI2wK7A7SWxe7xs78L214E9gf8GDgV+Jmn4300gnVjOkfSuXL6sr8uOiIiIWGckgYB5wAH91HXXCyS9mOrswp8H6AtwK3AqcJOk7foLQtLzgdcCX5G0mGprzdiybaexsm3pryXO1bHGrq0tvpuBTYFX9tPmUds32f448GngreVcwtuAfynfzxeAI8uKS911VGcdrmgrf8q/JdW5hie3KtleaPsS4HXAvuXfZCzwXGBRmbeL2jYm2w/a/prtY4DHqVZu6tcy2Xa37e5hI7bq65IjIiIi1hlJIOBmYLikE1oFkl4m6TXAt4CDJb2+lG9GdXD2s6Xp54Cz9LcnNm0k6Z/rg9ueWtp9b4AtLscC37C9s+0u2zsCi4CDV+GazqU65L1liWtLSScO0Kfdmry2dudQbYF6Ckn7txISSRtRbUX6NfB6YLbtHcv3szPVAe72w+FfAz7V4TzCecCZkrrK2F1UZ0XOL5+PqiVruwErgf+jWs04oszZRZVUtQ7bHyHpWeX9tsDzqR3cjoiIiFgfbfAJhG0DY4A3qHqM6zyqpx89WJ7mcwxwtqS7gTnAHVRPJ2ptmTkVuELSL4G5VAdr2+eYBHwHuK7Dwd+WHqqnQdVNpdpO0+51kh6ovV7VVn8JcAtwh6pHtP4PsLy/76FDzKt6be1nICZ26HMjsLSPqV8IfLfEfRfVb/UvpuH3Uw5dX9hhzlnAGWXsBVSHoj9RygHeTXUGYhbwTeBdwI7ATsDPauMsAh6W9ArgcGCupNlUT4T6uO2H+riuiIiIiPWCqvvniHi6dXd3u7e3d+CGEREREUNM0kzb7du/gaxARERERETEICSBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNbTzUAURsKOYsWUbX+BuGOoyIiFjDFk88aqhDiHhGZQViCEjaVtIUSQslzZd0o6TdJXVJmtvWdoKk08v7SyUdW94/S9JESfdKmitphqQjS91iSS8o7w+QtEjSfpLGSVoqaVbttVeZ15JOqc17saRxbbF8stZvZe39R/qJ83mS7pT0vvbrk3SCpF9Iem75vLGkP0g6t5/v7lJJyyVtUSu7sMT/glrZmFL2klrZRpIuKt/XHEl3SHpRrX6/0ueNbXP+pZ94Zku6oq/6iIiIiPVNEohnmCQBVwPTbO9iey/gLGCbQQ7178BIYJTtUcCbgS3qDSTtA3wbGGv7zlJ8pe3Rtdf8Uv574KOSNulrQtvntPoBK2pjXNTHtW4FfB+YbPvrbXXvBk4BDrf9v6X4cOBu4B3le+rLfcAxZZyNgMOAJW1teoDbgeNqZWOB7YB9bL8UGAP8X4c+Pf3MXb+GPan+HzpE0rOb9ImIiIhY1yWBeOYdBjxme1KrwPYs27c1HUDSCOAE4BTbj5Yxfmf7qlqzPYFrgHfbntFg2KXAj4H3No1jAJsDNwGX276kXiHpHcB4quThD7WqHuBC4H7glf2MfQVVMgBwKPAT4PHa+JsDBwH/xN8nECOB39p+AsD2A63kpSQsxwLjgMMlbdrgGt8JfBP4AfCWBu0jIiIi1nlJIJ55o4CZ/dTvUt9iBHywQ5tdgfttP9zPONcCJ9u+va18bNsWps1qdROBj0ka1uRCBvCfwO22L2gr3xm4mCp5eKhVWOJ4HXA9VYLQ3yrAvcDWZetTDzClrf6twPds3wP8SdL+pfwq4M3lus+XtF+tz0HAItsLgWnAmxpc41jgygbxRkRERKw3kkCsfRbWtxgBkwbs0dmPgPd3SAbatzCtaFXYXgTMoPrN+uq6GThG0gvbypdSrTC8o638aOAW28uBqcCYARKZ71CtLrwCaF+9qScVU8pnbD8A7AGcCTwB/FjS6/rr0xdJLwOW2v411crN/q2zHG3tTpTUK6l35fJl/Q0ZERERsU7IU5ieefOotsqsjvuAnSRtYfvPfbQ5mSr5+BLwgUGM/WmqcxO3rl6ITKE6T3CjpMNqcS4HjgRul/R7298q5T3AQZIWl8/Pp9ru9aN+xv8FcJntJ1pHJiQ9H3gtMEqSgWGAJX3ClUeptlbdJOl3wFslTQPeBrxF0icBAc8f4PvtAV5Si3fLMsZX6o1sTwYmAwwfuZv7/roiIiIi1g1ZgXjm3QwMl3RCq0DSyyS9pukA5bf0XwUuah16ljRS0vG1Zk9Q3eTuIelTgxh7ATCfakVgtdj+PNVv56+uH862vRQ4Avi0pDdK2hI4GNjJdpftLuAk+lkFsH0/8EmqBKnuWOAbtncuY+0ILAIOlrS/pO3gycPX+wC/Bl4PzLa9Y+mzM9UqyFs7zV36vp3qMHYr3mP6izciIiJifZEE4hlm21RP/3mDqse4zgMmAA8OcqizqbYDzS+PRr2mfK7P9SjVje1bJJ1UitvPQBzYYexzgB0GGU9Hts8AfkN12HijWvkiqoPHXwM+BNzcOhBeXFviHt7P2P9VzizU9VA95apuKtW2rBcC3y3f111UB68vHqAPwAhJD7RewKnAEtv1Jz/dCuwlaWRf8UZERESsD1Tdz0bE0627u9u9vb1DHUZERETEgCTNtN3dqS4rEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHR2MZDHUDEhmLOkmV0jb9hqMOIiIgBLJ541FCHELFWywpENCJpW0lTJC2UNF/SjZJ2l9QlaW5b2wmSTi/vL5V0bHn/LEkTJd0raa6kGZKOLHWLJb2gvD9A0iJJ+0kaJ2mppFm1115lXks6pTbvxZLGdYh9D0nTSt9fSprcVn+hpCWSnvL/g6RrJU3vUH68pLskzZM0W9JXJD1nlb7ciIiIiHVIEogYkCQBVwPTbO9iey/gLGCbQQ7178BIYJTtUcCbgS3a5toH+DYw1vadpfhK26Nrr/ml/PfARyVtMsC8FwEXlL57Al+ozbcRMAb4DXBIWyzPAfYHniPpRbXyI4DTgCNt713a/JTBfx8RERER65wkENHEYcBjtie1CmzPsn1b0wEkjQBOAE6x/WgZ43e2r6o12xO4Bni37RkNhl0K/Bh47wDtRgIP1GKfU6s7DJgLXAL0tPV7G/BdYApwXK38k8DptpeU8Vba/prtuxvEHBEREbFOSwIRTYwCZvZTv0t9ixHwwQ5tdgXut/1wP+NcC5xs+/a28rFtW5g2q9VNBD4maVg/414A3CzpJkmntW016gGuoFphOVrSszrUXcHfJxd7A7/oZ76IiIiI9VYSiFgTFta3GAGTBuzR2Y+A93dIBtq3MK1oVdheBMwA3tnXoLa/TrW68d/AocDPJA0vW5/eBFxTEpufA4cDSNqGKum53fY9wOOSRrWPLemlJalZKGlsh/oTJfVK6l25fNlgvouIiIiItVISiGhiHnDAao5xH7CTpC36aXNy+fmlQY79aeAM+vnv2faDZZvRMcDjVKsqRwBbAXMkLQYO5m8rDWOB5wKLSl0Xf9vGNI/q3AO255Sk6SagvjLSmney7W7b3cNGbDXIy4qIiIhY+ySBiCZuBoZLOqFVIOllkl7TdADby4GvAhe1Dj1LGinp+FqzJ6hu4PeQ9KlBjL0AmA8c3ale0hGtrUmStgWeDywpc73fdpftLuBFwOHlvEYPcESt7gD+lkCcC5wnaYfaNE9JHiIiIiLWR/k7EDEg25Y0Bvi8pPHAI8Bi4NRBDnU28B/AfEmPAH8F/qVtrkclHQP8j6TflTZjJR1ca/Zh4MG2sc8B7qSzw4ELy5wAHwceBt4IfKA2918l3Q6cAuwE/KxWt0jSw5JeYftGSVsDN5XtVv9HdRD7+02/iIiIiIh1lWwPdQwRG4Tu7m739vYOdRgRERERA5I003Z3p7psYYqIiIiIiMaSQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxjYe6gAiNhRzliyja/wNQx1GRMQGZ/HEo4Y6hIj1SlYgAknbSpoiaaGk+ZJulLS7pC5Jc9vaTpB0enl/qaRjy/tnSZoo6V5JcyXNkHRkqVss6QXl/QGSFknaT9I4SUslzaq99irzWtIptXkvljSuQ+z1eDaV9ENJ/1o+7yDp2hLTQkkXStqk1B0qaZmkOyUtkHRebcxxZf7X1crGlLJja2VbS3pM0gfWwD9DRERExDohCcQGTpKAq4FptnexvRdwFrDNIIf6d2AkMMr2KODNwBZtc+0DfBsYa/vOUnyl7dG11/xS/nvgo60b/gbXsQkwFZhp+9/KdX0HuMb2bsDuwObAObVut9neD9gPOFrSQbW6OUBP7fNxwOy2ad8O/KytXURERMR6LQlEHAY8ZntSq8D2LNu3NR1A0gjgBOAU24+WMX5n+6pasz2Ba4B3257RYNilwI+B9zZouzEwBbjX9vhS9lrgEdtfL/GsBE4D/rHE+yTbK4BZwPa14tuAl5eVlc2BXUubuh7gY8AOkrYnIiIiYgOQBCJGATP7qd+lvsUI+GCHNrsC99t+uJ9xrgVOtn17W/nYti1Mm9XqJgIfkzRsgGv4BPC47VNrZXvTdl0lvvtLvE+S9FxgN+DWenPgR8AbgWOA69r67AhsW5Khq4CxA8QYERERsV5IAhEDWVjfYgRMGrBHZz8C3t8hGWjfwrSiVWF7ETADeOcAY98OvErS7rUyUSUB7erlr5Z0F/AQcL3th9raTqHaunQccEVb3XFUiUOrXcdtTJJOlNQrqXfl8mUDXEZERETE2i8JRMwDDljNMe4DdpK0RT9tTi4/vzTIsT8NnEH//63eCpwK3CRpu1I2D+iuN5K0JbAjsLAU3WZ7H+ClwIckja63L6sLo4AX2L6nbc4eYJykxVSrE/tK2q09MNuTbXfb7h42YqsBLzYiIiJibZcEIm4Ghks6oVUg6WWSXtN0ANvLga8CF9WecjRS0vG1Zk9Q3XTvIelTgxh7ATAfOHqAdlOBzwHfk/QcqvMTIyS9p8QzDDgfuLTEW+97D3AuVaLS7kyqQ+VPkrQH8Gzb29vust1V+h/X9LoiIiIi1lVJIDZwtg2MAd5QHnU6D5gAPDjIoc6mOvg8vzz69ZryuT7Xo1TnCd4i6aRS3H4G4sAOY58D7NDgWiZRPXnpOmB4ua63S7oXuAd4hLZkoGYScIikF7WNeZPtW9ra9lA9uapuKnkaU0RERGwAVN0/RsTTrbu72729vUMdRkRERMSAJM203d2pLisQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNJYGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxJBAREREREdHYxkMdQMSGYs6SZXSNv2Gow4iIiFgvLJ541FCHsMHKCsQGStK2kqZIWihpvqQbJe0uqUvS3La2EySdXt5fKunY8v5ZkiZKulfSXEkzJB1Z6hZLekF5f4CkRZL2kzRO0lJJs2qvvcq8lnRKbd6LJY3rEPsESUtK3wWSLpG0UYf4pkm6W9JsSXdIGl3KL5f0odp4r5B0l6SNy+f9SixvbJvXks6vfT5d0oT27ygiIiJifZYEYgMkScDVwDTbu9jeCzgL2GaQQ/07MBIYZXsU8GZgi7a59gG+DYy1fWcpvtL26Nprfin/PfBRSZs0mPsC26OBvYCXAq/po927bO8LfAn4XCk7Dfi4pK1L4nEx8GHbj5f6HuD28rPuUeAfWolRRERExIYoCcSG6TDgMduTWgW2Z9m+rekAkkYAJwCn2H60jPE721fVmu0JXAO82/aMBsMuBX4MvLdpHMAmwKbA/w7QbjqwfStO4Dzgs8AHgbts3w5PJlfHAuOAwyVtWhvjcWAyVQISERERsUFKArFhGgXM7Kd+l/oWI6qb7Ha7Avfbfrifca4FTm7dnNeMbdvCtFmtbiLwMUnDBriG00psvwXusT1rgPZHUCUzLZOoVi8+DnyiVn4QsMj2QmAa8Ka2cb4IvEvSVgPMFxEREbFeSgIRnSysbzGiutleFT8C3t8hGWjfwrSiVWF7ETADeOcAY7e2ML0QeLak4/po9y1JDwBnAF+ozfME8F/ATbb/WGvfA0wp76fQto2pJEzfAD4yQHwASDpRUq+k3pXLlzXpEhEREbFWSwKxYZoHHLCaY9wH7CRpi37anFx+fmmQY3+a6oZ/wP8+bT8GfA84pI8m7wJeBFxOtXpQ90R5AVASnbcB/yJpMVXCcWSHa/w88E/AsxvEN9l2t+3uYSOyaBERERHrviQQG6abgeGSTmgVSHqZpL4OIj+F7eXAV4GLWoeeJY2UdHyt2RNUv8HfQ9KnBjH2AmA+cPRAbcuZhQOBhf2M9xhwNvBKSXv2M9zrgdm2d7TdZXtnYCrw1rbx/gRcRZVERERERGxQkkBsgGwbGAO8oTzGdR4wAXhwkEOdTXXweX559Os15XN9rkeBY4C3SDqpFLefgTiww9jnADv0M3frDMRcqr9n0u8qR9kmdT7Q36NWe6ieTlU3lc7bqc4H8jSmiIiI2OCoupeMiKdbd3e3e3t7hzqMiIiIiAFJmmm7u1NdViAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorGNhzqAiA3FnCXL6Bp/w1CHEbHOWDzxqKEOISIiOsgKRKwxkraVNEXSQknzJd0oaXdJXZLmtrWdIOn02ueNJf1B0rkdxt1a0mOSPlAr+7mkWZLul7S0vJ8lqaut7zRJd0uaLeknkvbob9xSvljSnNLnB5K2bSu/S9L/SNq51ucvq/7NRURERKw7kkDEGiFJwNXANNu72N4LOAvYpuEQhwN3A+8oY9W9HfgZ0NMqsP0K26OBfwGutD26vBZ3GPtdtvcFLgM+19+4NYeVPr3lOurl+wDTgLMbXltERETEeiMJRKwphwGP2Z7UKrA9y/ZtDfv3ABcC9wOv7FD3MWAHSduvRoy3ArsOctz2Pi3TgdWJJSIiImKdlAQi1pRRwMx+6nepbTOaBXywVSFpM+B1wPXAFdRWBCTtCGxrewZwFTB2NWJ8MzBnkOMe3erT5gjgmtWIJSIiImKdlAQinikLa9uMRgOTanVHA7fYXg5MBcZIGlbqjqO6wQeYQuftRgP5VklaDgJa5y4GGveW0mdL4Ny28t8DrwcuH2hiSSdK6pXUu3L5slUIPSIiImLtkqcwxZoyDzh2Ffv2AAdJWlw+P59qS9SPSt02kt5V6raTtJvtewcx/rts93aYs79xD7P9hw5jHQb8FbgU+BTwz/1NbHsyMBlg+MjdPIiYIyIiItZKWYGINeVmYLikE1oFkl4m6TX9dZK0JXAwsJPtLttdwElAT3li0rNtb1+rO5dq9WCVre64tlcApwLvkfS81YklIiIiYl2TBCLWCNsGxgBvKI9xnQdMAB4coOs/ADfbfrRWdi3wFmAc1ZOd6qayatuY6npWd1zbv6U6r3HSasYSERERsU5Rdd8XEU+37u5u9/a276SKiIiIWPtImmm7u1NdViAiIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorGNhzqAiA3FnCXL6Bp/w1CHERERG5DFE48a6hBiPZQViPg7kraVNEXSQknzJd0oafda/WmSHpG0Va3sUEnLJN0paYGk82p14yQtlTSr1J3WNt+JpXyBpBmSDi7lV5c+95WxZ5XXgW39L5V0bFvZX9o+9xXz9W3tjpF0Te3zmZLuq31+s6Trap/3k2RJb2zy3UZERESsD5JAxJMkCbgamGZ7F9t7AWcB29Sa9QB3AGPaut9mez9gP+BoSQfV6q60PRo4CPikpB3LfEcDHwAOtv0S4IPA5ZK2tT2m9Hl/GXt0ef10FS6tr5jb/RR4Ve3zq4CHJb2wfD4Q+EnbuLeXnxEREREbhCQQUXcY8JjtSa0C27Ns3wYgaRdgc+Bs+rhptr0CmAVs36Huj8B9wMhSdAbwcdt/KPW/AC4DTlpTF9Qk5lp8S4FlknYtRdsDU6kSB8rPn5ZxBRwLjAMOl7Tpmoo5IiIiYm2WBCLqRgEz+6nvAa4AbgP2qP1m/kmSngvsBtzaoW4nYFPgrlK0d4f5ekv5YHyutsVp1mBjbvNT4EBJewD3Aj8rnzcG9qFayYBqNWWR7YXANOBNnQYrW7R6JfWuXL5skJcVERERsfZJAhGDcRwwxfYTwHeAt9fqXi3pLuAh4HrbD9XqxkqaB/wKuND2I/3MIcCDjOvjtS1OowcRcyc/oVppOBCYDswAXkG1NevuWuw9wJTyfgp9r8hMtt1tu3vYiK06NYmIiIhYpySBiLp5wAGdKiTtQ7Wy8ENJi6luzOs3zbfZ3gd4KfAhSfUb+Stt7w28Gjhf0ralfH6H+fYv5autQcyd/JRaAmH7z1SrJodSzj9IGga8DfiXMu4XgCMlbbEm4o6IiIhYmyWBiLqbgeGSTmgVSHqZpNdQ3XhPsN1VXtsB20vauT6A7XuAc6nON9BWNx34JvDRUvRZ4DOSnl/mGk11puBLa+h6GsXcZj6wHVWyc2cpm0V1wLt1gPv1wGzbO5Zxd6Y6K/HWNRR3RERExForCUQ8ybapnlT0hvIY13nABOBBqt/eX93W5epS3m4ScIikF3Wo+wzwPklb2L4O+BrwU0kLgC8Dx9v+7Rq5oIFjfp2kB2qvV5Xv4OfAH2w/VtpNB17M3xKIng7jTgXeuYbijoiIiFhrqbpfioinW3d3t3t7e4c6jIiIiIgBSZppu7tTXVYgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0lgQiIiIiIiIaSwIRERERERGNJYGIiIiIiIjGkkBERERERERjSSAiIiIiIqKxjYc6gIgNxZwly+gaf8NQhxERsV5YPPGooQ4hYoOVFYgNlKSVkmZJmi3pF5IOLOWHSrq+re2lko6VdHXpc5+kZeX9LEm39FF+oKRpku6ulX27jDlB0pJSNl9STz+xvkfSXEnzStvT63G1tf1L+dklaW6t/OWSbi2xLJD0FUkjJI2TdHFps5GkyyR9TZXFkubUYr+oNu8SScPL5xdIWrwG/lkiIiIi1npZgdhwrbA9GkDSG4Fzgdf018H2mNL+UOB020fX6zuVSwJ4l+3eDkNeYPs8SbsBMyV92/ZjbWMeCZwKHG77QUmbAu8ezIVK2gb4b+A429NVBfU2YItaGwGTgGcB77PtEvthtv/QYdiVwD8ClwwmloiIiIh1XVYgAmBL4H+HanLb9wLLged2qD6TKil5sLR9xPaXBznFScBltqeXMWz727Z/V2tzIfB84D22n2gw5ueB0yQlCY+IKuelqwAAFBRJREFUiIgNSm5+NlybSZoFbAqMBF77NM71LUkryvsf2v54vVLS/sC9tn/foe8oYGY/Y39O0tkDzD8KuKyf+ncCvwQOtf14W90tklaW95fZvqC8vx+4nWo15Lt9DSzpROBEgGFbbj1AmBERERFrvyQQG676FqZXAd+QNApwH+37Km+iry1Mp0k6AXgxcMQqjv1x299ufWidgRikXwAvAV4O/KStrq8tTACfBq4D+jwZbXsyMBlg+MjdVuc7jIiIiFgrZAtTULb2vADYGvgjT91K9Dygr5vo1XGB7T2AsVQJzKYd2swDDljNeQYaYwHwDuBKSXs3HdT2fcCs0jciIiJig5AEIpD0EmAYVfJwL7CdpD1L3c7AvlQ3yk8L298BeoH3dqg+F/ispG1LPMMlfWSQU1wMvFfSK1oFko5vjVli+CnwQeAGSTsNYuxzgNMHGU9ERETEOitbmP7/9u49zK6qPuP49yURISB3ECU04R6BQhKnQgEpNyEIgjygZMASLJb6lHrh0SIIXgpSsFhRq8WHoiBegMpNipaCXARbQCaQkCC3xKRIREHAgJAKJG//2GtwczhnZk+AnMzM+3me88w5a6299to/Vubs3+y1N6NX/z0QAAJm2F4KLJX0PuD8ckXgeeADthe/gn3V74H4re192rQ5FfiepH+r38Rs+0flKUo/Lk9KMvDNoezc9m8kTQe+IGkjYBlwM3B5S7urJW0IXCPp7aW4fg/E3baPatnmHkl3AlOHMqaIiIiI4Up2lmVHrAg9PT3u62t3K0hERETEykXSTNs97eqyhCkiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGhvb7QFEjBZzFi1m4ok/7PYwImIFW3jmAd0eQkTEqypXIEY4SUslzZI0W9KdknYp5RMlzW1p+1lJHy/vL5B0WHl/k6S+WrseSTeV93tIWizpLkn3S7pZ0oHt+myzr0VlbA9KulzStrX6VSV9SdL8Uv8DSeM7HONCSXPKMV4raeNa+Qa1dodIsqRJtbLjyhj6X3NLm7dIOr2l7oESzzVr2/9A0q2N/4NEREREDHNJIEa+JbYn294ROAk4Yzn72UjS/h3qbrE9xfY2wIeBr0rau0GfZ5exbQVcAtwgacNS94/AG4CtS/2VwOWS1KGvPcsx9gGf7NCmF/gpML2/wPbXyhgm254MXAV81/a9tk9uqbsDOMP27wEkrQNMBdaRtFmD442IiIgY9pJAjC5rAU8u57ZnAacM1sj2LOBU4O+G0rntS4BrgSMkjQPeDxxve2mpPx/4A7DXIF3dDGzZWliuGuwKHEMtgWhpszvwXuBv29S9r/T72VrxocB/ABd36jMiIiJipEkCMfKtXpbf3AecB5xWq9uivkQH+OAA/dwK/EHSng32eScwadBWnbfbEnjI9lMt9X3AdoP0cSAwp035u4FrbD8APCFpar2yXE04H5jRul9JE4EzgSNtv1Cr6gUuKq/edoORdKykPkl9S59dPMjQIyIiIlZ+SSBGvv4lTJOAacCFtWVA81uW6Hx9kL4+R4OrEECnZUZNtxPgDvXtygFuLEnQWrRfptVLdaWA8rP1hP8c4Du2//slO5TGAN8BPmV7Xq38jVSJzk9LUvKCpO1bd2r7XNs9tnvGjFu7w9AjIiIiho88hWkUsX1rual4w0Ebt9/+BkmnATsP0nQKcO9y7GIK1VWGecAESW+w/XStfirVkqF29rT923YVktanWvq0vSQDYwBLOsG2Jc0AJgJ/2WbzU4BHyhKqusOBdYEFJR9bi2oZU5MEKyIiImLYyhWIUaQ8fWgM8Pgr6OZ04IQB9rED8Cnga0Mc26HAvsBFtp8BvgV8sVwBQNJRwDjghuUY82HAhbYn2J5oe1NgAbCbpM3LMbUuT0LSzsDRwLFt+uwFppX+JgJvJfdBRERExCiQKxAj3+plaQ9US4Bm2F7a+WFGA7P9I0mPtRS/XdJdVCf4jwIftn19g+6OLzcnrwHMBfay3d/3ScAXgAckLQPuAw6x3WkJ00B6qe5hqLsMOIIqiV6D6glP9foPUV1NGEe1PKpedyjwJ8Bt/QW2F0h6StJOtm9fjjFGREREDAtavvOxiBiqnp4e9/X1Dd4wIiIiosskzbTd064uS5giIiIiIqKxJBAREREREdFYEoiIiIiIiGgsCURERERERDSWBCIiIiIiIhpLAhEREREREY0lgYiIiIiIiMaSQERERERERGNJICIiIiIiorGx3R5AxGgxZ9FiJp74w24PIyJeoYVnHtDtIUREdFWuQIwikpZKmiVptqQ7Je3SUn+8pP+TtHatbA9JV5f3R0taJmmHWv1cSRPL+zUlnSNpvqS7JM2U9NcN92FJ76qVXS1pjzbHcIGkBeU47pP0mZb6DSU9L+lvWsoXSpoj6W5JP5E0QdL6pZ9Zkn4taVHt86qSft/Sx9GSvtpSNlvSRR2DHhERETHCJIEYXZbYnmx7R+Ak4IyW+l7gDuCQAfp4GDi5Q915wJPAVranANOA9RruY6B+W/297cnAZGCGpM1qde8Bbiv7abWn7R2Am4BTbD9e4jEZ+Dpwdv9n288NNghJb6H6N7S7pDUajj0iIiJiWEsCMXqtRXWyD4CkLYA1gVNof/Ld72pgO0nb1AvL9m+jOjFfBmD7Mdufb7iP2cBiSe8YwjGsVn4+UyvrBT4GjJe0SYftbgU61Q3FEcC3gWuBg16F/iIiIiJWekkgRpfV+5f+UF0tOK1W1wtcBNwCbCNpow59LAP+CfhkS/l2wOz+5KGDwfbxOarkYjBnSZpFddXiYtuPAkjaFNjY9s+AfwcO77D9NODKBvtZvbakaRZwakv94cAl5ZjaJl2SjpXUJ6lv6bOLG+wyIiIiYuWWBGJ06V/CNInqJPpCSSp106lOxpcBl1MtBerke8DOLUuHXkLSyeXE+1e14gH3YfuWsu3bBzmO/iVMGwN71+7lmE6VOABczMtP6m+U9CiwTzmGwSypLWmaDHy6dnx/Bjxm+3+B64GpktZt7cD2ubZ7bPeMGbd2a3VERETEsJMEYpSyfSuwAbBhuSl6K+A6SQupTsQ7LmOy/QLwz8AnasU/B3aUtEppc3o56V4LYAj7OJ2G90LY/j3V/Qy7laJe4OjS/1VlPFvVNtkTmADcw8uvJgxVLzCp7Gs+1XEe+gr7jIiIiFjpJYEYpSRNAsYAj1OdDH/W9sTyejOwiaQJA3RxAdVf8jcEsD0P6AM+J2lM2cdqQP8Vjkb7sH0tsC6wY4NjGAvsBMwv92SsYXuT/n1Q3SQ+vaX/JcBHgaMktd7g3UhJkt4D7FDb18EMfO9IRERExIiQBGJ0eXFNP9Xa/Rm2l1KdZF/R0vYKWk6+68pTir4C1O9j+ACwPjBP0kzgx/zxKsVQ9nE6MH6A4+i/B+JuYA7VcqjeNv1fRpuTetuPUN23cNwA+xjI7sAi24tqZTcD20p603L2GRERETEsyHa3xxAxKvT09Livr6/bw4iIiIgYlKSZtnva1eUKRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisSQQERERERHRWBKIiIiIiIhoLAlEREREREQ0NrbbA4gYLeYsWszEE3/Y7WFEREQMGwvPPKDbQ4g2cgUiBiTpEEmWNKlWNlHS3DZtJekUSQ9KekDSjZK2q9WvLelCSfPL60JJa3fY71JJsyTNlfR9SeMajGlJ2ebnpe/XtfT5ZUmLJK1SPr+/tJ8l6TlJc8r7MyUdLemrLdvfJKmn9nlKGcd+Q4tqRERExPCVBCIG0wv8FJjeoO1xwC7Ajra3Bs4ArpK0Wqn/BvAL21vY3gJYAJzXoa8ltifb3h54DvhggzHNtz0Z+FNgPPDe/oqSNBwC/BLYHcD2+WUfk4FfAXuWzyc2ONb6OHobto+IiIgY9pJAREeS1gR2BY6hWQLxCeBDtp8FsH0t8D/AkZK2BN4KnFZrfyrQI2mLQfq9Bdiy6ZhsLwV+BmxSK94TmAucw6twwi9JwGHA0cC+tSQpIiIiYkRLAhEDeTdwje0HgCckTe3UUNJawBq257dU9QHbAdsCs8rJPfDiif6sUt+p37HA/sCcpmMqJ/M7AdfUinuBi4ArgANblzd1cHhtidMsoKdWtyuwoBzvTcA7O4z/WEl9kvqWPru4wS4jIiIiVm5JIGIgvcDF5f3FLN9f7gW49rNTfavVy0l7H/AQ1fKnwca0RdnmceAh23cDSFqV6gT/SttPAbcD+zYY+yX9S5zKMqe+Wl2j2Ng+13aP7Z4x49re7hERERExrOQpTNGWpPWBvYDtJRkYA1jSCe3a235K0jOSNrf9i1rVVOAnwD3AFEmr2F5W9rEKsCNwb5sul5ST9qGMab7tyZLeBNwk6SDbVwHTgLWBOdXKI8YBzwLL9UgkSWOAQ4GDJJ1MlQStL+kNtp9enj4jIiIihotcgYhODgMutD3B9kTbm1Ld9LzbANucBXxF0uoAkvYp7b9nex5wF3BKrf0pwJ2l7lUbk+1HgBOBk0pRL/CBss1EYDOq+xbGsXz2AWbb3rT0OQG4jGp5VURERMSIlgQiOumlul+g7jLgiPJ+G0kP117vAf4FuIPqL/33A58CDra9pGxzDLC1pHmS5gNbl7JXa0x1VwLjJP0FsB+1qw22n6F6etK7hrDv5R1HRERExIgiu93y84h4tfX09Livr2/whhERERFdJmmm7Z52dbkCERERERERjSWBiIiIiIiIxpJAREREREREY0kgIiIiIiKisdxEHbGCSHoauL/b4xhGNgB+2+1BDBOJ1dAkXs0lVkOTeDWXWA1NN+I1wfaG7SryP5KLWHHu7/Q0g3g5SX2JVzOJ1dAkXs0lVkOTeDWXWA3NyhavLGGKiIiIiIjGkkBERERERERjSSAiVpxzuz2AYSbxai6xGprEq7nEamgSr+YSq6FZqeKVm6gjIiIiIqKxXIGIiIiIiIjGkkBERERERERjSSAiVgBJ0yTdL2mepBO7PZ5uk7SppBsl3SvpHkkfKeXrSbpO0oPl57qlXJK+UuJ3t6Sp3T2CFU/SGEl3Sbq6fN5M0u0lVpdIWrWUv758nlfqJ3Zz3N0gaR1Jl0q6r8yxP8/c6kzS8eXf4VxJF0laLfOrIumbkh6VNLdWNuS5JGlGaf+gpBndOJYVoUO8zir/Fu+WdIWkdWp1J5V43S9pv1r5iP/ObBerWt3HJVnSBuXzSje3kkBEvMYkjQG+BuwPbAv0Stq2u6PquheAj9l+C7AzcFyJyYnA9ba3Aq4vn6GK3VbldSxwzoofctd9BLi39vnzwNklVk8Cx5TyY4AnbW8JnF3ajTZfBq6xPQnYkSpumVttSNoE+DDQY3t7YAwwncyvfhcA01rKhjSXJK0HfAbYCXgb8Jn+pGMEuoCXx+s6YHvbOwAPACcBlN/504Htyjb/Wv5QMlq+My/g5bFC0qbAO4CHasUr3dxKAhHx2nsbMM/2L2w/B1wMHNzlMXWV7Uds31neP011grcJVVy+VZp9C3h3eX8wcKErtwHrSHrTCh5210gaDxwAnFc+C9gLuLQ0aY1VfwwvBfYu7UcFSWsBuwPfALD9nO3fkbk1kLHA6pLGAuOAR8j8AsD2zcATLcVDnUv7AdfZfsL2k1Qn1C87cRwJ2sXL9rW2XygfbwPGl/cHAxfb/oPtBcA8qu/LUfGd2WFuQZWYnwDUn3K00s2tJBARr71NgF/WPj9cygIoSyCmALcDb7T9CFRJBrBRaTbaY/glqi+UZeXz+sDval/K9Xi8GKtSv7i0Hy02Bx4Dzi9Lvs6TtAaZW23ZXgR8geqvnY9QzZeZZH4NZKhzaVTPsRZ/BfxneZ94tZB0ELDI9uyWqpUuVkkgIl577f46l+cnA5LWBC4DPmr7qYGatikbFTGUdCDwqO2Z9eI2Td2gbjQYC0wFzrE9BXiGPy4xaWdUx6ssdzgY2Ax4M7AG1XKJVplfg+sUm8QMkHQy1fLV7/YXtWk2auMlaRxwMvDpdtVtyroaqyQQEa+9h4FNa5/HA7/q0lhWGpJeR5U8fNf25aX4N/3LR8rPR0v5aI7hrsBBkhZSXcrfi+qKxDplyQm8NB4vxqrUr037y+Qj1cPAw7ZvL58vpUooMrfa2wdYYPsx288DlwO7kPk1kKHOpdE+xyg39x4IHOk//g/IEq+X2oIqkZ9dft+PB+6UtDErYaySQES89u4AtipPNVmV6qaxq7o8pq4qa6a/Adxr+4u1qquA/qdIzAB+UCs/qjyJYmdgcf8SgpHO9km2x9ueSDV3brB9JHAjcFhp1hqr/hgeVtqP+L/e9bP9a+CXkrYpRXsDPydzq5OHgJ0ljSv/LvvjlfnV2VDn0n8B+0pat1zx2beUjQqSpgGfAA6y/Wyt6ipguqone21GdYPwzxil35m259jeyPbE8vv+YWBq+Z228s0t23nllddr/ALeSfX0ifnAyd0eT7dfwG5Ul1nvBmaV1zup1lJfDzxYfq5X2ovqqRzzgTlUT4zp+nF0IW57AFeX95tTfdnOA74PvL6Ur1Y+zyv1m3d73F2I02Sgr8yvK4F1M7cGjNc/APcBc4FvA6/P/HoxNhdR3RvyPNUJ3THLM5eo1v7PK6/3d/u4VnC85lGt0+//Xf/1WvuTS7zuB/avlY/478x2sWqpXwhssLLOLZWdR0REREREDCpLmCIiIiIiorEkEBERERER0VgSiIiIiIiIaCwJRERERERENJYEIiIiIiIiGksCERERERERjSWBiIiIiIiIxv4fQ6U6CjRCzzAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "data.groupby('MenuItem').ItemQty.sum().plot.barh(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22038, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data = pd.get_dummies(data=data,columns=['Shift','Day','Day Type','MenuCategory'],drop_first=True)\n",
    "prepared_data = prepared_data.drop(columns=['Date','ItemQty'])\n",
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22038, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data['item_id'] = prepared_data['MenuItem'].factorize()[0]\n",
    "prepared_data.drop(columns=['MenuItem'],inplace=True)\n",
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shift_Lunch</th>\n",
       "      <th>Day_Monday</th>\n",
       "      <th>Day_Saturday</th>\n",
       "      <th>Day_Sunday</th>\n",
       "      <th>Day_Thursday</th>\n",
       "      <th>Day_Tuesday</th>\n",
       "      <th>Day_Wednesday</th>\n",
       "      <th>Day Type_Weekend</th>\n",
       "      <th>MenuCategory_CHICKEN SPECIALS</th>\n",
       "      <th>MenuCategory_DESSERTS</th>\n",
       "      <th>MenuCategory_LAMB SPECIALTIES</th>\n",
       "      <th>MenuCategory_RICE SPECIALS</th>\n",
       "      <th>MenuCategory_SEAFOOD SPECIALTIES</th>\n",
       "      <th>MenuCategory_Starter</th>\n",
       "      <th>MenuCategory_VEGETABLE SPECIALS</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Shift_Lunch  Day_Monday  Day_Saturday  Day_Sunday  Day_Thursday  \\\n",
       "0            1           0             0           0             0   \n",
       "1            1           0             0           0             0   \n",
       "2            1           0             0           0             0   \n",
       "3            1           0             0           0             0   \n",
       "4            1           0             0           0             0   \n",
       "\n",
       "   Day_Tuesday  Day_Wednesday  Day Type_Weekend  \\\n",
       "0            1              0                 0   \n",
       "1            1              0                 0   \n",
       "2            1              0                 0   \n",
       "3            1              0                 0   \n",
       "4            1              0                 0   \n",
       "\n",
       "   MenuCategory_CHICKEN SPECIALS  MenuCategory_DESSERTS  \\\n",
       "0                              0                      0   \n",
       "1                              0                      0   \n",
       "2                              0                      0   \n",
       "3                              0                      0   \n",
       "4                              0                      0   \n",
       "\n",
       "   MenuCategory_LAMB SPECIALTIES  MenuCategory_RICE SPECIALS  \\\n",
       "0                              0                           0   \n",
       "1                              0                           0   \n",
       "2                              0                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           0   \n",
       "\n",
       "   MenuCategory_SEAFOOD SPECIALTIES  MenuCategory_Starter  \\\n",
       "0                                 0                     1   \n",
       "1                                 0                     1   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "\n",
       "   MenuCategory_VEGETABLE SPECIALS  item_id  \n",
       "0                                0        0  \n",
       "1                                0        1  \n",
       "2                                1        2  \n",
       "3                                1        3  \n",
       "4                                0        4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = prepared_data.iloc[:,:-1].values\n",
    "Y_features = prepared_data.iloc[:,-1].values\n",
    "\n",
    "Y_features_dummy = pd.get_dummies(Y_features).values\n",
    "print(X_features.shape,Y_features.shape)\n",
    "Y_features_dummy[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note : I have also tried over sampling of data but didn't see much improvements in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(Y_features))\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_features_sampled,Y_features_sampled = oversample.fit_resample(X_features,Y_features)\n",
    "\n",
    "print(Counter(Y_features_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_features,Y_features_dummy,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to create a neural network with 2 hidden layers as our classifier for predicting MenuItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nn = Sequential()\n",
    "\n",
    "classifier_nn.add(Dense(units=128,activation='relu',input_dim=15))\n",
    "classifier_nn.add(Dropout(0.2))\n",
    "classifier_nn.add(Dense(units=64,activation='relu'))\n",
    "classifier_nn.add(Dropout(0.2))\n",
    "classifier_nn.add(Dense(units=64,activation='relu'))\n",
    "classifier_nn.add(Dropout(0.2))\n",
    "classifier_nn.add(Dense(units=43,activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01,nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ashish Vadhan\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "17630/17630 [==============================] - 2s 96us/step - loss: 3.0242 - accuracy: 0.1172\n",
      "Epoch 2/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.9897 - accuracy: 0.1983\n",
      "Epoch 3/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.8976 - accuracy: 0.1969\n",
      "Epoch 4/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.8636 - accuracy: 0.2001\n",
      "Epoch 5/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.8440 - accuracy: 0.2026\n",
      "Epoch 6/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.8327 - accuracy: 0.2001\n",
      "Epoch 7/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.8221 - accuracy: 0.2008\n",
      "Epoch 8/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.8205 - accuracy: 0.2019\n",
      "Epoch 9/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.8161 - accuracy: 0.1986\n",
      "Epoch 10/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.8085 - accuracy: 0.2002\n",
      "Epoch 11/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.8044 - accuracy: 0.2022\n",
      "Epoch 12/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.8031 - accuracy: 0.2030\n",
      "Epoch 13/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.8047 - accuracy: 0.1974\n",
      "Epoch 14/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7997 - accuracy: 0.2020\n",
      "Epoch 15/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7984 - accuracy: 0.2015\n",
      "Epoch 16/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7993 - accuracy: 0.2047\n",
      "Epoch 17/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7952 - accuracy: 0.2044\n",
      "Epoch 18/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7966 - accuracy: 0.2035\n",
      "Epoch 19/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7955 - accuracy: 0.2006\n",
      "Epoch 20/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7948 - accuracy: 0.2049\n",
      "Epoch 21/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7939 - accuracy: 0.2058\n",
      "Epoch 22/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7938 - accuracy: 0.2037\n",
      "Epoch 23/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7931 - accuracy: 0.2054\n",
      "Epoch 24/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7933 - accuracy: 0.2019\n",
      "Epoch 25/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7919 - accuracy: 0.2109\n",
      "Epoch 26/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7924 - accuracy: 0.2037\n",
      "Epoch 27/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7928 - accuracy: 0.2049\n",
      "Epoch 28/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7920 - accuracy: 0.2041\n",
      "Epoch 29/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7923 - accuracy: 0.2022\n",
      "Epoch 30/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7913 - accuracy: 0.2007\n",
      "Epoch 31/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7925 - accuracy: 0.2006\n",
      "Epoch 32/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7912 - accuracy: 0.2057\n",
      "Epoch 33/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7903 - accuracy: 0.2119\n",
      "Epoch 34/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7898 - accuracy: 0.2080\n",
      "Epoch 35/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7901 - accuracy: 0.2056\n",
      "Epoch 36/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7919 - accuracy: 0.2047\n",
      "Epoch 37/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7896 - accuracy: 0.2056\n",
      "Epoch 38/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7904 - accuracy: 0.2035\n",
      "Epoch 39/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7901 - accuracy: 0.2050\n",
      "Epoch 40/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7900 - accuracy: 0.2078\n",
      "Epoch 41/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7888 - accuracy: 0.2106\n",
      "Epoch 42/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7900 - accuracy: 0.2068\n",
      "Epoch 43/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7880 - accuracy: 0.2129\n",
      "Epoch 44/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7879 - accuracy: 0.2080\n",
      "Epoch 45/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7886 - accuracy: 0.2100\n",
      "Epoch 46/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7892 - accuracy: 0.2053\n",
      "Epoch 47/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7878 - accuracy: 0.2123\n",
      "Epoch 48/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7873 - accuracy: 0.2090\n",
      "Epoch 49/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7871 - accuracy: 0.2114\n",
      "Epoch 50/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7875 - accuracy: 0.2137\n",
      "Epoch 51/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7873 - accuracy: 0.2086\n",
      "Epoch 52/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7876 - accuracy: 0.2109\n",
      "Epoch 53/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7891 - accuracy: 0.2099\n",
      "Epoch 54/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7887 - accuracy: 0.2061\n",
      "Epoch 55/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7876 - accuracy: 0.2117\n",
      "Epoch 56/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7872 - accuracy: 0.2117\n",
      "Epoch 57/1000\n",
      "17630/17630 [==============================] - 1s 44us/step - loss: 1.7877 - accuracy: 0.2077\n",
      "Epoch 58/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7880 - accuracy: 0.2105\n",
      "Epoch 59/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7863 - accuracy: 0.2115\n",
      "Epoch 60/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7864 - accuracy: 0.2120\n",
      "Epoch 61/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7864 - accuracy: 0.2137\n",
      "Epoch 62/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7869 - accuracy: 0.2085\n",
      "Epoch 63/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7874 - accuracy: 0.2078\n",
      "Epoch 64/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7864 - accuracy: 0.2092\n",
      "Epoch 65/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7863 - accuracy: 0.2102\n",
      "Epoch 66/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7859 - accuracy: 0.2146\n",
      "Epoch 67/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7867 - accuracy: 0.2085\n",
      "Epoch 68/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7868 - accuracy: 0.2132\n",
      "Epoch 69/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7845 - accuracy: 0.2132\n",
      "Epoch 70/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7868 - accuracy: 0.2097\n",
      "Epoch 71/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7860 - accuracy: 0.2130\n",
      "Epoch 72/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7854 - accuracy: 0.2137\n",
      "Epoch 73/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7864 - accuracy: 0.2138\n",
      "Epoch 74/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7843 - accuracy: 0.2165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7861 - accuracy: 0.2136\n",
      "Epoch 76/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7861 - accuracy: 0.2120\n",
      "Epoch 77/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7849 - accuracy: 0.2148\n",
      "Epoch 78/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7850 - accuracy: 0.2178\n",
      "Epoch 79/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7856 - accuracy: 0.2111\n",
      "Epoch 80/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7854 - accuracy: 0.2140\n",
      "Epoch 81/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7863 - accuracy: 0.2091\n",
      "Epoch 82/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7856 - accuracy: 0.2096\n",
      "Epoch 83/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7850 - accuracy: 0.2099\n",
      "Epoch 84/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7853 - accuracy: 0.2154\n",
      "Epoch 85/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7845 - accuracy: 0.2155\n",
      "Epoch 86/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7854 - accuracy: 0.2180\n",
      "Epoch 87/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7846 - accuracy: 0.2153\n",
      "Epoch 88/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7857 - accuracy: 0.2138\n",
      "Epoch 89/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7848 - accuracy: 0.2161\n",
      "Epoch 90/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7852 - accuracy: 0.2180\n",
      "Epoch 91/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7854 - accuracy: 0.2144\n",
      "Epoch 92/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7847 - accuracy: 0.2136\n",
      "Epoch 93/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7852 - accuracy: 0.2152\n",
      "Epoch 94/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7852 - accuracy: 0.2164\n",
      "Epoch 95/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7848 - accuracy: 0.2157\n",
      "Epoch 96/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7843 - accuracy: 0.2121\n",
      "Epoch 97/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7852 - accuracy: 0.2133\n",
      "Epoch 98/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7830 - accuracy: 0.2201\n",
      "Epoch 99/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7838 - accuracy: 0.2205\n",
      "Epoch 100/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7851 - accuracy: 0.2159\n",
      "Epoch 101/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7838 - accuracy: 0.2183\n",
      "Epoch 102/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7845 - accuracy: 0.2153\n",
      "Epoch 103/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7839 - accuracy: 0.2162\n",
      "Epoch 104/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7852 - accuracy: 0.2158\n",
      "Epoch 105/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7833 - accuracy: 0.2178\n",
      "Epoch 106/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7853 - accuracy: 0.2143\n",
      "Epoch 107/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7852 - accuracy: 0.2135\n",
      "Epoch 108/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7836 - accuracy: 0.2179\n",
      "Epoch 109/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7838 - accuracy: 0.2149\n",
      "Epoch 110/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7832 - accuracy: 0.2192\n",
      "Epoch 111/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7835 - accuracy: 0.2133\n",
      "Epoch 112/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7835 - accuracy: 0.2162\n",
      "Epoch 113/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7849 - accuracy: 0.2105\n",
      "Epoch 114/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7833 - accuracy: 0.2132\n",
      "Epoch 115/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7834 - accuracy: 0.2195\n",
      "Epoch 116/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7842 - accuracy: 0.2165\n",
      "Epoch 117/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7837 - accuracy: 0.2200\n",
      "Epoch 118/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7837 - accuracy: 0.2166\n",
      "Epoch 119/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7833 - accuracy: 0.2142\n",
      "Epoch 120/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7832 - accuracy: 0.2151\n",
      "Epoch 121/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7840 - accuracy: 0.2158\n",
      "Epoch 122/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7831 - accuracy: 0.2195\n",
      "Epoch 123/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7833 - accuracy: 0.2191\n",
      "Epoch 124/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7830 - accuracy: 0.2140\n",
      "Epoch 125/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7834 - accuracy: 0.2175\n",
      "Epoch 126/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7826 - accuracy: 0.2176\n",
      "Epoch 127/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7834 - accuracy: 0.2189\n",
      "Epoch 128/1000\n",
      "17630/17630 [==============================] - ETA: 0s - loss: 1.7832 - accuracy: 0.21 - 1s 34us/step - loss: 1.7836 - accuracy: 0.2164\n",
      "Epoch 129/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7837 - accuracy: 0.2179\n",
      "Epoch 130/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7824 - accuracy: 0.2179\n",
      "Epoch 131/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7818 - accuracy: 0.2219\n",
      "Epoch 132/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7817 - accuracy: 0.2195\n",
      "Epoch 133/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7817 - accuracy: 0.2202\n",
      "Epoch 134/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7825 - accuracy: 0.2156\n",
      "Epoch 135/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7829 - accuracy: 0.2176\n",
      "Epoch 136/1000\n",
      "17630/17630 [==============================] - 1s 41us/step - loss: 1.7821 - accuracy: 0.2145\n",
      "Epoch 137/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7828 - accuracy: 0.2174\n",
      "Epoch 138/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7823 - accuracy: 0.2184\n",
      "Epoch 139/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7822 - accuracy: 0.2193\n",
      "Epoch 140/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7827 - accuracy: 0.2178\n",
      "Epoch 141/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7818 - accuracy: 0.2199\n",
      "Epoch 142/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7824 - accuracy: 0.2200\n",
      "Epoch 143/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7823 - accuracy: 0.2158\n",
      "Epoch 144/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7822 - accuracy: 0.2221\n",
      "Epoch 145/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7834 - accuracy: 0.2176\n",
      "Epoch 146/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.7820 - accuracy: 0.2192\n",
      "Epoch 147/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7827 - accuracy: 0.2161\n",
      "Epoch 148/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7826 - accuracy: 0.2171\n",
      "Epoch 149/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7829 - accuracy: 0.2193\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7827 - accuracy: 0.2212\n",
      "Epoch 151/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7830 - accuracy: 0.2185\n",
      "Epoch 152/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7823 - accuracy: 0.2175\n",
      "Epoch 153/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7822 - accuracy: 0.2188\n",
      "Epoch 154/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7829 - accuracy: 0.2206\n",
      "Epoch 155/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7819 - accuracy: 0.2201\n",
      "Epoch 156/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7819 - accuracy: 0.2184\n",
      "Epoch 157/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7827 - accuracy: 0.2207\n",
      "Epoch 158/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7829 - accuracy: 0.2222\n",
      "Epoch 159/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7824 - accuracy: 0.2171\n",
      "Epoch 160/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7816 - accuracy: 0.2213\n",
      "Epoch 161/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7825 - accuracy: 0.2210\n",
      "Epoch 162/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7816 - accuracy: 0.2188\n",
      "Epoch 163/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7817 - accuracy: 0.2226\n",
      "Epoch 164/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7817 - accuracy: 0.2183\n",
      "Epoch 165/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7818 - accuracy: 0.2235\n",
      "Epoch 166/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7816 - accuracy: 0.2201\n",
      "Epoch 167/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7822 - accuracy: 0.2167\n",
      "Epoch 168/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7824 - accuracy: 0.2187\n",
      "Epoch 169/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7825 - accuracy: 0.2186\n",
      "Epoch 170/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7817 - accuracy: 0.2204\n",
      "Epoch 171/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7821 - accuracy: 0.2190\n",
      "Epoch 172/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7819 - accuracy: 0.2206\n",
      "Epoch 173/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7811 - accuracy: 0.2196\n",
      "Epoch 174/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7822 - accuracy: 0.2189\n",
      "Epoch 175/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7822 - accuracy: 0.2156\n",
      "Epoch 176/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7818 - accuracy: 0.2195\n",
      "Epoch 177/1000\n",
      "17630/17630 [==============================] - ETA: 0s - loss: 1.7809 - accuracy: 0.22 - 1s 34us/step - loss: 1.7808 - accuracy: 0.2218\n",
      "Epoch 178/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7820 - accuracy: 0.2225\n",
      "Epoch 179/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7812 - accuracy: 0.2177\n",
      "Epoch 180/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7824 - accuracy: 0.2194\n",
      "Epoch 181/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7812 - accuracy: 0.2197\n",
      "Epoch 182/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7817 - accuracy: 0.2190\n",
      "Epoch 183/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7814 - accuracy: 0.2175\n",
      "Epoch 184/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7815 - accuracy: 0.2213\n",
      "Epoch 185/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7821 - accuracy: 0.2192\n",
      "Epoch 186/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7826 - accuracy: 0.2172\n",
      "Epoch 187/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7808 - accuracy: 0.2190\n",
      "Epoch 188/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7814 - accuracy: 0.2214\n",
      "Epoch 189/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7815 - accuracy: 0.2202\n",
      "Epoch 190/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7817 - accuracy: 0.2192\n",
      "Epoch 191/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7808 - accuracy: 0.2195\n",
      "Epoch 192/1000\n",
      "17630/17630 [==============================] - 1s 41us/step - loss: 1.7821 - accuracy: 0.2214\n",
      "Epoch 193/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7811 - accuracy: 0.2192\n",
      "Epoch 194/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7805 - accuracy: 0.2223\n",
      "Epoch 195/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7831 - accuracy: 0.2169\n",
      "Epoch 196/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7805 - accuracy: 0.2212\n",
      "Epoch 197/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.7808 - accuracy: 0.2206\n",
      "Epoch 198/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7811 - accuracy: 0.2213\n",
      "Epoch 199/1000\n",
      "17630/17630 [==============================] - 1s 41us/step - loss: 1.7816 - accuracy: 0.2216\n",
      "Epoch 200/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7809 - accuracy: 0.2246\n",
      "Epoch 201/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7810 - accuracy: 0.2231\n",
      "Epoch 202/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2208\n",
      "Epoch 203/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7830 - accuracy: 0.2216\n",
      "Epoch 204/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7816 - accuracy: 0.2234\n",
      "Epoch 205/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7804 - accuracy: 0.2209\n",
      "Epoch 206/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7819 - accuracy: 0.2184\n",
      "Epoch 207/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7802 - accuracy: 0.2194\n",
      "Epoch 208/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7813 - accuracy: 0.2191\n",
      "Epoch 209/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2194\n",
      "Epoch 210/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7807 - accuracy: 0.2238\n",
      "Epoch 211/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7807 - accuracy: 0.2213\n",
      "Epoch 212/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7805 - accuracy: 0.2220\n",
      "Epoch 213/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7806 - accuracy: 0.2218\n",
      "Epoch 214/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7807 - accuracy: 0.2212\n",
      "Epoch 215/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7804 - accuracy: 0.2188\n",
      "Epoch 216/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7816 - accuracy: 0.2234\n",
      "Epoch 217/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7817 - accuracy: 0.2165\n",
      "Epoch 218/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2205\n",
      "Epoch 219/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7815 - accuracy: 0.2251\n",
      "Epoch 220/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7810 - accuracy: 0.2212\n",
      "Epoch 221/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7805 - accuracy: 0.2205\n",
      "Epoch 222/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7808 - accuracy: 0.2199\n",
      "Epoch 223/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7810 - accuracy: 0.2226\n",
      "Epoch 224/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7804 - accuracy: 0.2233\n",
      "Epoch 225/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7816 - accuracy: 0.2201\n",
      "Epoch 226/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7809 - accuracy: 0.2188\n",
      "Epoch 227/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7807 - accuracy: 0.2217\n",
      "Epoch 228/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7811 - accuracy: 0.2237\n",
      "Epoch 229/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7818 - accuracy: 0.2206\n",
      "Epoch 230/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2234\n",
      "Epoch 231/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7816 - accuracy: 0.2187\n",
      "Epoch 232/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7803 - accuracy: 0.2222\n",
      "Epoch 233/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7803 - accuracy: 0.2186\n",
      "Epoch 234/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7815 - accuracy: 0.2178\n",
      "Epoch 235/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7810 - accuracy: 0.2225\n",
      "Epoch 236/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7818 - accuracy: 0.2166\n",
      "Epoch 237/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7790 - accuracy: 0.2276\n",
      "Epoch 238/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7816 - accuracy: 0.2217\n",
      "Epoch 239/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7806 - accuracy: 0.2220\n",
      "Epoch 240/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7808 - accuracy: 0.2197\n",
      "Epoch 241/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2214\n",
      "Epoch 242/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7798 - accuracy: 0.2277\n",
      "Epoch 243/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7812 - accuracy: 0.2183\n",
      "Epoch 244/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7811 - accuracy: 0.2221\n",
      "Epoch 245/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2246\n",
      "Epoch 246/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7797 - accuracy: 0.2223\n",
      "Epoch 247/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2226\n",
      "Epoch 248/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7808 - accuracy: 0.2209\n",
      "Epoch 249/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7808 - accuracy: 0.2229\n",
      "Epoch 250/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7798 - accuracy: 0.2239\n",
      "Epoch 251/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7821 - accuracy: 0.2135\n",
      "Epoch 252/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2223\n",
      "Epoch 253/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7804 - accuracy: 0.2233\n",
      "Epoch 254/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2217\n",
      "Epoch 255/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7802 - accuracy: 0.2195\n",
      "Epoch 256/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2231\n",
      "Epoch 257/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7813 - accuracy: 0.2181\n",
      "Epoch 258/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7805 - accuracy: 0.2230\n",
      "Epoch 259/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7814 - accuracy: 0.2227\n",
      "Epoch 260/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7817 - accuracy: 0.2156\n",
      "Epoch 261/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2175\n",
      "Epoch 262/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7805 - accuracy: 0.2250\n",
      "Epoch 263/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7802 - accuracy: 0.2214\n",
      "Epoch 264/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2216\n",
      "Epoch 265/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7805 - accuracy: 0.2246\n",
      "Epoch 266/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7809 - accuracy: 0.2215\n",
      "Epoch 267/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7809 - accuracy: 0.2174\n",
      "Epoch 268/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7811 - accuracy: 0.2210\n",
      "Epoch 269/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7802 - accuracy: 0.2247\n",
      "Epoch 270/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7796 - accuracy: 0.2235\n",
      "Epoch 271/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2242\n",
      "Epoch 272/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7804 - accuracy: 0.2212\n",
      "Epoch 273/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2213\n",
      "Epoch 274/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7796 - accuracy: 0.2242\n",
      "Epoch 275/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7800 - accuracy: 0.2216\n",
      "Epoch 276/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7803 - accuracy: 0.2220\n",
      "Epoch 277/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2268\n",
      "Epoch 278/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2212\n",
      "Epoch 279/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2220\n",
      "Epoch 280/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7808 - accuracy: 0.2231\n",
      "Epoch 281/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7802 - accuracy: 0.2260\n",
      "Epoch 282/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7803 - accuracy: 0.2220\n",
      "Epoch 283/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7802 - accuracy: 0.2202\n",
      "Epoch 284/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7797 - accuracy: 0.2187\n",
      "Epoch 285/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7800 - accuracy: 0.2223\n",
      "Epoch 286/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7808 - accuracy: 0.2222\n",
      "Epoch 287/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7807 - accuracy: 0.2185\n",
      "Epoch 288/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7807 - accuracy: 0.2213 0s - loss: 1.7828 \n",
      "Epoch 289/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7803 - accuracy: 0.2226\n",
      "Epoch 290/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7807 - accuracy: 0.2230\n",
      "Epoch 291/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7800 - accuracy: 0.2217\n",
      "Epoch 292/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2234\n",
      "Epoch 293/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7803 - accuracy: 0.2227\n",
      "Epoch 294/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7800 - accuracy: 0.2235\n",
      "Epoch 295/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2254\n",
      "Epoch 296/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7802 - accuracy: 0.2276\n",
      "Epoch 297/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7797 - accuracy: 0.2234\n",
      "Epoch 298/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7792 - accuracy: 0.2220\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7801 - accuracy: 0.2208\n",
      "Epoch 300/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7794 - accuracy: 0.2208\n",
      "Epoch 301/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2235\n",
      "Epoch 302/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7805 - accuracy: 0.2250\n",
      "Epoch 303/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7795 - accuracy: 0.2228\n",
      "Epoch 304/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7796 - accuracy: 0.2185\n",
      "Epoch 305/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2239\n",
      "Epoch 306/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7795 - accuracy: 0.2221\n",
      "Epoch 307/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7798 - accuracy: 0.2196\n",
      "Epoch 308/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2282\n",
      "Epoch 309/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2211\n",
      "Epoch 310/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7799 - accuracy: 0.2221\n",
      "Epoch 311/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.7801 - accuracy: 0.2227\n",
      "Epoch 312/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7799 - accuracy: 0.2212\n",
      "Epoch 313/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2224\n",
      "Epoch 314/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7805 - accuracy: 0.2221\n",
      "Epoch 315/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7799 - accuracy: 0.2244\n",
      "Epoch 316/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7809 - accuracy: 0.2230\n",
      "Epoch 317/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2243\n",
      "Epoch 318/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7798 - accuracy: 0.2233\n",
      "Epoch 319/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7798 - accuracy: 0.2255\n",
      "Epoch 320/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2234\n",
      "Epoch 321/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2259\n",
      "Epoch 322/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2226\n",
      "Epoch 323/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2279\n",
      "Epoch 324/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7793 - accuracy: 0.2235\n",
      "Epoch 325/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2266\n",
      "Epoch 326/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7796 - accuracy: 0.2230\n",
      "Epoch 327/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2236\n",
      "Epoch 328/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7799 - accuracy: 0.2209\n",
      "Epoch 329/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7796 - accuracy: 0.2229\n",
      "Epoch 330/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7803 - accuracy: 0.2239\n",
      "Epoch 331/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2210\n",
      "Epoch 332/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2220\n",
      "Epoch 333/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7792 - accuracy: 0.2227\n",
      "Epoch 334/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7813 - accuracy: 0.2232\n",
      "Epoch 335/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7797 - accuracy: 0.2183\n",
      "Epoch 336/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7787 - accuracy: 0.2264\n",
      "Epoch 337/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2228\n",
      "Epoch 338/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7794 - accuracy: 0.2214\n",
      "Epoch 339/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7792 - accuracy: 0.2223\n",
      "Epoch 340/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7801 - accuracy: 0.2196\n",
      "Epoch 341/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7792 - accuracy: 0.2219\n",
      "Epoch 342/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7780 - accuracy: 0.2302\n",
      "Epoch 343/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7798 - accuracy: 0.2201\n",
      "Epoch 344/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7805 - accuracy: 0.2201\n",
      "Epoch 345/1000\n",
      "17630/17630 [==============================] - 1s 41us/step - loss: 1.7801 - accuracy: 0.2209\n",
      "Epoch 346/1000\n",
      "17630/17630 [==============================] - 1s 44us/step - loss: 1.7800 - accuracy: 0.2221\n",
      "Epoch 347/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7785 - accuracy: 0.2213\n",
      "Epoch 348/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7791 - accuracy: 0.2251\n",
      "Epoch 349/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7796 - accuracy: 0.2257\n",
      "Epoch 350/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7799 - accuracy: 0.2220\n",
      "Epoch 351/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2213\n",
      "Epoch 352/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7794 - accuracy: 0.2243\n",
      "Epoch 353/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7790 - accuracy: 0.2248\n",
      "Epoch 354/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7791 - accuracy: 0.2225\n",
      "Epoch 355/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7790 - accuracy: 0.2234\n",
      "Epoch 356/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7804 - accuracy: 0.2235\n",
      "Epoch 357/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7789 - accuracy: 0.2268\n",
      "Epoch 358/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7797 - accuracy: 0.2229\n",
      "Epoch 359/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7796 - accuracy: 0.2208\n",
      "Epoch 360/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7804 - accuracy: 0.2211\n",
      "Epoch 361/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7801 - accuracy: 0.2220\n",
      "Epoch 362/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7789 - accuracy: 0.2253\n",
      "Epoch 363/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7793 - accuracy: 0.2208\n",
      "Epoch 364/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7791 - accuracy: 0.2227\n",
      "Epoch 365/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2200\n",
      "Epoch 366/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7800 - accuracy: 0.2239\n",
      "Epoch 367/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7793 - accuracy: 0.2263\n",
      "Epoch 368/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7788 - accuracy: 0.2249\n",
      "Epoch 369/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7795 - accuracy: 0.2218\n",
      "Epoch 370/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7793 - accuracy: 0.2250\n",
      "Epoch 371/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7804 - accuracy: 0.2229\n",
      "Epoch 372/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7786 - accuracy: 0.2247\n",
      "Epoch 373/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7797 - accuracy: 0.2233\n",
      "Epoch 374/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7799 - accuracy: 0.2201\n",
      "Epoch 375/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7800 - accuracy: 0.2275\n",
      "Epoch 376/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7804 - accuracy: 0.2218\n",
      "Epoch 377/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2221\n",
      "Epoch 378/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7791 - accuracy: 0.2233\n",
      "Epoch 379/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2240\n",
      "Epoch 380/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2232\n",
      "Epoch 381/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2233\n",
      "Epoch 382/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7800 - accuracy: 0.2255\n",
      "Epoch 383/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2249\n",
      "Epoch 384/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7787 - accuracy: 0.2238\n",
      "Epoch 385/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7801 - accuracy: 0.2209\n",
      "Epoch 386/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7796 - accuracy: 0.2236\n",
      "Epoch 387/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7795 - accuracy: 0.2190\n",
      "Epoch 388/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2228\n",
      "Epoch 389/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2259\n",
      "Epoch 390/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7800 - accuracy: 0.2251\n",
      "Epoch 391/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2230\n",
      "Epoch 392/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7801 - accuracy: 0.2214\n",
      "Epoch 393/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2225\n",
      "Epoch 394/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2258\n",
      "Epoch 395/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2213\n",
      "Epoch 396/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2248\n",
      "Epoch 397/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2241\n",
      "Epoch 398/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2225\n",
      "Epoch 399/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7793 - accuracy: 0.2240\n",
      "Epoch 400/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2259\n",
      "Epoch 401/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2280\n",
      "Epoch 402/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2229\n",
      "Epoch 403/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2242\n",
      "Epoch 404/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2174\n",
      "Epoch 405/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2237\n",
      "Epoch 406/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2206\n",
      "Epoch 407/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7797 - accuracy: 0.2231\n",
      "Epoch 408/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2225\n",
      "Epoch 409/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2210\n",
      "Epoch 410/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2230\n",
      "Epoch 411/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2248\n",
      "Epoch 412/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2229\n",
      "Epoch 413/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7792 - accuracy: 0.2245\n",
      "Epoch 414/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2209\n",
      "Epoch 415/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2230\n",
      "Epoch 416/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7796 - accuracy: 0.2207\n",
      "Epoch 417/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7801 - accuracy: 0.2227\n",
      "Epoch 418/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2258\n",
      "Epoch 419/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2226\n",
      "Epoch 420/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2234\n",
      "Epoch 421/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7797 - accuracy: 0.2238\n",
      "Epoch 422/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2256\n",
      "Epoch 423/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2272\n",
      "Epoch 424/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2268\n",
      "Epoch 425/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2248\n",
      "Epoch 426/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2252\n",
      "Epoch 427/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2268\n",
      "Epoch 428/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2272\n",
      "Epoch 429/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2231\n",
      "Epoch 430/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2271\n",
      "Epoch 431/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2192\n",
      "Epoch 432/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2234\n",
      "Epoch 433/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2278\n",
      "Epoch 434/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2235\n",
      "Epoch 435/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2232\n",
      "Epoch 436/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2248\n",
      "Epoch 437/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2223\n",
      "Epoch 438/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2257\n",
      "Epoch 439/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7796 - accuracy: 0.2254\n",
      "Epoch 440/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2221\n",
      "Epoch 441/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2226\n",
      "Epoch 442/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7795 - accuracy: 0.2206\n",
      "Epoch 443/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2285\n",
      "Epoch 444/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7795 - accuracy: 0.2246\n",
      "Epoch 445/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2229\n",
      "Epoch 446/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7792 - accuracy: 0.2237\n",
      "Epoch 447/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7793 - accuracy: 0.2259\n",
      "Epoch 448/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2228\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2245\n",
      "Epoch 450/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2224\n",
      "Epoch 451/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7786 - accuracy: 0.2238\n",
      "Epoch 452/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2216\n",
      "Epoch 453/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7798 - accuracy: 0.2246\n",
      "Epoch 454/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2226\n",
      "Epoch 455/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2231\n",
      "Epoch 456/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7787 - accuracy: 0.2240\n",
      "Epoch 457/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7793 - accuracy: 0.2207\n",
      "Epoch 458/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7783 - accuracy: 0.2237\n",
      "Epoch 459/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7786 - accuracy: 0.2226\n",
      "Epoch 460/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7781 - accuracy: 0.2247\n",
      "Epoch 461/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7789 - accuracy: 0.2221\n",
      "Epoch 462/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7786 - accuracy: 0.2242\n",
      "Epoch 463/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7790 - accuracy: 0.2233\n",
      "Epoch 464/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7792 - accuracy: 0.2218\n",
      "Epoch 465/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2277\n",
      "Epoch 466/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.7794 - accuracy: 0.2237\n",
      "Epoch 467/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7792 - accuracy: 0.2218\n",
      "Epoch 468/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7783 - accuracy: 0.2253\n",
      "Epoch 469/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7795 - accuracy: 0.2223\n",
      "Epoch 470/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2216\n",
      "Epoch 471/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2262 0s - loss: 1.784\n",
      "Epoch 472/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2261\n",
      "Epoch 473/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2229\n",
      "Epoch 474/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7790 - accuracy: 0.2233\n",
      "Epoch 475/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7788 - accuracy: 0.2242\n",
      "Epoch 476/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7794 - accuracy: 0.2253\n",
      "Epoch 477/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7793 - accuracy: 0.2242\n",
      "Epoch 478/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7783 - accuracy: 0.2243\n",
      "Epoch 479/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7792 - accuracy: 0.2251\n",
      "Epoch 480/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7782 - accuracy: 0.2244\n",
      "Epoch 481/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7789 - accuracy: 0.2249\n",
      "Epoch 482/1000\n",
      "17630/17630 [==============================] - 1s 40us/step - loss: 1.7791 - accuracy: 0.2255\n",
      "Epoch 483/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7777 - accuracy: 0.2253\n",
      "Epoch 484/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7786 - accuracy: 0.2259\n",
      "Epoch 485/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7778 - accuracy: 0.2256\n",
      "Epoch 486/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7784 - accuracy: 0.2254\n",
      "Epoch 487/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7797 - accuracy: 0.2218\n",
      "Epoch 488/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2248\n",
      "Epoch 489/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7788 - accuracy: 0.2231\n",
      "Epoch 490/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7788 - accuracy: 0.2284\n",
      "Epoch 491/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7778 - accuracy: 0.2240\n",
      "Epoch 492/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2262\n",
      "Epoch 493/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7788 - accuracy: 0.2236 0s - loss: 1.752\n",
      "Epoch 494/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7791 - accuracy: 0.2281\n",
      "Epoch 495/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2251\n",
      "Epoch 496/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7798 - accuracy: 0.2219\n",
      "Epoch 497/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7787 - accuracy: 0.2281\n",
      "Epoch 498/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2245\n",
      "Epoch 499/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2250\n",
      "Epoch 500/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7786 - accuracy: 0.2249\n",
      "Epoch 501/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7788 - accuracy: 0.2234\n",
      "Epoch 502/1000\n",
      "17630/17630 [==============================] - 1s 31us/step - loss: 1.7797 - accuracy: 0.2262\n",
      "Epoch 503/1000\n",
      "17630/17630 [==============================] - 1s 31us/step - loss: 1.7791 - accuracy: 0.2248\n",
      "Epoch 504/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2248\n",
      "Epoch 505/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2227\n",
      "Epoch 506/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2246 0s - loss: 1.7882 \n",
      "Epoch 507/1000\n",
      "17630/17630 [==============================] - 1s 30us/step - loss: 1.7789 - accuracy: 0.2222\n",
      "Epoch 508/1000\n",
      "17630/17630 [==============================] - 1s 31us/step - loss: 1.7787 - accuracy: 0.2212\n",
      "Epoch 509/1000\n",
      "17630/17630 [==============================] - 1s 31us/step - loss: 1.7782 - accuracy: 0.2272\n",
      "Epoch 510/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7781 - accuracy: 0.2244\n",
      "Epoch 511/1000\n",
      "17630/17630 [==============================] - 1s 44us/step - loss: 1.7787 - accuracy: 0.2251\n",
      "Epoch 512/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7785 - accuracy: 0.2270\n",
      "Epoch 513/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2232\n",
      "Epoch 514/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7788 - accuracy: 0.2246\n",
      "Epoch 515/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7790 - accuracy: 0.2259\n",
      "Epoch 516/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2275\n",
      "Epoch 517/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2240\n",
      "Epoch 518/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2273\n",
      "Epoch 519/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2243\n",
      "Epoch 520/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2256\n",
      "Epoch 521/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7795 - accuracy: 0.2210\n",
      "Epoch 522/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7788 - accuracy: 0.2248\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2237\n",
      "Epoch 524/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2258\n",
      "Epoch 525/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2215\n",
      "Epoch 526/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2290\n",
      "Epoch 527/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7784 - accuracy: 0.2280\n",
      "Epoch 528/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7797 - accuracy: 0.2244\n",
      "Epoch 529/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2298\n",
      "Epoch 530/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7775 - accuracy: 0.2286\n",
      "Epoch 531/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2244\n",
      "Epoch 532/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2249\n",
      "Epoch 533/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7781 - accuracy: 0.2252\n",
      "Epoch 534/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2248\n",
      "Epoch 535/1000\n",
      "17630/17630 [==============================] - 1s 44us/step - loss: 1.7790 - accuracy: 0.2245\n",
      "Epoch 536/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7790 - accuracy: 0.2237\n",
      "Epoch 537/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7784 - accuracy: 0.2256\n",
      "Epoch 538/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7785 - accuracy: 0.2252\n",
      "Epoch 539/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7795 - accuracy: 0.2235\n",
      "Epoch 540/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7772 - accuracy: 0.2251\n",
      "Epoch 541/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7792 - accuracy: 0.2252\n",
      "Epoch 542/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7788 - accuracy: 0.2279\n",
      "Epoch 543/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2252\n",
      "Epoch 544/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2250\n",
      "Epoch 545/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2246\n",
      "Epoch 546/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7780 - accuracy: 0.2267\n",
      "Epoch 547/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2257\n",
      "Epoch 548/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2232\n",
      "Epoch 549/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2221\n",
      "Epoch 550/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2230\n",
      "Epoch 551/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7797 - accuracy: 0.2205\n",
      "Epoch 552/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2267\n",
      "Epoch 553/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2265\n",
      "Epoch 554/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2243\n",
      "Epoch 555/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2244\n",
      "Epoch 556/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2227\n",
      "Epoch 557/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2215\n",
      "Epoch 558/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2221\n",
      "Epoch 559/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2241\n",
      "Epoch 560/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2216\n",
      "Epoch 561/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2223\n",
      "Epoch 562/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2267\n",
      "Epoch 563/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2239\n",
      "Epoch 564/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2256\n",
      "Epoch 565/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2280\n",
      "Epoch 566/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2235\n",
      "Epoch 567/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2239\n",
      "Epoch 568/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2246\n",
      "Epoch 569/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2258\n",
      "Epoch 570/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2272\n",
      "Epoch 571/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7772 - accuracy: 0.2260\n",
      "Epoch 572/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2244\n",
      "Epoch 573/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2229\n",
      "Epoch 574/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2257\n",
      "Epoch 575/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2250\n",
      "Epoch 576/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2290\n",
      "Epoch 577/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2222\n",
      "Epoch 578/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7772 - accuracy: 0.2284\n",
      "Epoch 579/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7793 - accuracy: 0.2204\n",
      "Epoch 580/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2244\n",
      "Epoch 581/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7783 - accuracy: 0.2256\n",
      "Epoch 582/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2240\n",
      "Epoch 583/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2256\n",
      "Epoch 584/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2222\n",
      "Epoch 585/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7786 - accuracy: 0.2251\n",
      "Epoch 586/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2231\n",
      "Epoch 587/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2233\n",
      "Epoch 588/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2259\n",
      "Epoch 589/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2230\n",
      "Epoch 590/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2248\n",
      "Epoch 591/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2246\n",
      "Epoch 592/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2248\n",
      "Epoch 593/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2251\n",
      "Epoch 594/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2262\n",
      "Epoch 595/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7799 - accuracy: 0.2270\n",
      "Epoch 596/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2287\n",
      "Epoch 597/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2263\n",
      "Epoch 598/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7784 - accuracy: 0.2239\n",
      "Epoch 599/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7790 - accuracy: 0.2236\n",
      "Epoch 600/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2216\n",
      "Epoch 601/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2251\n",
      "Epoch 602/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7786 - accuracy: 0.2231\n",
      "Epoch 603/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2260\n",
      "Epoch 604/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2254\n",
      "Epoch 605/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2265\n",
      "Epoch 606/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2258\n",
      "Epoch 607/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2211\n",
      "Epoch 608/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2268\n",
      "Epoch 609/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7786 - accuracy: 0.2237\n",
      "Epoch 610/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2258\n",
      "Epoch 611/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2273\n",
      "Epoch 612/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2268\n",
      "Epoch 613/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2299\n",
      "Epoch 614/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2262\n",
      "Epoch 615/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2275\n",
      "Epoch 616/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2271\n",
      "Epoch 617/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7783 - accuracy: 0.2262\n",
      "Epoch 618/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2223\n",
      "Epoch 619/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2238\n",
      "Epoch 620/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2261\n",
      "Epoch 621/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7790 - accuracy: 0.2255\n",
      "Epoch 622/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7777 - accuracy: 0.2294\n",
      "Epoch 623/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2245\n",
      "Epoch 624/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2261\n",
      "Epoch 625/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7783 - accuracy: 0.2286\n",
      "Epoch 626/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7781 - accuracy: 0.2220\n",
      "Epoch 627/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7788 - accuracy: 0.2266\n",
      "Epoch 628/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2213\n",
      "Epoch 629/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2268\n",
      "Epoch 630/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2256\n",
      "Epoch 631/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2255\n",
      "Epoch 632/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2238\n",
      "Epoch 633/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2239\n",
      "Epoch 634/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2267\n",
      "Epoch 635/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2279\n",
      "Epoch 636/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2257\n",
      "Epoch 637/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2215\n",
      "Epoch 638/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7794 - accuracy: 0.2237\n",
      "Epoch 639/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2274\n",
      "Epoch 640/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2243\n",
      "Epoch 641/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2272\n",
      "Epoch 642/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2222\n",
      "Epoch 643/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7794 - accuracy: 0.2197\n",
      "Epoch 644/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2223\n",
      "Epoch 645/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2255\n",
      "Epoch 646/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2247\n",
      "Epoch 647/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7791 - accuracy: 0.2247\n",
      "Epoch 648/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7784 - accuracy: 0.2239\n",
      "Epoch 649/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7785 - accuracy: 0.2251\n",
      "Epoch 650/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7787 - accuracy: 0.2209\n",
      "Epoch 651/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7784 - accuracy: 0.2257\n",
      "Epoch 652/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7784 - accuracy: 0.2266\n",
      "Epoch 653/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7775 - accuracy: 0.2270\n",
      "Epoch 654/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2278\n",
      "Epoch 655/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2250\n",
      "Epoch 656/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7786 - accuracy: 0.2299\n",
      "Epoch 657/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2250\n",
      "Epoch 658/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7765 - accuracy: 0.2297\n",
      "Epoch 659/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7788 - accuracy: 0.2227\n",
      "Epoch 660/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2280\n",
      "Epoch 661/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2250\n",
      "Epoch 662/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7787 - accuracy: 0.2228\n",
      "Epoch 663/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2251\n",
      "Epoch 664/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2277\n",
      "Epoch 665/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2242\n",
      "Epoch 666/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2252\n",
      "Epoch 667/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2242\n",
      "Epoch 668/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7788 - accuracy: 0.2263\n",
      "Epoch 669/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7778 - accuracy: 0.2294\n",
      "Epoch 670/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2237 0s - loss: 1.7\n",
      "Epoch 671/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2235\n",
      "Epoch 672/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2226\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2186\n",
      "Epoch 674/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2227\n",
      "Epoch 675/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2283\n",
      "Epoch 676/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2231\n",
      "Epoch 677/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7789 - accuracy: 0.2269\n",
      "Epoch 678/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2252\n",
      "Epoch 679/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7791 - accuracy: 0.2269\n",
      "Epoch 680/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2240\n",
      "Epoch 681/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2243\n",
      "Epoch 682/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7777 - accuracy: 0.2255\n",
      "Epoch 683/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7783 - accuracy: 0.2242\n",
      "Epoch 684/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2286\n",
      "Epoch 685/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7786 - accuracy: 0.2234\n",
      "Epoch 686/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2279\n",
      "Epoch 687/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2247\n",
      "Epoch 688/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7787 - accuracy: 0.2222\n",
      "Epoch 689/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7779 - accuracy: 0.2242\n",
      "Epoch 690/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2253\n",
      "Epoch 691/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2229\n",
      "Epoch 692/1000\n",
      "17630/17630 [==============================] - ETA: 0s - loss: 1.7777 - accuracy: 0.22 - 1s 34us/step - loss: 1.7790 - accuracy: 0.2245\n",
      "Epoch 693/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7789 - accuracy: 0.2252\n",
      "Epoch 694/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7784 - accuracy: 0.2253\n",
      "Epoch 695/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7781 - accuracy: 0.2274\n",
      "Epoch 696/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7788 - accuracy: 0.2238\n",
      "Epoch 697/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2225\n",
      "Epoch 698/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2261\n",
      "Epoch 699/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2269\n",
      "Epoch 700/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7768 - accuracy: 0.2297\n",
      "Epoch 701/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2260\n",
      "Epoch 702/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7789 - accuracy: 0.2263\n",
      "Epoch 703/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2269\n",
      "Epoch 704/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2257\n",
      "Epoch 705/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2231\n",
      "Epoch 706/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7783 - accuracy: 0.2244\n",
      "Epoch 707/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7786 - accuracy: 0.2249\n",
      "Epoch 708/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2262\n",
      "Epoch 709/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2239\n",
      "Epoch 710/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7786 - accuracy: 0.2255\n",
      "Epoch 711/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2223\n",
      "Epoch 712/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2270\n",
      "Epoch 713/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2254\n",
      "Epoch 714/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2299\n",
      "Epoch 715/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2264\n",
      "Epoch 716/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7792 - accuracy: 0.2264\n",
      "Epoch 717/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2258\n",
      "Epoch 718/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2244\n",
      "Epoch 719/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2285\n",
      "Epoch 720/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2243\n",
      "Epoch 721/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2237\n",
      "Epoch 722/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2240\n",
      "Epoch 723/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2242\n",
      "Epoch 724/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2220\n",
      "Epoch 725/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2279\n",
      "Epoch 726/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2284\n",
      "Epoch 727/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2242\n",
      "Epoch 728/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2244\n",
      "Epoch 729/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2215\n",
      "Epoch 730/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7787 - accuracy: 0.2276\n",
      "Epoch 731/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2252\n",
      "Epoch 732/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2286\n",
      "Epoch 733/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2251\n",
      "Epoch 734/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2265\n",
      "Epoch 735/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2279\n",
      "Epoch 736/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2268\n",
      "Epoch 737/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7772 - accuracy: 0.2262\n",
      "Epoch 738/1000\n",
      "17630/17630 [==============================] - 1s 42us/step - loss: 1.7777 - accuracy: 0.2271\n",
      "Epoch 739/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2261\n",
      "Epoch 740/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7791 - accuracy: 0.2222\n",
      "Epoch 741/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2268\n",
      "Epoch 742/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2282\n",
      "Epoch 743/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7775 - accuracy: 0.2262\n",
      "Epoch 744/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2256\n",
      "Epoch 745/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2284\n",
      "Epoch 746/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2290\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2284\n",
      "Epoch 748/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2239\n",
      "Epoch 749/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2238\n",
      "Epoch 750/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2256\n",
      "Epoch 751/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2245\n",
      "Epoch 752/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7772 - accuracy: 0.2260\n",
      "Epoch 753/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7772 - accuracy: 0.2294\n",
      "Epoch 754/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2262\n",
      "Epoch 755/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2254\n",
      "Epoch 756/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2239\n",
      "Epoch 757/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2298\n",
      "Epoch 758/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7777 - accuracy: 0.2254\n",
      "Epoch 759/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2253\n",
      "Epoch 760/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2251\n",
      "Epoch 761/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2260\n",
      "Epoch 762/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2250\n",
      "Epoch 763/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7779 - accuracy: 0.2276\n",
      "Epoch 764/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2279\n",
      "Epoch 765/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2272\n",
      "Epoch 766/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2263\n",
      "Epoch 767/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2235\n",
      "Epoch 768/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2213\n",
      "Epoch 769/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2267\n",
      "Epoch 770/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2230\n",
      "Epoch 771/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7779 - accuracy: 0.2257\n",
      "Epoch 772/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2292\n",
      "Epoch 773/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2238\n",
      "Epoch 774/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2298\n",
      "Epoch 775/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2264\n",
      "Epoch 776/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2247\n",
      "Epoch 777/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2254\n",
      "Epoch 778/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2258\n",
      "Epoch 779/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2230\n",
      "Epoch 780/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2240\n",
      "Epoch 781/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2270\n",
      "Epoch 782/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2235\n",
      "Epoch 783/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2239\n",
      "Epoch 784/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7792 - accuracy: 0.2223\n",
      "Epoch 785/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2267\n",
      "Epoch 786/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2280\n",
      "Epoch 787/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2204\n",
      "Epoch 788/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2272\n",
      "Epoch 789/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2229\n",
      "Epoch 790/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2249\n",
      "Epoch 791/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2209\n",
      "Epoch 792/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2293\n",
      "Epoch 793/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2254\n",
      "Epoch 794/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2224\n",
      "Epoch 795/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2275\n",
      "Epoch 796/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2263\n",
      "Epoch 797/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2249\n",
      "Epoch 798/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7783 - accuracy: 0.2233\n",
      "Epoch 799/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7774 - accuracy: 0.2260\n",
      "Epoch 800/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7774 - accuracy: 0.2277\n",
      "Epoch 801/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7771 - accuracy: 0.2283\n",
      "Epoch 802/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7781 - accuracy: 0.2261\n",
      "Epoch 803/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7779 - accuracy: 0.2238\n",
      "Epoch 804/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7779 - accuracy: 0.2269\n",
      "Epoch 805/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7790 - accuracy: 0.2259\n",
      "Epoch 806/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7773 - accuracy: 0.2301\n",
      "Epoch 807/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7780 - accuracy: 0.2242\n",
      "Epoch 808/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7781 - accuracy: 0.2258\n",
      "Epoch 809/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7780 - accuracy: 0.2263\n",
      "Epoch 810/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7773 - accuracy: 0.2243\n",
      "Epoch 811/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7776 - accuracy: 0.2275\n",
      "Epoch 812/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7780 - accuracy: 0.2260\n",
      "Epoch 813/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7777 - accuracy: 0.2264\n",
      "Epoch 814/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7784 - accuracy: 0.2240\n",
      "Epoch 815/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7780 - accuracy: 0.2247\n",
      "Epoch 816/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2281\n",
      "Epoch 817/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2247\n",
      "Epoch 818/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2280\n",
      "Epoch 819/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2281\n",
      "Epoch 820/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2239\n",
      "Epoch 821/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2237\n",
      "Epoch 822/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2296\n",
      "Epoch 823/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2252\n",
      "Epoch 824/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7785 - accuracy: 0.2255\n",
      "Epoch 825/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2265\n",
      "Epoch 826/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2243\n",
      "Epoch 827/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2255\n",
      "Epoch 828/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2252\n",
      "Epoch 829/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2257\n",
      "Epoch 830/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7784 - accuracy: 0.2243\n",
      "Epoch 831/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7791 - accuracy: 0.2282\n",
      "Epoch 832/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2271\n",
      "Epoch 833/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7767 - accuracy: 0.2282\n",
      "Epoch 834/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2261\n",
      "Epoch 835/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7776 - accuracy: 0.2279\n",
      "Epoch 836/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2275\n",
      "Epoch 837/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2253\n",
      "Epoch 838/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2272\n",
      "Epoch 839/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7776 - accuracy: 0.2283\n",
      "Epoch 840/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7780 - accuracy: 0.2254\n",
      "Epoch 841/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2301\n",
      "Epoch 842/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7777 - accuracy: 0.2257\n",
      "Epoch 843/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7779 - accuracy: 0.2250\n",
      "Epoch 844/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7774 - accuracy: 0.2246 0s - loss: 1.7\n",
      "Epoch 845/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7778 - accuracy: 0.2226\n",
      "Epoch 846/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7778 - accuracy: 0.2269\n",
      "Epoch 847/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7781 - accuracy: 0.2248\n",
      "Epoch 848/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7771 - accuracy: 0.2300\n",
      "Epoch 849/1000\n",
      "17630/17630 [==============================] - 1s 39us/step - loss: 1.7787 - accuracy: 0.2227\n",
      "Epoch 850/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7781 - accuracy: 0.2238\n",
      "Epoch 851/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7791 - accuracy: 0.2237\n",
      "Epoch 852/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7778 - accuracy: 0.2272\n",
      "Epoch 853/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7769 - accuracy: 0.2272\n",
      "Epoch 854/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7784 - accuracy: 0.2241\n",
      "Epoch 855/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7779 - accuracy: 0.2293\n",
      "Epoch 856/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7780 - accuracy: 0.2276\n",
      "Epoch 857/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2292\n",
      "Epoch 858/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7776 - accuracy: 0.2238\n",
      "Epoch 859/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7774 - accuracy: 0.2282\n",
      "Epoch 860/1000\n",
      "17630/17630 [==============================] - 1s 37us/step - loss: 1.7783 - accuracy: 0.2258\n",
      "Epoch 861/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7780 - accuracy: 0.2249\n",
      "Epoch 862/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7790 - accuracy: 0.2237\n",
      "Epoch 863/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7784 - accuracy: 0.2290\n",
      "Epoch 864/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7780 - accuracy: 0.2277\n",
      "Epoch 865/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7781 - accuracy: 0.2199\n",
      "Epoch 866/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7781 - accuracy: 0.2272\n",
      "Epoch 867/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2270\n",
      "Epoch 868/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2258\n",
      "Epoch 869/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2226\n",
      "Epoch 870/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7776 - accuracy: 0.2290\n",
      "Epoch 871/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7778 - accuracy: 0.2264\n",
      "Epoch 872/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7775 - accuracy: 0.2252\n",
      "Epoch 873/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7772 - accuracy: 0.2254\n",
      "Epoch 874/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7783 - accuracy: 0.2246\n",
      "Epoch 875/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7782 - accuracy: 0.2271\n",
      "Epoch 876/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7773 - accuracy: 0.2278\n",
      "Epoch 877/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7782 - accuracy: 0.2233\n",
      "Epoch 878/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7779 - accuracy: 0.2262\n",
      "Epoch 879/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7782 - accuracy: 0.2239\n",
      "Epoch 880/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7786 - accuracy: 0.2250\n",
      "Epoch 881/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7776 - accuracy: 0.2284\n",
      "Epoch 882/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7787 - accuracy: 0.2257\n",
      "Epoch 883/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7784 - accuracy: 0.2260\n",
      "Epoch 884/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7773 - accuracy: 0.2257\n",
      "Epoch 885/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7780 - accuracy: 0.2237\n",
      "Epoch 886/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7782 - accuracy: 0.2268\n",
      "Epoch 887/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7789 - accuracy: 0.2246\n",
      "Epoch 888/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7767 - accuracy: 0.2248\n",
      "Epoch 889/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7772 - accuracy: 0.2250\n",
      "Epoch 890/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7772 - accuracy: 0.2265\n",
      "Epoch 891/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7776 - accuracy: 0.2240\n",
      "Epoch 892/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7776 - accuracy: 0.2238\n",
      "Epoch 893/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7776 - accuracy: 0.2281\n",
      "Epoch 894/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7772 - accuracy: 0.2275\n",
      "Epoch 895/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7779 - accuracy: 0.2217\n",
      "Epoch 896/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7784 - accuracy: 0.2236\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7772 - accuracy: 0.2276\n",
      "Epoch 898/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7787 - accuracy: 0.2248\n",
      "Epoch 899/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2234\n",
      "Epoch 900/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7773 - accuracy: 0.2277\n",
      "Epoch 901/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7770 - accuracy: 0.2289\n",
      "Epoch 902/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7784 - accuracy: 0.2285\n",
      "Epoch 903/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7777 - accuracy: 0.2289\n",
      "Epoch 904/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2239\n",
      "Epoch 905/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2243\n",
      "Epoch 906/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2290\n",
      "Epoch 907/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7781 - accuracy: 0.2263\n",
      "Epoch 908/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7773 - accuracy: 0.2269\n",
      "Epoch 909/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7776 - accuracy: 0.2261\n",
      "Epoch 910/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2265\n",
      "Epoch 911/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7779 - accuracy: 0.2277\n",
      "Epoch 912/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2260\n",
      "Epoch 913/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2281\n",
      "Epoch 914/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2246\n",
      "Epoch 915/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7785 - accuracy: 0.2244\n",
      "Epoch 916/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2215\n",
      "Epoch 917/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2261\n",
      "Epoch 918/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7769 - accuracy: 0.2320\n",
      "Epoch 919/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2240\n",
      "Epoch 920/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2247\n",
      "Epoch 921/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7772 - accuracy: 0.2256\n",
      "Epoch 922/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7786 - accuracy: 0.2273\n",
      "Epoch 923/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2241\n",
      "Epoch 924/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2258\n",
      "Epoch 925/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7774 - accuracy: 0.2235\n",
      "Epoch 926/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2255\n",
      "Epoch 927/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7788 - accuracy: 0.2249\n",
      "Epoch 928/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2256\n",
      "Epoch 929/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2280\n",
      "Epoch 930/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2275\n",
      "Epoch 931/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2267\n",
      "Epoch 932/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2261\n",
      "Epoch 933/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7779 - accuracy: 0.2238\n",
      "Epoch 934/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7783 - accuracy: 0.2271\n",
      "Epoch 935/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2256\n",
      "Epoch 936/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2233\n",
      "Epoch 937/1000\n",
      "17630/17630 [==============================] - 1s 35us/step - loss: 1.7778 - accuracy: 0.2241\n",
      "Epoch 938/1000\n",
      "17630/17630 [==============================] - 1s 38us/step - loss: 1.7787 - accuracy: 0.2246\n",
      "Epoch 939/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7776 - accuracy: 0.2275\n",
      "Epoch 940/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7771 - accuracy: 0.2273\n",
      "Epoch 941/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7777 - accuracy: 0.2268\n",
      "Epoch 942/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2245\n",
      "Epoch 943/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2259\n",
      "Epoch 944/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2287\n",
      "Epoch 945/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2275\n",
      "Epoch 946/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7774 - accuracy: 0.2286\n",
      "Epoch 947/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7784 - accuracy: 0.2236\n",
      "Epoch 948/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2240\n",
      "Epoch 949/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7770 - accuracy: 0.2291\n",
      "Epoch 950/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7773 - accuracy: 0.2279\n",
      "Epoch 951/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2263\n",
      "Epoch 952/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2267\n",
      "Epoch 953/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7776 - accuracy: 0.2290\n",
      "Epoch 954/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2296\n",
      "Epoch 955/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2279\n",
      "Epoch 956/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2260\n",
      "Epoch 957/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2300\n",
      "Epoch 958/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7777 - accuracy: 0.2246\n",
      "Epoch 959/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2303\n",
      "Epoch 960/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7768 - accuracy: 0.2291\n",
      "Epoch 961/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7779 - accuracy: 0.2263\n",
      "Epoch 962/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7770 - accuracy: 0.2281\n",
      "Epoch 963/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2267\n",
      "Epoch 964/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7787 - accuracy: 0.2254\n",
      "Epoch 965/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7780 - accuracy: 0.2275\n",
      "Epoch 966/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7781 - accuracy: 0.2268\n",
      "Epoch 967/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2280\n",
      "Epoch 968/1000\n",
      "17630/17630 [==============================] - 1s 36us/step - loss: 1.7774 - accuracy: 0.2267\n",
      "Epoch 969/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2265\n",
      "Epoch 970/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7774 - accuracy: 0.2267\n",
      "Epoch 971/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2242\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7770 - accuracy: 0.2258\n",
      "Epoch 973/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7784 - accuracy: 0.2270\n",
      "Epoch 974/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7769 - accuracy: 0.2274\n",
      "Epoch 975/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7774 - accuracy: 0.2273\n",
      "Epoch 976/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7768 - accuracy: 0.2288\n",
      "Epoch 977/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7773 - accuracy: 0.2260\n",
      "Epoch 978/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2286\n",
      "Epoch 979/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7776 - accuracy: 0.2254\n",
      "Epoch 980/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7788 - accuracy: 0.2228\n",
      "Epoch 981/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7782 - accuracy: 0.2247\n",
      "Epoch 982/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7776 - accuracy: 0.2294\n",
      "Epoch 983/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2255\n",
      "Epoch 984/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7773 - accuracy: 0.2260\n",
      "Epoch 985/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7768 - accuracy: 0.2272\n",
      "Epoch 986/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7777 - accuracy: 0.2264\n",
      "Epoch 987/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7780 - accuracy: 0.2268\n",
      "Epoch 988/1000\n",
      "17630/17630 [==============================] - 1s 34us/step - loss: 1.7773 - accuracy: 0.2264\n",
      "Epoch 989/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2281\n",
      "Epoch 990/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7780 - accuracy: 0.2243\n",
      "Epoch 991/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7778 - accuracy: 0.2297\n",
      "Epoch 992/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7769 - accuracy: 0.2244\n",
      "Epoch 993/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2222\n",
      "Epoch 994/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7782 - accuracy: 0.2243\n",
      "Epoch 995/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7775 - accuracy: 0.2309\n",
      "Epoch 996/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7771 - accuracy: 0.2288\n",
      "Epoch 997/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7775 - accuracy: 0.2263\n",
      "Epoch 998/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2280\n",
      "Epoch 999/1000\n",
      "17630/17630 [==============================] - 1s 32us/step - loss: 1.7779 - accuracy: 0.2261\n",
      "Epoch 1000/1000\n",
      "17630/17630 [==============================] - 1s 33us/step - loss: 1.7778 - accuracy: 0.2217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27fd66acfc8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_nn.fit(x_train,y_train,batch_size=128,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4408/4408 [==============================] - 0s 42us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8083463349056763, 0.18421052396297455]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = classifier_nn.evaluate(x_test,y_test,batch_size=128)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier_nn.predict_classes(x_test)\n",
    "rounded_predictions = y_pred\n",
    "rounded_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "rounded_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19,  0,  0, ...,  0,  0,  0],\n",
       "       [20,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, 13, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [24,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0, 33,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0, 30]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(rounded_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18421052631578946\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(rounded_labels, rounded_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6049"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will be using PyCaret library which is an open source, low-code machine learning library in Python that aims to reduce the cycle time from hypothesis to insights.\n",
    "\n",
    "#### Creating a model in any module is as simple as writing create_model. It takes only one parameter i.e. the model abbreviation as string. For supervised modules (classification and regression) this function returns a table with k-fold cross validated scores of common evaluation metrics along with trained model object.The evaluation metrics used are:\n",
    "\n",
    "#### Classification: Accuracy, AUC, Recall, Precision, F1, Kappa\n",
    "\n",
    "\n",
    "## Advantages of PyCaret :\n",
    "        Performs all data preprocessing steps by itself like handling missing values,handling categoricals,sampling of data,\n",
    "        splitting of training and test data,10 fold cross validation or even hyperparameter tuning, PyCaret automates \n",
    "        all of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Setup Succesfully Completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e3323624_8f8a_11ea_8400_485ab642acbe\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow0_col1\" class=\"data row0 col1\" >2021</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow1_col0\" class=\"data row1 col0\" >Target Type</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow1_col1\" class=\"data row1 col1\" >Multiclass</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow2_col0\" class=\"data row2 col0\" >Label Encoded</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow2_col1\" class=\"data row2 col1\" >ALOO PARATHA: 0, BAINGAN BARTHA: 1, BHINDI DO PIAZZA: 2, BUTTER CHICKEN: 3, CARROT HALWA: 4, CHAAT PAPRI: 5, CHICKEN BIRYANI: 6, CHICKEN KORMA: 7, CHICKEN SAAG: 8, CHICKEN TIKKA MASALA: 9, COCKTAIL CHICKEN SAMOSAS: 10, COCONUT CHICKEN CURRY: 11, FISH CURRY: 12, FISH KORMA: 13, FISH PAKORA: 14, GARLIC NAAN: 15, GOBI MANCHURIAN: 16, GULABJAMUN: 17, HARA BHARA KABOB: 18, KADAHI LAMB: 19, KADAHI PANEER: 20, KHEER: 21, LACHA PARATHA: 22, MALAI KOFTA: 23, MALPURA: 24, MASALA CHICKEN WINGS: 25, NAAN: 26, ONION KULCHA: 27, PANEER VINDALOO: 28, RASMALAI: 29, RICE: 30, SARSON DA SAAG: 31, SHAHI PANEER: 32, SHRIMP STRIPS: 33, SPICY CHICKEN BITES: 34, SPINACH NAAN: 35, TANDOORI ROTI: 36, TASTY FLATBREAD: 37, TASTY SLIDERS : CHICKEN PANEER: 38, TIKKA RICE BOWL : PANEER | CHICKEN: 39, VEGETABLE PAKORA: 40, VEGETABLE SAMOSA: 41, YELLOW DAL FRY: 42</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow3_col0\" class=\"data row3 col0\" >Original Data</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow3_col1\" class=\"data row3 col1\" >(22038, 5)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow4_col0\" class=\"data row4 col0\" >Missing Values </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow4_col1\" class=\"data row4 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow5_col0\" class=\"data row5 col0\" >Numeric Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow6_col0\" class=\"data row6 col0\" >Categorical Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow6_col1\" class=\"data row6 col1\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow7_col0\" class=\"data row7 col0\" >Ordinal Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow7_col1\" class=\"data row7 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow8_col0\" class=\"data row8 col0\" >High Cardinality Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow8_col1\" class=\"data row8 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow9_col0\" class=\"data row9 col0\" >High Cardinality Method </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow9_col1\" class=\"data row9 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow10_col0\" class=\"data row10 col0\" >Sampled Data</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow10_col1\" class=\"data row10 col1\" >(22038, 5)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow11_col1\" class=\"data row11 col1\" >(15426, 17)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow12_col1\" class=\"data row12 col1\" >(6612, 17)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow13_col0\" class=\"data row13 col0\" >Numeric Imputer </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow14_col0\" class=\"data row14 col0\" >Categorical Imputer </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow14_col1\" class=\"data row14 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow15_col0\" class=\"data row15 col0\" >Normalize </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow15_col1\" class=\"data row15 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow16_col0\" class=\"data row16 col0\" >Normalize Method </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow16_col1\" class=\"data row16 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow17_col0\" class=\"data row17 col0\" >Transformation </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow17_col1\" class=\"data row17 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow18_col0\" class=\"data row18 col0\" >Transformation Method </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow18_col1\" class=\"data row18 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow19_col0\" class=\"data row19 col0\" >PCA </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow19_col1\" class=\"data row19 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow20_col0\" class=\"data row20 col0\" >PCA Method </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow20_col1\" class=\"data row20 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow21_col0\" class=\"data row21 col0\" >PCA Components </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow21_col1\" class=\"data row21 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow22_col0\" class=\"data row22 col0\" >Ignore Low Variance </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow22_col1\" class=\"data row22 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow23_col0\" class=\"data row23 col0\" >Combine Rare Levels </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow23_col1\" class=\"data row23 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow24_col0\" class=\"data row24 col0\" >Rare Level Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow24_col1\" class=\"data row24 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow25_col0\" class=\"data row25 col0\" >Numeric Binning </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow25_col1\" class=\"data row25 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow26_col0\" class=\"data row26 col0\" >Remove Outliers </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow26_col1\" class=\"data row26 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow27_col0\" class=\"data row27 col0\" >Outliers Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow27_col1\" class=\"data row27 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow28_col0\" class=\"data row28 col0\" >Remove Multicollinearity </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow28_col1\" class=\"data row28 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow29_col0\" class=\"data row29 col0\" >Multicollinearity Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow29_col1\" class=\"data row29 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow30_col0\" class=\"data row30 col0\" >Clustering </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow30_col1\" class=\"data row30 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow31_col0\" class=\"data row31 col0\" >Clustering Iteration </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow31_col1\" class=\"data row31 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow32_col0\" class=\"data row32 col0\" >Polynomial Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow32_col1\" class=\"data row32 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow33_col0\" class=\"data row33 col0\" >Polynomial Degree </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow33_col1\" class=\"data row33 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow34_col0\" class=\"data row34 col0\" >Trignometry Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow34_col1\" class=\"data row34 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow35_col0\" class=\"data row35 col0\" >Polynomial Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow36_col0\" class=\"data row36 col0\" >Group Features </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow37_col0\" class=\"data row37 col0\" >Feature Selection </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow38_col0\" class=\"data row38 col0\" >Features Selection Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow38_col1\" class=\"data row38 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow39_col0\" class=\"data row39 col0\" >Feature Interaction </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow39_col1\" class=\"data row39 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow40_col0\" class=\"data row40 col0\" >Feature Ratio </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e3323624_8f8a_11ea_8400_485ab642acbelevel0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow41_col0\" class=\"data row41 col0\" >Interaction Threshold </td>\n",
       "                        <td id=\"T_e3323624_8f8a_11ea_8400_485ab642acberow41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27fdda2fb88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Data preparation step in pycaret '''\n",
    "data_pycaret_model = data.drop(columns=['Date','ItemQty'])\n",
    "clf1 = setup(data = data_pycaret_model, target = 'MenuItem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.1716</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1878</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.2119  0.0  0.1930  0.1954  0.1951  0.1902\n",
       "1       0.2087  0.0  0.1906  0.2018  0.1888  0.1869\n",
       "2       0.1931  0.0  0.1775  0.1848  0.1807  0.1709\n",
       "3       0.1905  0.0  0.1745  0.1716  0.1713  0.1683\n",
       "4       0.2165  0.0  0.2009  0.1965  0.1948  0.1949\n",
       "5       0.2054  0.0  0.1953  0.1850  0.1832  0.1836\n",
       "6       0.1997  0.0  0.1878  0.1869  0.1830  0.1777\n",
       "7       0.2224  0.0  0.2100  0.2080  0.2017  0.2010\n",
       "8       0.1868  0.0  0.1760  0.1753  0.1688  0.1644\n",
       "9       0.2069  0.0  0.1914  0.1927  0.1898  0.1850\n",
       "Mean    0.2042  0.0  0.1897  0.1898  0.1857  0.1823\n",
       "SD      0.0110  0.0  0.0108  0.0108  0.0099  0.0113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Creating XGBOOST classifier model for predicting MenuItems with 10 fold Cross validation '''\n",
    "xgboost = create_model('xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>0.1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>0.1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.1743</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1803</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.1698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.1803</td>\n",
       "      <td>0.1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.2003  0.0  0.1814  0.1887  0.1851  0.1783\n",
       "1       0.2035  0.0  0.1872  0.1872  0.1837  0.1815\n",
       "2       0.1892  0.0  0.1739  0.1800  0.1767  0.1669\n",
       "3       0.1938  0.0  0.1789  0.1743  0.1760  0.1717\n",
       "4       0.1977  0.0  0.1833  0.1803  0.1804  0.1757\n",
       "5       0.1977  0.0  0.1864  0.1772  0.1785  0.1757\n",
       "6       0.1842  0.0  0.1702  0.1758  0.1683  0.1617\n",
       "7       0.2069  0.0  0.1958  0.1860  0.1892  0.1852\n",
       "8       0.1991  0.0  0.1848  0.1888  0.1833  0.1771\n",
       "9       0.1920  0.0  0.1801  0.1853  0.1816  0.1698\n",
       "Mean    0.1964  0.0  0.1822  0.1824  0.1803  0.1744\n",
       "SD      0.0064  0.0  0.0068  0.0052  0.0055  0.0066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Creating RandomForest Classifier model for predicting MenuItems with 10 fold Cross validation '''\n",
    "rf_model = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>0.1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.1744</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>0.1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>0.1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>0.1710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.1821</td>\n",
       "      <td>0.1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.2080  0.0  0.1898  0.1866  0.1887  0.1862\n",
       "1       0.2087  0.0  0.1898  0.1967  0.1905  0.1868\n",
       "2       0.1866  0.0  0.1717  0.1813  0.1762  0.1643\n",
       "3       0.1905  0.0  0.1723  0.1791  0.1759  0.1684\n",
       "4       0.2061  0.0  0.1895  0.1935  0.1872  0.1842\n",
       "5       0.1938  0.0  0.1833  0.1724  0.1733  0.1716\n",
       "6       0.1907  0.0  0.1757  0.1744  0.1725  0.1684\n",
       "7       0.2173  0.0  0.2058  0.1995  0.1962  0.1957\n",
       "8       0.2043  0.0  0.1892  0.1905  0.1859  0.1823\n",
       "9       0.1933  0.0  0.1758  0.1775  0.1749  0.1710\n",
       "Mean    0.1999  0.0  0.1843  0.1852  0.1821  0.1779\n",
       "SD      0.0097  0.0  0.0101  0.0091  0.0081  0.0099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Tuning RandomForest Model to get better results using Pycaret '''\n",
    "rf_tuned = tune_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1971</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.1858</td>\n",
       "      <td>0.1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.1717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1964</td>\n",
       "      <td>0.1907</td>\n",
       "      <td>0.1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.2022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.1802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy  AUC  Recall   Prec.      F1   Kappa\n",
       "0       0.2145  0.0  0.1971  0.1970  0.1967  0.1928\n",
       "1       0.2041  0.0  0.1861  0.1915  0.1858  0.1822\n",
       "2       0.1879  0.0  0.1742  0.1780  0.1753  0.1656\n",
       "3       0.1938  0.0  0.1770  0.1810  0.1780  0.1717\n",
       "4       0.2106  0.0  0.1949  0.1964  0.1907  0.1889\n",
       "5       0.2029  0.0  0.1927  0.1915  0.1843  0.1810\n",
       "6       0.1952  0.0  0.1811  0.1787  0.1774  0.1731\n",
       "7       0.2166  0.0  0.2056  0.2014  0.1962  0.1951\n",
       "8       0.2004  0.0  0.1866  0.1868  0.1809  0.1783\n",
       "9       0.1958  0.0  0.1815  0.1823  0.1790  0.1737\n",
       "Mean    0.2022  0.0  0.1877  0.1885  0.1844  0.1802\n",
       "SD      0.0090  0.0  0.0093  0.0079  0.0074  0.0092"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Creating Gradient Boosting Classifier model for predicting MenuItems with 10 fold Cross validation '''\n",
    "gbc = create_model('gbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we can examine from outputs of various classification models, overall performance of XGBOOST is higher than others.\n",
    "\n",
    "### So we will be using XGBOOST model as our final model for predictions of MenuItems on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Day Type</th>\n",
       "      <th>Shift</th>\n",
       "      <th>MenuCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>DESSERTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>CHICKEN SPECIALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>SEAFOOD SPECIALTIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day Day Type  Shift         MenuCategory\n",
       "0  Monday  Weekday  Lunch             DESSERTS\n",
       "1  Monday  Weekday  Lunch               BREADS\n",
       "2  Monday  Weekday  Lunch               BREADS\n",
       "3  Monday  Weekday  Lunch   VEGETABLE SPECIALS\n",
       "4  Monday  Weekday  Lunch     CHICKEN SPECIALS\n",
       "5  Monday  Weekday  Lunch  SEAFOOD SPECIALTIES\n",
       "6  Monday  Weekday  Lunch   VEGETABLE SPECIALS\n",
       "7  Monday  Weekday  Lunch               BREADS\n",
       "8  Monday  Weekday  Lunch              Starter\n",
       "9  Monday  Weekday  Lunch               BREADS"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Importing Test set created for dates from 1st July,2019 to 7th July,2019 '''\n",
    "load_test_data = pd.read_excel('test_data.xlsx')\n",
    "test_data = load_test_data.copy()\n",
    "test_data.drop(columns=['Date','ItemQty','MenuItem'],inplace=True)\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Day Type</th>\n",
       "      <th>Shift</th>\n",
       "      <th>MenuCategory</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>17</td>\n",
       "      <td>0.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>CHICKEN SPECIALS</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>CHICKEN SPECIALS</td>\n",
       "      <td>11</td>\n",
       "      <td>0.2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>29</td>\n",
       "      <td>0.2562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>22</td>\n",
       "      <td>0.1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>29</td>\n",
       "      <td>0.2562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Day Day Type   Shift        MenuCategory  Label   Score\n",
       "0    Monday  Weekday   Lunch            DESSERTS     17  0.2180\n",
       "1    Monday  Weekday   Lunch              BREADS     36  0.1796\n",
       "2    Monday  Weekday   Lunch              BREADS     36  0.1796\n",
       "3    Monday  Weekday   Lunch  VEGETABLE SPECIALS     32  0.1836\n",
       "4    Monday  Weekday   Lunch    CHICKEN SPECIALS      9  0.2412\n",
       "..      ...      ...     ...                 ...    ...     ...\n",
       "841  Sunday  Weekend  Dinner    CHICKEN SPECIALS     11  0.2304\n",
       "842  Sunday  Weekend  Dinner  VEGETABLE SPECIALS      2  0.1525\n",
       "843  Sunday  Weekend  Dinner            DESSERTS     29  0.2562\n",
       "844  Sunday  Weekend  Dinner              BREADS     22  0.1708\n",
       "845  Sunday  Weekend  Dinner            DESSERTS     29  0.2562\n",
       "\n",
       "[846 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions = predict_model(xgboost,test_data)\n",
    "model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_of_items = { 0:'ALOO PARATHA',  1:'BAINGAN BARTHA',  2:'BHINDI DO PIAZZA',  3:'BUTTER CHICKEN',  4:'CARROT HALWA', \n",
    "                     5:'CHAAT PAPRI',  6:'CHICKEN BIRYANI',  7:'CHICKEN KORMA',  8:'CHICKEN SAAG', 9:'CHICKEN TIKKA MASALA' ,\n",
    "                     10:'COCKTAIL CHICKEN SAMOSAS',  11:'COCONUT CHICKEN CURRY',  12:'FISH CURRY',  13:'FISH KORMA',  14:'FISH PAKORA',\n",
    "                     15:'GARLIC NAAN',  16:'GOBI MANCHURIAN',  17:'GULABJAMUN',  18:'HARA BHARA KABOB',  19:'KADAHI LAMB',\n",
    "                     20:'KADAHI PANEER',  21:'KHEER',  22:'LACHA PARATHA',  23:'MALAI KOFTA',  24:'MALPURA',  25:'MASALA CHICKEN WINGS',\n",
    "                    26:'NAAN' , 27:'ONION KULCHA' , 28:'PANEER VINDALOO' , 29:'RASMALAI' , 30:'RICE' ,  31:'SARSON DA SAAG', \n",
    "                     32:'SHAHI PANEER',  33:'SHRIMP STRIPS',  34:'SPICY CHICKEN BITES',  35:'SPINACH NAAN',  36:'TANDOORI ROTI',\n",
    "                    37:'TASTY FLATBREAD' ,  38:'TASTY SLIDERS : CHICKEN PANEER', 39:'TIKKA RICE BOWL : PANEER | CHICKEN' ,\n",
    "                     40:'VEGETABLE PAKORA', 41:'VEGETABLE SAMOSA' ,  42:'YELLOW DAL FRY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day Type</th>\n",
       "      <th>Shift</th>\n",
       "      <th>MenuCategory</th>\n",
       "      <th>MenuItem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>GULABJAMUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>TANDOORI ROTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>BREADS</td>\n",
       "      <td>TANDOORI ROTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>VEGETABLE SPECIALS</td>\n",
       "      <td>SHAHI PANEER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>CHICKEN SPECIALS</td>\n",
       "      <td>CHICKEN TIKKA MASALA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Day Day Type  Shift        MenuCategory              MenuItem\n",
       "0 2019-07-01  Monday  Weekday  Lunch            DESSERTS            GULABJAMUN\n",
       "1 2019-07-01  Monday  Weekday  Lunch              BREADS         TANDOORI ROTI\n",
       "2 2019-07-01  Monday  Weekday  Lunch              BREADS         TANDOORI ROTI\n",
       "3 2019-07-01  Monday  Weekday  Lunch  VEGETABLE SPECIALS          SHAHI PANEER\n",
       "4 2019-07-01  Monday  Weekday  Lunch    CHICKEN SPECIALS  CHICKEN TIKKA MASALA"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Converting the labels into names of food items using above mapping '''\n",
    "model_predictions['MenuItem'] = model_predictions.Label.apply(lambda x: mapping_of_items.get(x))\n",
    "model_predictions['Date'] = load_test_data.Date.apply(lambda x: x)\n",
    "model_predictions.drop(columns=['Label','Score'],inplace=True)\n",
    "model_predictions = model_predictions[['Date', 'Day', 'Day Type', 'Shift', 'MenuCategory', 'MenuItem']]\n",
    "model_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Exporting results to an excel file which will be used as test data for predicting Item Quantity for each MenuItem '''\n",
    "model_predictions.to_excel('Predicted_MenuItems.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53467"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
